<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Nonparametrics on Sam Clifford </title>
    <link>/./tags/nonparametrics/</link>
    <language>en-us</language>
    <author>Alexander Ivanov</author>
    <updated>2014-09-24 00:00:00 &#43;0000 UTC</updated>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2014/09/24/posterior-samples/</link>
      <pubDate>Wed, 24 Sep 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/09/24/posterior-samples/</guid>
      <description>&lt;p&gt;SEB113 students really seemed to enjoy looking at mathematical modelling last week. &lt;a href=&#34;http://books.google.com.au/books?id=nM_X1PTccloC&amp;amp;lpg=PA111&amp;amp;ots=dCzeaDpIeb&amp;amp;dq=lotka%20volterra%20fulford%20and%20barnes&amp;amp;pg=PA106#v=onepage&amp;amp;q=lotka%20volterra%20fulford%20and%20barnes&amp;amp;f=false&#34;&gt;The Lotka-Volterra equations&lt;/a&gt; continue to be a good teaching tool. A student pointed out that when reviewing the limit idea for derivatives it’d be useful to show it with approximating the circumference of a circle using a polygon. So I knocked this up: &lt;a href=&#34;https://samcliffordinfo.files.wordpress.com/2014/09/approximations.png&#34;&gt;&lt;img src=&#34;approximations.png?w=300&#34; alt=&#34;approximations&#34; /&gt;&lt;/a&gt; Are you interested in big data and/or air quality? &lt;a href=&#34;https://www.qut.edu.au/research/our-research/student-topics/big-data-and-nanoparticles-modelling-complex-spatio-temporal-variation&#34;&gt;Consider doing a PhD with me&lt;/a&gt;. This week I showed in the workshop how Markov chains are a neat application of linear algebra for dealing with probability. We used &lt;a href=&#34;http://setosa.io/blog/2014/07/26/markov-chains/&#34;&gt;this interactive visualisation&lt;/a&gt; to investigate what happens as the transition probabilities change. Zoubin Ghahramani has written &lt;a href=&#34;http://rsta.royalsocietypublishing.org/content/371/1984/20110553.abstract&#34;&gt;a really nice review paper&lt;/a&gt; of Bayesian non-parametrics that I really recommend checking out if you’re interested in the new modelling techniques that have been coming out in the last few years for complex data sets. &lt;a href=&#34;http://www.wired.com/2014/09/exercism/&#34;&gt;Exercism.io&lt;/a&gt; is a new service for learning how to master programming by getting feedback on exercises.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/08/02/posterior-samples/</link>
      <pubDate>Fri, 02 Aug 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/08/02/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://lindsaybradford.wordpress.com/2013/07/25/the-database-design-goggles-they-do-nothing/&#34;&gt;Database design is important&lt;/a&gt;, especially if someone else has to work with your database. It’s not really something we teach in undergraduate science, perhaps the American model of requiring a certain number of credits from certain fields would help remedy this. Ever wanted a glimpse of &lt;a href=&#34;http://xianblog.wordpress.com/2013/07/22/bayes-notebook/&#34;&gt;Bayes’ notebook&lt;/a&gt;? Laura McInerney’s comments on the benefits of &lt;a href=&#34;http://thesiswhisperer.com/2013/07/31/in-praise-of-the-small-conference/&#34;&gt;small conferences&lt;/a&gt; are similar to my experience with &lt;a href=&#34;http://bayesian.org/node/1657&#34;&gt;8 BNP&lt;/a&gt; in Veracruz, Mexico. As long as you’re within the niche field this sort of conference is a great experience. I felt a little like an outsider at 8 BNP because while I was interested in non-parametrics and was working on smoothing, a lot of people were working on things that I had no experience with which are actually the central elements of the field. I got to learn about a lot of neat things, hear some great talks and meet lots of amazing people, but I don’t think I was steeped in NP Bayes enough to really get the most out of the conference. My research went a bit away from NP Bayes these last few years so I didn’t get to put anything together for 9 BNP in Amsterdam. Perhaps ISBA 2014 in Cancún, Mexico will provide a bit more of a chance to get back to that work. We’re teaching R in SEB113. Perhaps any students reading this might be interested in these &lt;a href=&#34;http://www.computerworld.com/s/article/9239799/60_R_resources_to_improve_your_data_skills&#34;&gt;60 R resources&lt;/a&gt;. I use multiple monitors at work but really enjoyed the virtual monitors setup in Gnome when I ran Ubuntu. &lt;a href=&#34;http://lifehacker.com/5616859/is-the-multiple+monitor-productivity-boost-a-myth&#34;&gt;It turns out&lt;/a&gt; that having a large canvas of pixels, rather than multiple monitors, is the key to workplace productivity. My work setup has two widescreen monitors side by side in portrait orientation. This doesn’t work particularly well with programs that assume you’re using a single landscape monitor (such as RStudio) or give you a single window with multiple documents inside that each have focus one at a time (Microsoft Office, why can’t I have a spreadsheet on each monitor?) but it means I don’t have to keep switching back and forth between TeXStudio and RStudio when I’m writing up my analysis. &lt;a href=&#34;http://chronicle.com/article/Introduction-to-Ancient/140475/&#34;&gt;Flipped classes&lt;/a&gt; are an interesting model for education. I remember taking an Honours level mathematical modelling course a few years ago where the three hours of lecture time allocated us were used to discuss concepts and do modelling. We would read a chapter from the textbook in the lead-up to the class and then have a talk about what it meant and then work out a model based on a case study. I don’t know how well a truly flipped class would translate to a group bigger than about 30 students, but Sue Savage (QUT) tells me that the new lecture theatres in P block are designed to facilitate small group discussions within lectures. Daina Taimiņa explains &lt;a href=&#34;https://www.youtube.com/watch?v=w1TBZhd-sN0&#34;&gt;hyperbolic geometry&lt;/a&gt; with crochet. Every once in a while something similar pops up and I can’t help but get excited. &lt;a href=&#34;http://longnow.org/essays/richard-feynman-connection-machine/&#34;&gt;Daniel Hills recalls his memories&lt;/a&gt; of working with Richard Feynman on developing a massive parallel computer in the 1980s.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stop, collaborate and listen</title>
      <link>/./2013/06/27/stop-collaborate-and-listen/</link>
      <pubDate>Thu, 27 Jun 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/06/27/stop-collaborate-and-listen/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://simplystatistics.org/2013/06/25/doing-statistical-research/&#34;&gt;Roger Peng posted at Simply Statistics&lt;/a&gt; about what it is to &lt;a href=&#34;http://stattrak.amstat.org/2013/06/01/how-to-do-statistical-research/&#34;&gt;do statistical research&lt;/a&gt; and how research is essentially solving problems that can’t be solved with the current methods. The message I took from Peng’s post is that often you can 90% solve a problem with current methods and that a lot of the time this is “good enough” and you can come back to the problem later with some new approaches that go beyond the current methods. As part of the UPTECH project I’ve been doing a lot of work with Bayesian hierarchical linear models. While our data has been collected from a panel design (25 schools, two weeks at each) it’s not always appropriate to use a full-blown spatial model. For example, the microbiological work I’ve been doing with my Finnish collaborator is mostly solvable by using exchangeable means priors to estimate classroom level and school level effects. Recently I’ve also had to start looking at clustering techniques, meta-analysis, spatial modelling of high-resolution data, estimating personal exposure, large surveys, and many other applied science problems that require a novel statistical approach. This sort of collaboration/consulting work, according to Terry Speed (whose post Peng is discussing), is a chance to meet lots of people and work on some interesting problems. For me, it has involved learning about existing techniques and trying to figure out how my collaborators and I can apply them to our data to do the best inference we can. With the UPTECH work, there’s always going to be a large list of authors due to the size of the project and the number of people involved in collecting data. Authorship will always be an issue with our papers, both in terms of inclusion and ordering, and we’ve got a decent process in place which makes people aware of papers as they’re finishing up (but not yet ready for submission). My personal belief is that one should always be able to point to a published paper and say “I did that”. Collaboration in applied physics and chemistry seems to be a very different beast to collaboration in statistics and mathematics. Many of the postgraduate students I know in Mathematics have tended to write methods papers with their supervisor(s) and that’s it. There’s the occasional collaboration to apply the method to a problem, but unless you’re working on cross-disciplinary modelling work or a large project involving numerical simulation there doesn’t appear to be much scope for multi-author work. Look back at some of the foundational statistical papers and you’ll see they’ve been written by a single author (some (non-parametric) Bayesian foundations spring to mind: &lt;a href=&#34;http://www.numdam.org/item?id=AIHP_1937__7_1_1_0&#34;&gt;de Finetti, 1937&lt;/a&gt;; &lt;a href=&#34;http://projecteuclid.org/DPubS?service=UI&amp;amp;version=1.0&amp;amp;verb=Display&amp;amp;handle=euclid.pjm/1102992601&#34;&gt;Kingman, 1967&lt;/a&gt;; and &lt;a href=&#34;http://projecteuclid.org/DPubS?service=UI&amp;amp;version=1.0&amp;amp;verb=Display&amp;amp;handle=euclid.aos/1176342360&#34;&gt;Ferguson, 1973&lt;/a&gt;). The question of when to collaborate, with whom, and what it will add is part and parcel of modern science but there are some fields where collaboration is rare and keeping the author list short &lt;a href=&#34;http://andrewgelman.com/2013/06/25/is-there-too-much-coauthorship-in-economics-and-science-more-generally-or-too-little/&#34;&gt;can lead to problems&lt;/a&gt;. Statistical research is necessary when there’s a problem to be solved that is 0% solvable with the current methods. Some of what I’m doing is novel, within the context of aerosol science, but I haven’t done as much stats research in my postdoc as in my PhD. This is no doubt a result of my doing as much collaboration as I am. I get to work on a lot of problems but there’s not much original statistical work in these papers; if I’m lucky I get to do some of the “10%” research. It’s hard to do statistical research in a physics group, especially as the only statistician here. I think if we had a second statistician in the group there’d be a lot more statistics being done both in terms of collaboration/consultation with the scientists and the methods we use to solve problems. The “Airports of the Future” project has quite a number of statisticians working on, among other things, Bayesian Networks, and they’re extending the BN methodology as well as applying it to a novel problem. Two of the members of this team gave a talk at BRAG this morning about visualisation of BN results. This is something I’ll no doubt need to learn about sooner or later as we plan on using BNs with another project that ILAQH is putting together. Four and a half years ago I was under the impression I was joining a physics group to do computational fluid dynamics. Since then I have been learning statistics almost constantly. It’s opened up many more opportunities for collaboration than CFD would have. The trick for me now is to try and put myself in a position where I’m working with other statisticians on statistics. We’ve got some work coming up soon with a more senior statistician at &lt;a href=&#34;http://www.ihbi.qut.edu.au/&#34;&gt;IHBI&lt;/a&gt;, which I hope will bring with it some opportunities for more statistical methodology work. Unrelated PS: The &lt;a href=&#34;http://andrewgelman.com/2013/06/26/dont-buy-bayesian-data-analysis/&#34;&gt;3rd edition of Gelman’s Bayesian Data Analysis&lt;/a&gt; is being released soon, with contributions from David Dunson and Aki Vehtari.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I seem to be taking on a lot of work right now</title>
      <link>/./2012/11/12/i-seem-to-be-taking-on-a-lot-of-work-right-now/</link>
      <pubDate>Mon, 12 Nov 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/11/12/i-seem-to-be-taking-on-a-lot-of-work-right-now/</guid>
      <description>&lt;p&gt;For someone who’s meant to be finishing his PhD I sure do have a lot of other peoples’ papers on my plate. Today and Friday I had a chat with another PhD student from the UPTECH project about looking for spatial variation within the UPTECH schools. We’ve got some divergent ideas about how to go about it but we sat down this afternoon and spent some time going over regression modelling versus exploratory/summary statistics and how we can move from using Spearman’s rank correlation coefficient to doing non-parametric function estimation. I wrote some code and commented it as we went, so it should be fairly straightforward to write the accompanying methodology subsection for the paper. I’m going to spend the week focussing on my final thesis paper (a spatio-temporal model for data from a split panel design). I got some comments back from my supervisors last week and there’s a lot to be done checking certain sources of variation. I spent a fair bit of time today looking over a former students’ papers, checking old email threads, discussing a few things with the co-authors of his papers who are still around and have even been tracking down which particular instruments were used to perform the measurements. It’ll be important to check that my spatial analysis of the within-school variation matches up with the other UPTECH student’s analysis. If we come to opposite conclusions then at least one of us is wrong. I’m now tossing up whether I should check my results from the supercomputer or wait until tomorrow.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bayes on the Beach</title>
      <link>/./2012/11/08/bayes-on-the-beach/</link>
      <pubDate>Thu, 08 Nov 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/11/08/bayes-on-the-beach/</guid>
      <description>&lt;p&gt;I’ve spent the last three days at the Bayes on the Beach conference/workshop in &lt;a href=&#34;https://maps.google.com.au/maps?q=caloundra&amp;amp;hl=en&amp;amp;sll=-19.457034,145.879162&amp;amp;sspn=35.100111,39.506836&amp;amp;hnear=Caloundra+Queensland&amp;amp;t=m&amp;amp;z=14&amp;amp;iwloc=A&#34;&gt;Caloundra&lt;/a&gt;. The meeting is an annual event where Bayesian statisticians (usually Australians who know Kerrie Mengersen) get together for a very casual set of talks, workshops and other activities in a beachside town.&lt;/p&gt;
&lt;div id=&#34;design&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Design&lt;/h3&gt;
&lt;p&gt;We arrived in Caloundra on Tuesday morning and got down to business with a keynote talk from &lt;a href=&#34;http://www.southampton.ac.uk/maths/about/staff/davew.page&#34;&gt;Dave Woods&lt;/a&gt; (University of Southampton). Professor Woods’ talk opened a day in which the over-arching theme was experimental design and made the point that any design is at least implicitly Bayesian. I really agree with this point because any design is based on the prior experience of the experimenter or is pieced together from a review of what’s been done previously. I don’t know of any situation in which an experimental study was carried out totally at random without choosing appropriate covariate values. I don’t have much of a head for design but I think after seeing the talks on Tuesday (particularly Liz Ryan’s, which others in her session praised as giving a good review of utility) I’m a bit more aware of what it all means. What really helped was &lt;a href=&#34;http://pharmacy.otago.ac.nz/our-people/academic-staff/stephen-duffull&#34;&gt;Stephen Duffull&lt;/a&gt; (University of Otago) in his Thursday talk where he spelled out D-optimality (wanting to maximise the effect) and P-optimality (wanting to get the best estimate of parameters). D- and P-optimality work in opposite directions quite frequently (killing all your patients doesn’t tell you much about the parameters in your model, for example) but it’s possible to trade them off with a DP-optimal design.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;workshops&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Workshops&lt;/h3&gt;
&lt;p&gt;One of my favourite aspects of the Bayes on the Beach meetings is the workshops. At my first Bayes on the Beach (2009) we were shown how to do a Bayesian meta-analysis to combine the results of a bunch of disparate studies that dealt with the same topic. Ever since then, I’ve been looking forward to learning some more statistics or getting to grips with interesting data. &lt;a href=&#34;http://datasearch2.uts.edu.au/science/staff/maths/details.cfm?StaffID=11641&#34;&gt;Matt Wand&lt;/a&gt; (University of Technology Sydney), &lt;a href=&#34;http://data.aims.gov.au/staffcv/jsf/external/view.xhtml?partyId=900000428&#34;&gt;Julian Caley&lt;/a&gt; (Australian Institute of Marine Science) and &lt;a href=&#34;http://staff.qut.edu.au/staff/lowchoy/&#34;&gt;Sama Low Choy&lt;/a&gt; (Queensland University of Technology, my associate supervisor) each pitched a problem that people could have a look at, not necessarily solving but, working towards a solution. Wand presented some really interesting spatio-temporal data of extreme rainfall in NSW which I was very keen to sign up to but Kerrie suggested that it might be a bit more of a challenge to do something other than spatio-temporal modelling of environmental data. Sama presented some work that she’s been doing on combining elicited opinions into a subjective prior that represents the aggregate knowledge of experts. I ended up in Caley’s group, where we worked on some data that &lt;a href=&#34;http://scholar.google.com/citations?user=T-nbIuUAAAAJ&amp;amp;hl=en&#34;&gt;Julie Vercelloni&lt;/a&gt; is dealing with as part of her PhD.&lt;/p&gt;
&lt;div id=&#34;reef-workshop&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Reef workshop&lt;/h4&gt;
&lt;p&gt;Caley, Vercelloni and Mengersen (among others) are working on coral coverage in the Great Barrier Reef in six sectors that run up the length of the reef (2600km). Within each sector there are reef shelves and on each shelf there are multiple reefs with multiple measurement patches. The question we attempted to answer was “How different are the long term trends in coral coverage at these reefs?” Caley has data going back to about 1994, reported annually, which when pooled looked very boring but when plotted (very well by Vercelloni) grouped by reef shelf within sector indicated that there might be quite a lot of interesting variation which may not be so straight forward to model. Our group split up into a few subgroups with different approaches and I ended up working with James McKeone and a few others on a model inspired by &lt;a href=&#34;http://samclifford.info/2012/10/19/anova/&#34; title=&#34;ANOVA&#34;&gt;Cari Kaufmann’s functional ANOVA with GP priors&lt;/a&gt;. Over the next day or so McKeone took what we’d discussed and written down as a model and came up with quite a general Gibbs sampling scheme that is flexible enough to admit any linear predictor. I’m fairly certain James and I both had P-splines in mind but I did talk later to Matt Wand about O’Sullivan splines and I think it might be conceptually easier to use Wand’s low rank thin plate smoothers, particularly as Vercelloni’s quite new to Bayesian statistics and has a background in ecology rather than computational statistics. It was interesting to see how the other workshops went on the Thursday afternoon recap. Sama’s group had split into three groups, each tackling the issue of elicitation with a different topic and a different angle. I must say that my favourite was the group who did an elicitation of predictions of the outcome of the US Presidential Election. &lt;a href=&#34;http://conidialcoleopticide.wordpress.com/&#34;&gt;Luisa Hall&lt;/a&gt; even managed to elicit my opinion for her survey without me even realising it (we talk a lot about politics)! The other groups asked about how risky a life-saving operation would have to be for them to not take it and average completion time for PhD students (which Sama gave a talk about on Thursday).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;real-time-updates-for-mean-field-variational-bayes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Real time updates for Mean Field Variational Bayes&lt;/h3&gt;
&lt;p&gt;Matt Wand also gave a talk and tutorial about using Mean Field Variational Bayes (a name he attributes to Mike Jordan) to do live, real-time updates of posterior estimates with streamed data such as stock trading. Rather than going into the content of the talk, I suggest you read &lt;a href=&#34;http://www.uow.edu.au/~mwand/ovbpap.pdf&#34;&gt;the paper&lt;/a&gt; he’s written with Tamara Broderick (University of California, Berkeley) and his PhD student Jan Luts (University of Technology Sydney) and check out &lt;a href=&#34;http://realtime-semiparametric-regression.net/&#34;&gt;their website&lt;/a&gt; with neat examples, e.g. &lt;a href=&#34;http://realtime-semiparametric-regression.net/SydneyRealEstate/&#34;&gt;the Sydney rental market&lt;/a&gt; (which I think would be fascinating with the train lines superimposed).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;games-and-posters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Games and Posters&lt;/h3&gt;
&lt;p&gt;Tuesday and Wednesday evenings had Luisa and I running some games (&lt;a href=&#34;http://en.wikipedia.org/wiki/Fictionary&#34;&gt;Dictionary&lt;/a&gt; and &lt;a href=&#34;http://boardgamegeek.com/boardgame/38159/ultimate-werewolf-ultimate-edition&#34;&gt;Werewolf&lt;/a&gt;) before the poster sessions. It’s interesting running games like this with Bayesians because Dictionary is basically a problem of credibility of unknown experts and Werewolf is all about updating an initially uninformative prior with information based on peoples’ behaviour as they accuse others while trying to avoid being lynched. The poster sessions themselves were quite good, with a wide variety of applications and methodologies being presented. Everyone seemed quite keen to talk about their posters and they were generally of a high quality. On Thursday afternoon I gave my talk about spatio-temporal modelling of the UPTECH data as a case study for INLA. I got a few questions about the versatility of INLA and my choice of random walk and spline models instead of other bases as well as comments about the spatial modelling I’m doing. Definitely some things to think about for the next papers I write.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-success&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A success&lt;/h3&gt;
&lt;p&gt;The organisers of Bayes on the Beach (Nicole White, Matt Moores, Jannah Baker and Dow Jaemjamrat) all did a really good job and I think everyone had a good time but was also inspired. I had a few minor issues (timekeeping is a perpetual bugbear of mine and I’m yet to go to a conference that runs totally on schedule) but think that the meeting did a really good job of bringing together a disparate group of researchers and introducing them to each other and providing ideas for future work and employment opportunities (Kim-Anh Do did a really good job of selling the &lt;a href=&#34;http://www.mdanderson.org/&#34;&gt;MD Anderson Cancer Center&lt;/a&gt;). I think the challenge for future Bayes on the Beach meetings will be managing the growth in the number of attendees. I look forward to next year’s meeting; I might even have some time to go to the beach!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ANOVA</title>
      <link>/./2012/10/19/anova/</link>
      <pubDate>Fri, 19 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/19/anova/</guid>
      <description>&lt;p&gt;ANOVA is one of those things that all the scientists in my group do when writing a paper where there’s more than one group, which is totally natural and a good first step for data analysis. Whether it’s looking at the mean concentration of some aerosol at the UPTECH schools, the level of diesel engine emissions by fuel type or some other experimental setup, ANOVA will typically make it into a paper (even if only as a &lt;em&gt;t&lt;/em&gt; test). ANOVA (or a &lt;em&gt;t&lt;/em&gt; test) may not always be an appropriate test to use, e.g. if the data is not normal, has a few large outliers or exhibits some sort of reliance on a covariate. In such cases it may be better to use a regression model with a non-Gaussian likelihood. This week I’ve spent a bit of time getting to grips with the Mann-Whitney U test as a way of testing medians, another summary which is used for aerosol concentrations. It’s not featured in Excel, so the person I was helping had to dust off their SPSS skills and we eventually made our way through and figured out how to run the test. But descriptive statistics of quantiles or measures of central tendency aren’t nearly as exciting as something I’ve come across, functional ANOVA. I met Cari Kaufman at ISBA earlier this year and we had a bit of a chat about spatio-temporal models of climate data with Gaussian processes and Gaussian Markov Random Fields. When I got back to Brisbane I decided to have a look at what she’s written and whether I should think about applying to work with her at Berkeley. Kaufman has &lt;a href=&#34;http://ba.stat.cmu.edu/journal/2010/vol05/issue01/kaufman.pdf&#34;&gt;a 2010 paper&lt;/a&gt; [1], which appears to have its genesis &lt;a href=&#34;http://andrewgelman.com/2007/10/anova/&#34;&gt;at least as far back as 2007&lt;/a&gt;, where functional ANOVA is discussed as a way of testing whether some observed effect (which may be a nonlinear function) is the same across groups. The examples given include temperature records in Canada and spatio-temporal modelling of regional climate in the UK. I would like to go over the functional ANOVA paper with the QUT NP Bayes reading group, as it’s a very interesting use of the Gaussian process prior. I’d also like to use it in my own work, as the question “Is the daily trend the same at each school?” is of interest to me. [1] Cari G. Kaufman and Stephan R. Sain, “Bayesian Functional ANOVA Modeling Using Gaussian Process Prior Distributions”, &lt;em&gt;Bayesian Analysis&lt;/em&gt; 5, 2010, pages 123-150. [&lt;a href=&#34;http://ba.stat.cmu.edu/journal/2010/vol05/issue01/kaufman.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Research position with QUT&#39;s Applied Data Mining group</title>
      <link>/./2012/10/16/research-position-with-quts-applied-data-mining-group/</link>
      <pubDate>Tue, 16 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/16/research-position-with-quts-applied-data-mining-group/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;http://www.applieddatamining.info/&#34;&gt;Applied Data Mining group&lt;/a&gt; has an opening for a one year position as a research officer with the group, working on topics in data mining and machine learning (which appears to be a less rigorous Bayesian non-parametrics). So if you or someone you know is finishing a PhD in statistics, machine learning or computer science and knows how to do scientific computation/data mining for big data and wouldn’t mind working in lovely, subtropical Brisbane, Australia for a year, email &lt;a href=&#34;mailto:r.nayak@qut.edu.au&#34;&gt;Associate Professor Richi Nayak&lt;/a&gt; this week. Some selection criteria are under the cut. The successful application should have:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Completed the PhD (or nearly completed) with success as evidenced by publications in proceedings of important conferences and journals in the field of machine learning/ data mining;&lt;/li&gt;
&lt;li&gt;Acquired a profound knowledge and practical experience in machine learning, data mining and information retrieval; experience with Big Data is an advantage.&lt;/li&gt;
&lt;li&gt;Good programming skills (e.g., Java, C++, MATLAB, Python);&lt;/li&gt;
&lt;li&gt;Experience with data mining tools such as WEKA, SAS, MSQLServer;&lt;/li&gt;
&lt;li&gt;Excellent English language skills (written and spoken);&lt;/li&gt;
&lt;li&gt;Good communication skills especially for interacting with industry partners;&lt;/li&gt;
&lt;li&gt;The capability to work independently and in a team;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Starting more papers</title>
      <link>/./2012/07/17/starting-more-papers/</link>
      <pubDate>Tue, 17 Jul 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/07/17/starting-more-papers/</guid>
      <description>&lt;p&gt;One of the benefits of being a statistically curious researcher is that you get to read about all sorts of cool stuff. The UPTECH project is generating a huge amount of time series data, some of which have change points, non-linear behaviour, trends, and all sorts of other quirks. I’ve spent most of my time learning about the use of splines but over the last year have been exposed to Gaussian processes (and I guess I would say splines are a special case) and Gaussian Markov Random Fields. I’ve been having the occasional chat with the other researchers about how to analyse the time series data they’re working with and have stumbled across some really neat methods. Apart from the work I’ve been doing on spline models with my Finnish collaborators, interesting ideas for analysing time series data include Treed Linear Models, Treed Gaussian Processes [1,2] and Dirichlet Process Mixtures of GLMs [3]. The tree nature of the first two models I mentioned is apparent in its partitioning of the covariate space into regions in which the behaviour is locally linear. Change points are placed where the behaviour changes and each partition has its own linear mean and its own variance estimate. This is a fairly simple model to fit but it’s a bit limited by its only using linear functions. The treed GP relaxes this and spends its time fitting a more GP within each partition, with the focus on the covariance relationship. The third, DP mixtures of GLMs gives much smoother estimates of the mean and credible interval and has some really nice properties courtesy of the DP (which looks to be superior to tree based clustering). I find the tree structure of these models quite interesting and the treed linear model appears to be, conceptually, a mix of a multiple changepoint model and a piecewise linear regression spline with wombling knots. I’m not 100% sure how to apply these but an initial chat makes me think they will be very applicable and I’m looking forward to some exploratory data analysis. [1] [Gramacy, R. B. (2007). tgp: An r package for bayesian nonstationary, semiparametric nonlinear regression and design by treed gaussian process models. Journal of Statistical Software 19(9), 1-46.](&lt;a href=&#34;http://www.jstatsoft.org/v19/i09/&#34; class=&#34;uri&#34;&gt;http://www.jstatsoft.org/v19/i09/&lt;/a&gt;) [2] [Gramacy, R. B. and H. K. H. Lee (2008). Bayesian treed gaussian process models with an application to computer modeling. Journal of the American Statistical Association 103(483), 1119-1130.](&lt;a href=&#34;http://amstat.tandfonline.com/doi/abs/10.1198/016214508000000689&#34; class=&#34;uri&#34;&gt;http://amstat.tandfonline.com/doi/abs/10.1198/016214508000000689&lt;/a&gt;) (&lt;a href=&#34;http://arxiv.org/abs/0710.4536&#34;&gt;arXiv preprint&lt;/a&gt;) [3] [Hannah, L. A., D. M. Blei, and W. B. Powell (2011). Dirichlet process mixtures of generalized linear models. Journal of Machine Learning Research 12, 1923-1953.](&lt;a href=&#34;http://www.cs.princeton.edu/~blei/papers/HannahBleiPowell2011.pdf&#34; class=&#34;uri&#34;&gt;http://www.cs.princeton.edu/~blei/papers/HannahBleiPowell2011.pdf&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ISBA 2012 - A few thoughts</title>
      <link>/./2012/06/27/isba-2012---a-few-thoughts/</link>
      <pubDate>Wed, 27 Jun 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/06/27/isba-2012---a-few-thoughts/</guid>
      <description>&lt;p&gt;Christian Robert asked for some guest bloggers for ISBA 2012 and &lt;a href=&#34;http://xianblog.wordpress.com/2012/06/27/isba-2012-guest-post/&#34;&gt;today his ’og features my thoughts&lt;/a&gt; as of this morning’s coffee break. There have been some really amazing talks in the sessions I’ve gone to, mostly in the NP Bayes talks. My poster went well, I had a good discussion with Daniel Williamson about some of the shortfalls of P-spline models when smoothing temporal data. Hopefully I convinced him that my use of AR residuals means I’m not modelling noise with a highly oscillatory spline. I don’t think I can convince him of the validity of using an informative Gamma(1,b) prior for the smoothing parameter as he’s quite firmly in the subjective priors camp. Perhaps he and Sama should have a meeting. I still haven’t been able to find Jukka Corander, he didn’t seem to be at the poster session where three of his students were presenting. Perhaps I just haven’t spotted him because we’ve only met once before and that was a year ago.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ad hoc collaboration</title>
      <link>/./2012/06/05/ad-hoc-collaboration/</link>
      <pubDate>Tue, 05 Jun 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/06/05/ad-hoc-collaboration/</guid>
      <description>&lt;p&gt;Rbloggers have &lt;a href=&#34;http://www.r-bloggers.com/announcing-rpubs-a-new-web-publishing-service-for-r/&#34;&gt;announced the launch&lt;/a&gt; of &lt;a href=&#34;http://www.rpubs.com/&#34;&gt;RPubs&lt;/a&gt;, a free service which makes it easy to publish code and analysis on the web. It’s based on RStudio and the markdown package and looks like a great way for people to show analysis to co-workers who might not have R on their computers when you don’t feel like writing a report. I really like this idea and might end up using it in my office to show what we can do with statistics. Another thing I’ve been thinking about is the potential to use an Apple TV and its &lt;a href=&#34;http://www.apple.com/au/appletv/airplay/&#34;&gt;screen sharing&lt;/a&gt; capabilities to do presentation work from iPhones, iPads and Mac computers. A lot of people in my office have iPhones, so an Apple TV hooked up to a HDMI screen (surely universities just leave these lying around) might be a good way to get a group of people to take some notes or share prepared slides with a small room of people. For example, if people had a PDF version of slides on their iPhones they could take control of the Apple TV and use their iPhone to flick through the slides, allowing everyone to stay in their seats and control the slideshow from their own device. I was excited by Google Wave when it first launched, as it combined a lot of what I liked about Gmail, Google Docs and Google Chat with an extension system, making it an incredibly powerful and flexible platform for collaborative work. Unfortunately it was released prematurely and died off after a flurry of uptake. Google Plus doesn’t really make up for it, either. I really liked the idea of collaboratively writing a document and being able to add in a voting gadget to resolve whether a section should be included. I used it socially to determine the dates of picnics with friends, which was probably where most of my use was directed. Probably the best example of how useful I found it was in writing a manual of procedures with about ten other volunteers who would ask questions. As we answered the questions, we folded the answers into the main part of the document. This was much more useful than writing a static document and then having a separate email list for discussion, or using track changes in Microsoft Word to email around a huge document that kept on growing. I have high hopes for the internet in terms of &lt;em&gt;ad hoc&lt;/em&gt; collaboration, particularly academic collaboration. I find &lt;a href=&#34;http://github.com/&#34;&gt;GitHub&lt;/a&gt; really exciting because it allows me to work on a private project and then add a collaborator when they come on board. Once a project is finished and the paper published, that private repository can be made public and anyone can fork it and do with it what they will. If they’re intrigued by what’s been done, they could contact me and discuss what they’ve done and we can build a new project based on their fork of my work. With so much of my work being based on R or MATLAB and written up in LaTeX, I find this potential way of working quite sensible. Add in the fact that GitHub gives you a wiki system for each project and you’ve got a great tool at your disposal. A somewhat &lt;em&gt;ad hoc&lt;/em&gt; collaborative tool that I organised is the &lt;a href=&#34;https://wiki.qut.edu.au/display/npbayes/Home&#34;&gt;wiki for QUT’s Bayesian Non-parametrics reading group&lt;/a&gt;. This is a repository for the collective work of the group, including Q&amp;amp;A on the papers we’re reading, notes from the meetings, a list of papers read, code chunks, links to videos explaining what we’re working on, etc. It’s been a really useful tool and I’d hope that others interested in the same work could use it as a resource for their own learning. There’s a lot of really cool stuff out there. It’s a matter of finding useful tools that don’t have particularly high barriers to entry and allow non-experts to view expertly produced material (like on RPubs). The longer it’s been since one was a student, the less likely one seems to be to adopt new workflow practices. I’ve suggested git to my supervisors as a good way for our groups to work but I have a feeling that none of them are interested enough in distributed version control to put the effort in to learning how to use them. So for now it’s annotated PDFs or printed pages with scribbles on them rather than making the edits to a LaTeX source file and committing and pushing their changes to a shared repository.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bioaerosols</title>
      <link>/./2012/05/17/bioaerosols/</link>
      <pubDate>Thu, 17 May 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/05/17/bioaerosols/</guid>
      <description>&lt;p&gt;One of our researchers asked me to come along to a meeting next week to discuss my potential involvement on a paper as “the statistician”. It’s part of the UPTECH project but it’s not the spatial distribution of outdoor aerosols, which is what I’ve been working on for my PhD. &lt;a href=&#34;http://www.uku.fi/vaitokset/2009/ISBN978.951.802.908.6salonen.htm&#34;&gt;Heidi Salonen&lt;/a&gt;, a visiting researcher from Finland, is working on UPTECH looking at the concentration of microbiological agents in indoor air. Luckily I don’t have to be &lt;a href=&#34;http://en.wikipedia.org/wiki/Egon_Spengler&#34;&gt;an expert on spores, moulds and fungus&lt;/a&gt; but it’ll be interesting to pick up a bit more knowledge from the quite broad field of aerosols. I’ve been asked a few times to be involved with some ILAQH projects but at the moment it’s been limited to helping write the statistical methodology for grant applications or discussing an approach for data from another part of the UPTECH project. As far as I recall, this is the first time that someone from ILAQH has come and said “Hey, I want you to be a co-author on this paper”. This sort of thing is what I’ve been looking forward to as I finish off my PhD, the chance to get out of my specific topic and start looking at other peoples’ work. I’ll probably try to recommend a non-parametric regression technique but I have a feeling it’ll be a classically designed experiment and that all we’ll need is some t-tests.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ISBA update - logistics</title>
      <link>/./2012/05/10/isba-update---logistics/</link>
      <pubDate>Thu, 10 May 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/05/10/isba-update---logistics/</guid>
      <description>&lt;p&gt;This morning I booked my flights to Osaka ($670 return, a very good deal) and am in the process of organising accommodation with &lt;a href=&#34;http://www.stat.berkeley.edu/~tab/&#34;&gt;Tamara Broderick&lt;/a&gt;. I’m getting excited about catching up with the various people that I met at the BNP conference last year and it’s even more exciting to see their names on the list of people giving talks. Tamara will be talking about Beta processes and Sergio Bacallado is giving a talk alongside Sonia Petrone and Yee Whye Teh, two of the big names in Bayesian non-parametrics. A few QUT people are talking as well. Nicole White and Susanna Cramb will be talking about spatio-temporal disease modelling. One of my supervisors, Sama Low Choy, will be talking about combining subjective priors (expert elicitation) and another, Kerrie Mengersen, is organising that session and co-author on a few papers that are being presented by people in her BRAG group, as well as posters (such as mine). I’m also looking forward to seeing presentations on INLA, spatial modelling, non-parametric estimation and environmental modelling.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A mostly Fin(n)ish[ed] paper</title>
      <link>/./2012/05/09/a-mostly-finnished-paper/</link>
      <pubDate>Wed, 09 May 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/05/09/a-mostly-finnished-paper/</guid>
      <description>&lt;p&gt;The paper I started with some collaborators in Finland (&lt;a href=&#34;https://tuhat.halvi.helsinki.fi/portal/en/persons/bjarke-moelgaard(74a8081d-a379-4e4b-9aff-e9b85bc98c78)/publications.html&#34;&gt;Bjarke Mølgaard&lt;/a&gt;, &lt;a href=&#34;http://www.rni.helsinki.fi/~jic/&#34;&gt;Jukka Corander&lt;/a&gt;, &lt;a href=&#34;http://www.atm.helsinki.fi/~khameri/&#34;&gt;Kaarle Hämeri&lt;/a&gt;, &lt;a href=&#34;https://tuhat.halvi.helsinki.fi/portal/en/persons/tareq-hussein(3aacf8e7-f431-41b0-9303-1abaf1897bf7)/publications.html?page=5&amp;amp;rendering=vancouver&#34;&gt;Tareq Hussein&lt;/a&gt;) almost a year ago is nearly done. It’s been nearly done a few times, but now all that remains is to do a little bit of model choice regarding the separability of the effects of meteorology on ultrafine particle number concentration. We’ve been using git to send the paper and code back and forth (well, Bjarke and I have) and I’ve found that to be a really simple way of collaboratively writing code and a paper. To see the changes made, one need only look at the commit details. Much nicer than using tracked changes in Word and emailing a bunch of versions of the same file back and forth and trying to do complicated merges of changes. I am really looking forward to submitting this paper, as it’s probably the most methodological work I’ll get out of my PhD (the other papers are largely applications of some novel techniques to the UPTECH project’s data). It’s quite a nice blending of the &lt;a href=&#34;https://tuhat.halvi.helsinki.fi/portal/en/publications/forecasting-sizefra(9c6ae07d-af34-4909-a4f9-d758bc7a4795).html&#34;&gt;work done by the Finnish authors previously&lt;/a&gt; [1] as part of Bjarke’s PhD and some of the ideas in my first paper [2]. While I don’t know that it will totally revolutionise atmospheric modelling (in the way that I’m sure we all hope it will), it’s quite a nice technique that increases the flexibility of the Generalised Additive Model and hopefully encourage anyone interested in doing Bayesian modelling with the GAM to stop using &lt;a href=&#34;http://www.uow.edu.au/~mwand/&#34;&gt;Matt Wand&lt;/a&gt;’s WinBUGS approach [3, 4]. To be clear, I find GAMs in WinBUGS particularly cumbersome to code given that WinBUGS doesn’t deal with matrix operations very well and the use of P-splines requires a lot of matrix operations. Having said that, though, Wand’s code is a nice intro to Bayesian splines where you don’t have to write your own MCMC sampler. I just think it has some limitations that are not easily overcome. I’d like to present this to a statistics conference but it wasn’t anywhere near ready enough to demonstrate at ISBA 2012 when I was submitting an abstract. [1] B. Mølgaard, T. Hussein, J. Corander, K. Hämeri, Forecasting size-fractionated particle number concentrations in the urban atmosphere, Atmospheric Environment, Volume 46, January 2012, Pages 155-163, ISSN 1352-2310, 10.1016/j.atmosenv.2011.10.004. &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1352231011010491&#34;&gt;ScienceDirect&lt;/a&gt; [2] S. Clifford, S. Low Choy, T. Hussein, K. Mengersen, L. Morawska, Using the Generalised Additive Model to model the particle number count of ultrafine particles, Atmospheric Environment, Volume 45, Issue 32, October 2011, Pages 5934-5945, ISSN 1352-2310, 10.1016/j.atmosenv.2011.05.004. &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1352231011004766&#34;&gt;ScienceDirect&lt;/a&gt; [3] C. M. Crainiceanu, D. Ruppert. M. P. Wand, Bayesian Analysis for Penalized Spline Regression Using WinBUGS, &lt;a href=&#34;http://www.jstatsoft.org/v14/i14/&#34;&gt;Journal of Statistical Software, Volume 14, Issue 14, September 2005&lt;/a&gt;. [4] J. K. Marley, M. P. Wand, Non-Standard Semiparametric Regression via BRugs, &lt;a href=&#34;http://www.jstatsoft.org/v37/i05&#34;&gt;Journal of Statistical Software, Volume 37, Issue 5, November 2010&lt;/a&gt;. P.S. I apologise for the awful pun, but &lt;a href=&#34;http://en.wikipedia.org/wiki/The_Micallef_P(r)ogram(me)&#34;&gt;Shaun Micallef&lt;/a&gt; has been on my mind recently.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Indian Buffet process - I&#39;m full</title>
      <link>/./2012/04/06/indian-buffet-process---im-full/</link>
      <pubDate>Fri, 06 Apr 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/04/06/indian-buffet-process---im-full/</guid>
      <description>&lt;p&gt;My little NP Bayes reading group finally finished with the &lt;a href=&#34;http://samclifford.info/2012/03/28/indian-buffet-process/&#34;&gt;IBP&lt;/a&gt; paper &lt;a href=&#34;https://wiki.qut.edu.au/display/npbayes/2012/04/04/Week+12+Summary&#34;&gt;this week&lt;/a&gt;, having spent five weeks going over it. It’s quite a neat paper which introduces some very interesting approaches to latent feature modelling, such as generating binary matrices which are explicitly in a certain form and using combinatorics to figure out how many other matrices can be reordered into that form. Another neat mathematical trick is the use of the Sherman-Morrison formula to update the inverse of Z’Z (part of the posterior covariance). Each row of Z represents an observation’s latent feature presence and absence. The exchangeable IBP allows us to reorder the observations however we want, so we can sequentially sample rows in Z and then perform the rank one update, rather than block sampling (regenerating the entire Z matrix) and computing the inverse of quite a dense matrix. It turns out that inference for infinite binary matrices can be performed by considering the finite case and recognising that the infinitely many zero columns won’t contribute to the posterior. The example they give, image analysis, is quite effective in illustrating the use of the IBP. One of us suggested that we could spend the next few weeks coding up the Metropolis within Gibbs MCMC sampler and applying it to Fisher’s iris data. We’ve looked at the iris data with the DP for allocating flowers to clusters but perhaps some latent feature analysis will better unearth the underlying species.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Indian Buffet process</title>
      <link>/./2012/03/28/indian-buffet-process/</link>
      <pubDate>Wed, 28 Mar 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/03/28/indian-buffet-process/</guid>
      <description>&lt;p&gt;The NP Bayes reading group that I started is currently working through Griffiths and Ghahramani’s paper on the Indian Buffet process [1], an infinite latent feature model which is used in topic modelling, document clustering, pattern recognition, etc. It’s been pretty hard going because QUT doesn’t teach a lot of combinatorics and we’ve had some patchy attendance recently so we’ve had to go over things a few times (especially the Chinese Restaurant process, the left-ordering function). It’s been a very interesting paper and I am looking forward to the possibility of using it with some survey data. No doubt I’ll get a better understanding of it when I head to ISBA later in the year (&lt;a href=&#34;http://www2.e.u-tokyo.ac.jp/~isba2012/stsessions.html&#34;&gt;Nils Hjort has organised a session&lt;/a&gt; on Beta processes that will include talks from Yongdai Kim, Tamara Broderick and Sinead Williamson). If you’re interested in reading about it, we’ve been making notes on our Wiki. You can start from &lt;a href=&#34;https://wiki.qut.edu.au/display/npbayes/2012/03/&#34;&gt;here&lt;/a&gt; as it’s taken us all of this month so far. I’ve written some code snippets to do some of the things the paper mentions. [1] [Griffiths, T. L., and Ghahramani, Z. “Infinite Latent Feature Models and the Indian Buffet Process”, &lt;em&gt;Advances in Neural Information Processing Systems&lt;/em&gt;, 2005, &lt;strong&gt;18&lt;/strong&gt;, 475-82](&lt;a href=&#34;http://cocosci.berkeley.edu/tom/papers/ibptr.pdf&#34; class=&#34;uri&#34;&gt;http://cocosci.berkeley.edu/tom/papers/ibptr.pdf&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Julian Caley</title>
      <link>/./2012/03/16/julian-caley/</link>
      <pubDate>Fri, 16 Mar 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/03/16/julian-caley/</guid>
      <description>&lt;p&gt;I went to quite an interesting talk this afternoon by &lt;a href=&#34;http://data.aims.gov.au/staffcv/jsf/external/view.jspx;jsessionid=BC0E61EB624F8D24FAE7FCD8F225C067?partyId=900000428&#34;&gt;Dr Julian Caley from the Australian Institute of Marine Science&lt;/a&gt;. Julian’s visiting us at QUT for a few weeks and presented some interesting work he and his colleagues have done on estimating marine biodiversity (they estimate somewhere between 500,000 and 2,000,000 species) and the statistical and ecological issues faced. At least one QUT Bayesian Statistics PhD graduate has ended up at AIMS, &lt;a href=&#34;http://www.esajournals.org/doi/abs/10.1890/07-1886.1&#34;&gt;Dr Rebecca O’Leary&lt;/a&gt;. Some of the work members of BRAG have done with AIMS involve expert elicitation around the issues of fish population but Julian said today that fish and coral populations, commonly used as a proxy for biodiversity, only account for about 2% of the total species in marine environments. Some of the expert elicitation involves not only quantifying the named species and the discovered but unnamed species but quantifying the prevalence of undiscovered species. Apparently the place to be working isn’t in fish and coral species (which are already well known and quite easy to study) but in &lt;a href=&#34;http://en.wikipedia.org/wiki/Nematode&#34;&gt;nematodes&lt;/a&gt; and &lt;a href=&#34;http://en.wikipedia.org/wiki/Isopods&#34;&gt;isopods&lt;/a&gt; which are expected to have many undiscovered species. Julian talked about some very interesting ways of estimating the prevalence of unobserved species by looking at which Orders are present (higher level taxa) that cover the species you’re interested in, which other species in the same taxa are prevalent (cross-taxa) or which species are present in the genus you’re interested in (subset taxa). Not having a huge amount of experience in classification and regression trees I wasn’t entirely sure about how one would go about working through these various methods but I could see it being quite an interesting way of estimating biodiversity and quantifying the uncertainty. After Julian’s talk and some afternoon tea a few members of BRAG stayed back to do a brief workshop on the statistical issues in ecology and to try to match up which methods we’re good at with what the problems in marine ecology are, in an effort to stimulate some work that could be started while Julian visits us. I’m sure there’s also a lot of spatial modelling and NP Bayes to be done with the data that AIMS has available to them, so I’ll have to keep an eye out on positions they have going.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Non-parametrics reading group</title>
      <link>/./2012/03/01/non-parametrics-reading-group/</link>
      <pubDate>Thu, 01 Mar 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/03/01/non-parametrics-reading-group/</guid>
      <description>&lt;p&gt;At the &lt;a href=&#34;http://bnpworkshop.org/&#34;&gt;8th Bayesian Non-parametrics workshop&lt;/a&gt; in Veracruz, Mexico, last year I met a very enthusiastic grad student from UC Berkeley, &lt;a href=&#34;http://www.stat.berkeley.edu/~tab/&#34;&gt;Tamara Broderick&lt;/a&gt;. I spent a lot of time hanging out with Tamara and a bunch of the other PhD students attending the conference and I got to know about the reading group that she’d set up within the UC Berkeley Statistics Graduate Student Association (of which she is co-president). Tam’s reading group, “Classics of NP Bayes”, are working their way through a lot of the foundational papers of Bayesian non-parametric statistics, the papers that are always cited but seldom read. Inspired by this and hungry for more knowledge about NP Bayes (my only real experience at the time being semi-parametric regression with splines) I asked around the Bayesian stats group at QUT if anyone was interested in setting up a similar group here. In August 2011 the QUT NP Bayes reading group held its first meeting to decide a structure, meeting frequency, and discuss what kind of papers we wanted to read. Six or seven months later we have made our way through a number of papers, theoretical and applied, and learned quite a lot along the way. This morning I will be giving a presentation to the Bayesian stats group about our progress and writing the slides has really made me realise just how far we’ve all come together. Our little group consists mostly of PhD students, with backgrounds as varied as applied stats, computational maths, econometrics, environmental statistics, computer science, and we now have an electrical engineer from outside the School of Mathematics joining us to get more of a background in the techniques he’s using (Latent Dirichlet Allocation and Hierarchical Dirichlet Processes). We’ve covered measure theory, the Poisson process (as a completely random measure), the Dirichlet process, infinite mixture models and density estimation, the Polya urn formulation of the DP, MCMC methods for DP models, the Gaussian process and its relationship with GMRFs, non-parametric covariance regression and will spend our next few meetings on the Chinese Restaurant and Indian Buffet processes. I’m really glad with the way things have turned out, and if you’re interested in reading more about the topics we’ve covered you can check out the &lt;a href=&#34;http://samcliffordinfo.files.wordpress.com/2012/03/npbayes.pdf&#34;&gt;NP Bayes review slides&lt;/a&gt; or our &lt;a href=&#34;https://wiki.qut.edu.au/display/npbayes/Home&#34;&gt;wiki&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
