<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Visualisation on Sam Clifford </title>
    <link>/./tags/visualisation/</link>
    <language>en-us</language>
    <author>Alexander Ivanov</author>
    <updated>2014-10-17 00:00:00 &#43;0000 UTC</updated>
    
    <item>
      <title>posterior samples</title>
      <link>/./2014/10/17/posterior-samples/</link>
      <pubDate>Fri, 17 Oct 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/10/17/posterior-samples/</guid>
      <description>&lt;p&gt;I probably should have put this post up earlier because it’s now a huge collection of stuff from the last month. Here we go! It appears that &lt;a href=&#34;http://hilaryparker.com/2012/08/16/the-setup-part-1/&#34;&gt;Hilary Parker&lt;/a&gt; and I have similar (but by no means identical) work setups for doing stats (or at least we did two years ago). It’s never too late to come up with a sensible way of organising your work and collection of references/downloaded papers. Applied statisticians should probably &lt;a href=&#34;http://simplystatistics.org/2014/09/15/applied-statisticians-people-want-to-learn-what-we-do-lets-teach-them/&#34;&gt;teach scientists what it is we do&lt;/a&gt;, rather than just the mathematics behind statistics. This is a difference I’ve noticed between SEB113 and more traditional statistics classes; we spend a lot less time discussion F distributions and a lot more time on model development and visualisation. Speaking of visualisation, here’s a really great article on visualisation and how we can use small multiples and colour, shape, etc. to highlight the interesting differences so that it’s very clear what our message is. Jeff Leek has compiled &lt;a href=&#34;http://simplystatistics.org/2014/09/09/a-non-comprehensive-list-of-awesome-female-data-people-on-twitter/&#34;&gt;a list of some of the most awesome data people&lt;/a&gt; on Twitter who happen to be female. In the ongoing crusade against abuse of p-values, &lt;a href=&#34;http://simplystatistics.org/2014/09/30/you-think-p-values-are-bad-i-say-show-me-the-data/&#34;&gt;we may want to instead focus on reproducibility&lt;/a&gt; to show that our results say what we say they do. Andrew Gelman and Eric Loken have &lt;a href=&#34;http://www.americanscientist.org/issues/feature/2014/6/the-statistical-crisis-in-science/99999&#34;&gt;an article in The American Statistician&lt;/a&gt; reminding us that p-values have a context and we need to be aware of issues like sample size, p-hacking, multiple comparisons, etc.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior Samples</title>
      <link>/./2014/07/30/posterior-samples/</link>
      <pubDate>Wed, 30 Jul 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/07/30/posterior-samples/</guid>
      <description>&lt;p&gt;Interested in collaborative use of R, MATLAB, etc. for analysis and visualisation within a webpage? &lt;a href=&#34;http://nbviewer.ipython.org/gist/msund/403910de45e282d658fa&#34;&gt;Combining plotly and iPython&lt;/a&gt; can help you with that. Cosmopolitan (yes, &lt;em&gt;that&lt;/em&gt; Cosmopolitan) has &lt;a href=&#34;http://www.cosmopolitan.com/career/news/a29534/get-that-life-emily-graslie-science/&#34;&gt;a great article&lt;/a&gt; interviewing Emily Graslie, Chief Curiosity Officer at the Field Museum in Chicago. She discusses being an artist and making the transition into science, science education and YouTube stardom. A few of the PhD students in my lab have asked if I could run an introduction to R session. I’d mentioned the CAR workshop that I’d be doing but the cost had put them off. Luckily, there are alternatives like &lt;a href=&#34;https://www.datacamp.com/courses/introduction-to-r&#34;&gt;Datacamp&lt;/a&gt;, &lt;a href=&#34;https://www.coursera.org/&#34;&gt;Coursera&lt;/a&gt; and &lt;a href=&#34;http://www.lynda.com/R-tutorials/R-Statistics-Essential-Training/142447-2.html&#34;&gt;Lynda&lt;/a&gt;. Coursera’s next round of “Data Science”, delivered by Johns Hopkins University, starts next Monday (Course 1 - &lt;a href=&#34;https://www.coursera.org/specialization/jhudatascience/1&#34;&gt;R Programming&lt;/a&gt;). So get in there and learn some R! I’m considering recommending some of these Coursera courses to my current SEB113 students who want to go a bit further with R, but the approach that they take in these online modules is quite different to what we do in SEB113 and I don’t want them to confuse themselves.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2014/07/02/posterior-samples/</link>
      <pubDate>Wed, 02 Jul 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/07/02/posterior-samples/</guid>
      <description>&lt;p&gt;ARC Discovery Projects have been returned to their authors, and we are putting our responses together for the rejoinders. Interesting to see that we got a comment suggesting that we use the less restrictive CC-by instead of CC-by-nc-sa as we’d suggested. We weren’t successful in our Linkage Project applications, which is disappointing as they were interesting projects (well, we thought so). Continuing to bring research funding in is an ongoing struggle for all research groups and I feel it’s only going to get harder as the new federal government’s research priorities appear to be more aligned to medical science that delivers treatments than to our group’s traditional strengths. SEB113 is pretty much completely over for the semester, with marks having been entered for almost every student. Overall I think the students did fairly well. We had some issues with the timetable this semester. Ideally, we’d like the Lecture, then all of the computer labs, then all of the workshops, so that we can introduce a statistical idea, show the code and then apply the idea and code in a group setting. Next semester, we have the lecture followed immediately by the workshops with the computer labs dotted throughout the remainder of the week. This has provided us with an opportunity to try some semi-flipped classroom ideas, where students are able/expected to do the computer lab at home at their own pace rather than watch a tutor explain it one line at a time at the front of a computer lab. I’m teaching part of a &lt;a href=&#34;http://www.eventbrite.com.au/e/r-statistical-language-for-air-pollution-epidemiology-tickets-12043581677&#34;&gt;two day course&lt;/a&gt; on the use of R in air pollution epidemiology. My part will introduce Bayesian statistics with a brief overview, a discussion about prior distributions as a means of encoding &lt;em&gt;a priori&lt;/em&gt; beliefs about model parameters, and discuss the use of Bayesian hierarchical modelling (as opposed to more traditional ANOVA techniques) as a way of making the most of the data that’s been collected. The other two presenters are &lt;a href=&#34;http://researchers.uq.edu.au/researcher/2181&#34;&gt;Dr Peter Baker&lt;/a&gt; and &lt;a href=&#34;http://researchers.uq.edu.au/researcher/2530&#34;&gt;Dr Yuming Guo&lt;/a&gt;. The course is being run by the CAR-CRE, who partially fund my postdoctoral fellowship. I had meant to post this back when they were doing the rounds, but there’s &lt;a href=&#34;http://www.tylervigen.com/&#34;&gt;a bunch of plots&lt;/a&gt; that attempt to show that correlation isn’t causation and that spurious correlations exist in large data sets. &lt;a href=&#34;https://tom-christie.github.io/articles/correlation/&#34;&gt;Tom Christie has responded&lt;/a&gt; to this by going over the fact that correlation in time series isn’t as simple as in the case of independent, identically distributed data. One should be careful that one’s criticism of bad statistics is itself founded on good statistics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The ongoing crusade against Excel-based analysis</title>
      <link>/./2014/05/14/the-ongoing-crusade-against-excel-based-analysis/</link>
      <pubDate>Wed, 14 May 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/05/14/the-ongoing-crusade-against-excel-based-analysis/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;line-height:1.714285714;font-size:1rem;&#34;&gt;One of the things I catch myself saying quite often in SEB113 is “This is new. It’s hard. But remember, you weren’t born knowing how to walk. You learned it”, as my way of saying that it’s okay to not understand this straight away, it takes time, practice and determination. I often say this in response to students complaining about learning R to do their data analysis. It’s actually got to the point where t&lt;/span&gt;&lt;span style=&#34;line-height:1.714285714;font-size:1rem;&#34;&gt;he unit co-ordinator suggested I get a t-shirt printed with “You weren’t born knowing how to walk” on the front and “So learn R” on the back.&lt;/span&gt; One of the reasons I’m so keen to push new students into learning R is that while Excel can do some of the simpler calculations required in the first year of a science degree it is often completely inadequate for doing data analysis as a professional scientist, or even in an advanced level university course. I actually saw a senior researcher in a 3 day Bayesian statistics course try to avoid using R to code a Gibbs sampler by getting it up and running in Excel. They managed it, but it took minutes to run what the rest of us could compute in a second (and it was for a trivially simple problem). There are &lt;a href=&#34;http://www.asq904.org/StatisticalFlawsInExcel.pdf&#34;&gt;problems with Excel&lt;/a&gt;, such as its inability to deal with the standard deviation of a group of very large numbers due to its bizarre formulation. Apparently the secret to sane use of Excel is to &lt;a href=&#34;http://www.r-bloggers.com/excel-fanaticism-and-r/&#34;&gt;only use it for data storage&lt;/a&gt;. This guiding principle has meant that I no longer manipulate my data in Excel. Even with time stamp information I’ll fire up the &lt;a href=&#34;http://cran.r-project.org/web/packages/lubridate/index.html&#34;&gt;lubridate&lt;/a&gt; package to convert from one format to another. I’m slowly exploring the &lt;a href=&#34;http://blog.datascienceretreat.com/&#34;&gt;Hadleyverse&lt;/a&gt; and that sort of approach is filtering through into SEB113 where we’re teaching the use of ggplot2 and reshape2 within RStudio. These are all powerful tools that simplify data analysis and avoid the hackish feel that much Excel-based analysis has, where pivot tables are a thing and graphs are made by clicking and dragging a selection tool down the data (which can lead to &lt;a href=&#34;http://en.wikipedia.org/wiki/Growth_in_a_Time_of_Debt&#34;&gt;some nasty errors&lt;/a&gt;). The fact that these powerful tools that make data analysis simple are free is another reason to choose R over Excel. I’m not on the “Open Source Software and provision of all code is mandatory” bandwagon as others seem to be when it comes to analysis being replicable. I agree it’s a worthwhile goal but it’s not a priority for me. That said, though, I definitely support encouraging the use of free software (in both senses) in education on the grounds of equity of access. I had a chat with some students in SEB113 yesterday about why we’re teaching everything in R given that the SEB114 staff use a combination of Excel, MATLAB (and maybe even other packages I don’t know about). If we were to teach analysis the way that the SEB114 lecturers do it themselves, we’d have to teach multiple packages to multiple disciplines. Even discounting the fact that everything we teach is implemented in R, that R is free (unlike Excel and MATLAB), cross-platform (Excel on Linux? Try OpenOffice/OfficeLibre) and extensible (MATLAB has toolboxes, Excel has add-ins, R has a nice package manager) was a big plus for students who said that being able to work on assignments at home was valuable and so paying for software would make study difficult. Convincing students to use R can be difficult, especially if they have no programming background, but ultimately they seem to accept that R is powerful, can do more than Excel and that writing reusable code makes future analysis easier. Convincing SEB114 academics that teaching their students to use R is a good idea is probably a harder sell, given that they’ve got years of experience with other tools. It’s still only semester 3 of the new Bachelor of Science course so we’ll have to see how this plays out over the years to come.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2014/04/26/posterior-samples/</link>
      <pubDate>Sat, 26 Apr 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/04/26/posterior-samples/</guid>
      <description>&lt;p&gt;I’m teaching science students how to do statistics. It would be great if we could turn them into Bayesians, especially seeing as we’ve just covered the Agresti-Coull correction for estimating proportions from small experiments. &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/teachingbayes.pdf&#34;&gt;Andrew Gelman has an interesting paper&lt;/a&gt; on teaching Bayesian statistics to non-statisticians that focuses on the delivery of skills rather than concepts. I would definitely agree with his approach, especially when you consider how he stresses that discussing the model is probably the most important part. NASA have done some work simulating global aerosols and it’s been compiled into &lt;a href=&#34;http://www.itsokaytobesmart.com/post/82630633966/one-of-my-favorite-gifs-of-one-of-my-favorite-nasa&#34;&gt;a neat video&lt;/a&gt; (via &lt;a href=&#34;http://www.itsokaytobesmart.com/&#34;&gt;It’s Okay To Be Smart’s Joe Hanson&lt;/a&gt;). CSIRO have been doing some interesting stuff looking at the production of organic aerosols as well, so this is something I’m paying a bit more attention to at the moment. &lt;a href=&#34;https://www.datacamp.com/&#34;&gt;Datacamp&lt;/a&gt; is a set of online labs for learning to use R, covering the basics of R, data analysis and statistical inference, and computational finance and econometrics. &lt;a href=&#34;https://medium.com/of-games-and-code/d90a50c5d58e&#34;&gt;Learn to be a better coder&lt;/a&gt; by improving your communication skills. The most practical (in terms of coding, at least) aspect of this includes using meaningful names and writing comments that describe what the code does when it’s not clear from the code itself.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2014/03/05/posterior-samples/</link>
      <pubDate>Wed, 05 Mar 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/03/05/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.ntnu.edu/&#34;&gt;NTNU&lt;/a&gt; in Trondheim, Norway, has &lt;a href=&#34;https://sites.google.com/a/r-inla.org/www/events/openphd-grants&#34;&gt;five PhD fellowships&lt;/a&gt; open. Visualising homicide rates in Mexico &lt;a href=&#34;http://lcolladotor.github.io/2014/02/26/excited-by-willingness-to-help-get-things-done/&#34;&gt;using R and GitHub&lt;/a&gt; (via &lt;a href=&#34;http://www.statisticsblog.com/2014/03/the-week-in-stats-mar-3rd-edition/&#34;&gt;Probability and Statistics Blog&lt;/a&gt;). If you’re in Melbourne, Australia, you should consider popping along to &lt;a href=&#34;http://thelaborastory.com/&#34;&gt;Laborastory&lt;/a&gt; at the Cider House (Brunswick), where five scientists get up on the first Tuesday of the month to tell the stories of the heroes and history of their field. A friend of mine went along this week and enjoyed it immensely. SEB113 has started again. I’ve already done 5 workshops (I have three a week). Introducing a whole new cohort of students to R, RStudio and ggplot. We did some paper plane throwing last week and had a look at how simple usage of faceting, colouring and stacking histograms can reveal both overall variation and group-to-group variation. A few students are still bewildered by the idea of writing code to make pictures but they recognise that it’s just a case of needing practice.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior Samples</title>
      <link>/./2013/12/02/posterior-samples/</link>
      <pubDate>Mon, 02 Dec 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/12/02/posterior-samples/</guid>
      <description>&lt;p&gt;Thiago Martins has posted &lt;a href=&#34;http://tgmstat.wordpress.com/2013/11/28/computing-and-visualizing-pca-in-r/&#34;&gt;a neat little tutorial&lt;/a&gt; about using R to calculate and visualise Principle Components Analysis, using Fisher’s Iris data. PCA is something I’ve struggled with as I’ve gone further into statistics, as it comes across as being based on mathematics rather than statistics. I’d like to learn more about the Indian Buffet Process and associated non-parametric Bayesian methods but if I’m going to be looking at long and wide data sets (say, UPTECH questionnaire data) I’d like to have somewhere to start. It looks like this may provide that. Rasmus Bååth’s done &lt;a href=&#34;http://www.sumsar.net/blog/2013/11/easy-laplace-approximation/&#34;&gt;a tutorial on Laplace Approximations in R&lt;/a&gt; (hat tip to Matt Moores for this one). Laplace Approximations are an alternative to MCMC simulation that can provide good approximations to well-behaved posterior densities in a fraction of the time. The tutorial deals with the issue of reparameterisation for when you’ve got parameters which have bounded values (such as binomial proportions). As a piece of trivia, Thiago (above) is based at NTNU where &lt;a href=&#34;http://www.r-inla.org/&#34;&gt;R-INLA&lt;/a&gt; is developed. I’m at the &lt;a href=&#34;http://emac2013.com.au/&#34;&gt;emac2013&lt;/a&gt; conference this week. We’re about half way through day one of the talks (of three) and there’s already been some fascinating stuff. Professor Robert Mahony (ANU) gave a talk that shows that the development of more advanced unmanned aerial vehicles (UAVs, drones) involves some quite complex but elegant mathematics, involving Lie group symmetries, rather than just coming up with cooler robots. Hasitha Nayanajith Polwaththe Gallage (QUT) showed some really interesting particle method (mesh-free) modelling where forces and energies were used to determine the shape of a red blood cell that had just ejected its nucleus.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>More on the use of R and ggplot in SEB113</title>
      <link>/./2013/11/20/more-on-the-use-of-r-and-ggplot-in-seb113/</link>
      <pubDate>Wed, 20 Nov 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/11/20/more-on-the-use-of-r-and-ggplot-in-seb113/</guid>
      <description>&lt;p&gt;One of the benefits of waking up stupidly early is that you can organise to have coffee and a chat with a friend before work and still get there on time. A friend who I haven’t seen in a while contacted me recently to ask a few questions about learning R for data analysis and visualisation. While they won’t need to formally learn statistics and visualisation for their work it certainly doesn’t hurt to be able to generate better analysis of data and make more informative and easy to interpret graphs. My friend hasn’t done any statistics since high school Maths B, approximately ten years ago, which makes them similar to many of my SEB113 students. They have done a bit of programming along the way as a hobby, which will of course be a huge help. Having downloaded R and had a crack at a ggplot2 tutorial, they were confident that they &lt;em&gt;could&lt;/em&gt; learn what was going on even though they didn’t really understand what was going on in the tutorial. We sat down with the tutorial and some avocado on toast and worked through what the arguments for each function represented and what the data frame was made of, how ggplot has a grammar of graphics and how we can continue to add elements to the code to change the plot. To an extent, the ability to work through but not explain what some code is doing is typical of an SEB113 student in the first half of the subject (where we provide the code and get them to run it). It’s not until later in the semester, when the computer labs stop, that we expect that they can turn their ideas into code (and they’re welcome to cannibalise the code we provide) to write their quantitative workbooks. I suggested the &lt;a href=&#34;http://samclifford.info/2013/11/11/coursera-courses-on-statistics/&#34; title=&#34;Coursera courses on statistics&#34;&gt;Coursera course that started yesterday&lt;/a&gt; as a way to get a bit more familiar with how R works and get recognition of the completion of the course (which isn’t a recognised qualification but is evidence of being interested enough to pursue it). These days I’m always on the lookout for better ways to introduce SEB113 students to R and ggplot2 and I found the following tutorials (and have passed them on to my friend and the SEB113 teaching team) via Matt Asher’s “&lt;a href=&#34;http://www.statisticsblog.com/2013/11/the-week-in-stats-nov-18th-edition/&#34;&gt;Statistics Blog&lt;/a&gt;” and I have copied and pasted the text directly:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Martin Johnsson wrote a series of five well-written tutorials called &lt;em&gt;A slightly different introduction to R,&lt;/em&gt; with tips for beginner R users. Here are the links to parts &lt;a href=&#34;http://bit.ly/1fzSWRq&#34;&gt;I&lt;/a&gt;, &lt;a href=&#34;http://bit.ly/18pRHiz&#34;&gt;II&lt;/a&gt;, &lt;a href=&#34;http://bit.ly/19if90E&#34;&gt;III&lt;/a&gt;, &lt;a href=&#34;http://bit.ly/183o9eb&#34;&gt;IV&lt;/a&gt; and &lt;a href=&#34;http://bit.ly/1i7x0j0&#34;&gt;V&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I had no idea that the &lt;a href=&#34;http://cran.r-project.org/web/packages/coefplot/index.html&#34;&gt;coefplot&lt;/a&gt; package existed! That’s going to make visualisation of fitted linear models much easier for our students, as we’ve previously had them using geom_segment to manually plot estimates and confidence intervals. This is part of what I love about R, compared to, say, SAS. There’s a huge community of people working out there to add extra functionality to an open source project by building on each others’ work. GGally and coefplot both require ggplot2 and have got a lot of really nice functions that extend the publication quality graphics of ggplot2. The community is quite active and if you can think of a question for R there’s probably an answer out there already.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Using ggplot2 in SEB113</title>
      <link>/./2013/09/10/using-ggplot2-in-seb113/</link>
      <pubDate>Tue, 10 Sep 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/09/10/using-ggplot2-in-seb113/</guid>
      <description>&lt;p&gt;One of the big pieces of feedback we got during last semester’s SEB113 class was that the programming was difficult to understand and reproduce. While the subject is not a programming subject, we do use R quite heavily for all of the data analysis. Maths B isn’t a pre-requisite for SEB113 and I’d wager that even fewer of the students entering the ST01 Bachelor of Science program have taken senior IPT/ICT subjects at their high schools than have taken Maths B. This semester we introduced R in the very first lecture and gave it a bit of a context. This means that students are aware from the get-go that they will be learning statistics through data analysis on a computer. The lectorials introduce the concepts and provide code for the resulting plots and analysis, the computer labs show how to do that particular form of analysis in R and then the collaborative workshops reinforce the labs by getting groups to work through the analysis of some problem using the statistical concepts and code that they’ve learned that week. One of the biggest stumbling blocks last semester was the inconsistency in the way visualisation was done in R. We used a combination of base graphics, trellis graphics in the lattice package, heatmaps and dendrograms from other packages and had to turn to yet another package to get colorbars for the heatmaps. Part of the fine-tuning this semester has been employing someone (who also does the labs) to rewrite the graphics in the labs in terms of Hadley Wickham’s &lt;a href=&#34;http://ggplot2.org/&#34;&gt;ggplot2&lt;/a&gt; library. This brings consistency to the graphical aspect of the unit and the plot geometries are named explicitly so that it’s clear what style of plot you’ll be generating. I was quite sceptical of ggplot2 when I first saw it, as the only exposure I had to it was the default options for a scatterplot with points. Sure, that’s pretty boring, but the fact that you can make a faceted grid (or wrap it using facet_wrap instead of facet_grid) means that investigating the use of small multiples is so much easier. Small multiples is a visualisation technique developed by &lt;a href=&#34;http://www.edwardtufte.com/tufte/&#34;&gt;Edward Tufte&lt;/a&gt; to allow the reader to see how the relationship between two variables changes as you also vary one or two other (categorical) covariates. Doing this in lattice required specifying a formula, similar to the way you specify a model in lm, but lattice is so different from the base graphics that you lose consistency. I’m touching up this week’s workshop at the moment and I’m really noticing where the graphics code has been greatly simplified by access to a grammar of graphics for a powerful set of plotting routines. The &lt;a href=&#34;http://cran.r-project.org/web/packages/GGally/index.html&#34;&gt;GGally&lt;/a&gt; pacakge provides things like ggpairs, which does what pairs does in the base graphics but gives you the correlation above the diagonal and the scatterplots below the diagonal. This makes for more informative graphs with the beauty of the ggplot style. As far as I can tell we’re hearing fewer complaints about the programming and the visualisation is happening much quicker in the workshops this semester as ggplot2’s documentation is amazing and it’s often a choice of geometry (and changing one or two options) rather than a choice of library (and changing the entire approach to the coding). The use of ggplot2 has made teaching visualisation much simpler and we’re now getting through the workshops quite quickly because the visualisation is no longer a huge stumbling block.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples - July wrap</title>
      <link>/./2013/07/29/posterior-samples---july-wrap/</link>
      <pubDate>Mon, 29 Jul 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/07/29/posterior-samples---july-wrap/</guid>
      <description>&lt;p&gt;I had some Posterior Samples to share before going on leave but didn’t get around to posting them. Here’s what’s been on my mind this month: Maths and science units are popular with (Kentucky) students until they realise that &lt;a href=&#34;http://blogs.wsj.com/economics/2013/07/08/math-science-popular-until-students-realize-theyre-hard/&#34;&gt;they’re hard&lt;/a&gt;. While not directly relevant to the Australian university education model it’s probably an important thing for the Science and Engineering Faculty to keep in mind. &lt;a href=&#34;http://blogs.wsj.com/economics/2013/07/08/math-science-popular-until-students-realize-theyre-hard/&#34;&gt;&lt;/a&gt; I’m looking at ggplot2 more these days, so the idea of a “grammar of graphics” is beginning to resonate with me. &lt;a href=&#34;//www.youtube.com/watch?v=xyGggdg31mc&#34;&gt;Here’s a talk&lt;/a&gt; about building one for &lt;a href=&#34;http://clojure.org/&#34;&gt;clojure&lt;/a&gt; (which I don’t use). Something for me to keep in mind when delivering SEB113 slides this semester is &lt;a href=&#34;https://www.dropbox.com/s/p0sgdgo7mxkoj4h/What%20your%20math%20slides%20dont%20need.pdf&#34;&gt;what your maths slides don’t need&lt;/a&gt;. Probably also good pointers for any PhD students graduating soon. &lt;a href=&#34;http://well.blogs.nytimes.com/2013/07/22/the-kitchen-as-a-pollution-hazard/&#34;&gt;An interesting article in the New York Times&lt;/a&gt; about air pollution from cooking. This is something that ILAQH has a research interest in and our nanotracer paper contains a bit of analysis of inhaled surface area dose from particles that originate from cooking. &lt;a href=&#34;http://www.nytimes.com/2013/07/22/business/in-climbing-income-ladder-location-matters.html&#34;&gt;Another NYT article&lt;/a&gt;, this time with a delicious visualisation of the geographical trends in income disparity and social mobility. &lt;a href=&#34;http://www.slate.com/articles/health_and_science/science/2013/07/statistics_and_psychology_multiple_comparisons_give_spurious_results.html&#34;&gt;Andrew Gelman writes at Slate&lt;/a&gt; about some of the problems with scientific publishing and the publication of spurious findings (which isn’t always willingly dishonest). A special “Big Bayes Stories” issue of “Statistical Science” will be published soon, focussing on the real world application of Bayesian statistics where other methods were inapplicable. &lt;a href=&#34;http://xianblog.wordpress.com/2013/07/29/big-bayes-stories/&#34;&gt;Christian Robert has written the preface&lt;/a&gt;; the issue is being edited by Robert, Kerrie Mengersen (one of my PhD supervisors) and Sharon McGrayne, author of “&lt;a href=&#34;http://www.amazon.com/Theory-That-Would-Not-Die/dp/1452636850&#34;&gt;The Theory That Would Not Die&lt;/a&gt;”. Also I went to &lt;a href=&#34;http://www.questacon.edu.au/&#34;&gt;Questacon&lt;/a&gt; and it was awesome.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/05/23/posterior-samples/</link>
      <pubDate>Thu, 23 May 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/05/23/posterior-samples/</guid>
      <description>&lt;p&gt;Some people make their visualisations in Excel, I make mine in R and others still use things like Processing or InDesign. Bret Victor &lt;a href=&#34;http://vimeo.com/66085662&#34;&gt;shows us&lt;/a&gt; how the various ideas from each approach can be combined to make dynamic visualisations. It’s written with a view to &lt;a href=&#34;http://andrewgelman.com/2013/05/17/how-can-statisticians-help-psychologists-do-their-research-better/&#34;&gt;the interaction between statisticians and psychologists&lt;/a&gt; but it applies just as much to statisticians helping scientists with their statistics, which is basically my job at the moment. Two of my colleagues in BRAG gave &lt;a href=&#34;http://bragqut.wordpress.com/2013/05/21/geospatial-visualisation/&#34;&gt;a really neat talk&lt;/a&gt; about using R to visualise spatial data. Maybe &lt;a href=&#34;http://phenomena.nationalgeographic.com/2013/05/07/charlemagnes-dna-and-our-universal-royalty/&#34;&gt;Europe’s genetic history&lt;/a&gt; isn’t as diverse as we’d previously thought. They’re not all Habsburgs but there’s a little bit of Charlemagne in all of us. I helped a colleague hand in her PhD thesis recently; perhaps she should have read this beforehand: “&lt;a href=&#34;http://thesiswhisperer.com/2013/05/22/how-not-to-hand-in-your-phd/&#34;&gt;How not to hand in your PhD&lt;/a&gt;”.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>BRAG for 2013</title>
      <link>/./2013/02/07/brag-for-2013/</link>
      <pubDate>Thu, 07 Feb 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/02/07/brag-for-2013/</guid>
      <description>&lt;p&gt;The fornightly meetings for my stats group, BRAG, started up again two weeks ago and I’ve put my hand up to chair the meetings. I totally flubbed it this morning by forgetting we’d switched the start times to 10.30 instead of 11. Today’s meeting was less of a formal meeting and more of an exploration of QUT“s”&lt;a href=&#34;http://www.thecube.qut.edu.au/&#34;&gt;The Cube&lt;/a&gt;“, a new resource provided in the Science and Engineering Faculty’s new building. [caption id=“attachment_781” align=“aligncenter” width=“300”][&lt;img src=&#34;cubit1.jpg?w=300&#34; alt=&#34;CubIT, a unique system at the Cube that allows the general public to collaborate with and access research content shared by QUT’s students and academics. Photo copyright QUT.&#34; /&gt;](&lt;a href=&#34;http://samcliffordinfo.files.wordpress.com/2013/02/cubit1.jpg&#34; class=&#34;uri&#34;&gt;http://samcliffordinfo.files.wordpress.com/2013/02/cubit1.jpg&lt;/a&gt;) CubIT, a unique system at the Cube that allows the general public to collaborate with and access research content shared by QUT’s students and academics. Photo copyright QUT.[/caption] Marcus Rittenbruch showed us a bit about what CubIT is, how it works and what the plans are for the future. There are a bunch of touch screens that the public can interact with as part of The Cube, and CubIT is the system that allows you to use it. If you’re a QUT student or staff member you can &lt;a href=&#34;http://cubit.thecube.qut.edu.au/users/sign_in&#34;&gt;register an account&lt;/a&gt; and upload media (photos, text notes, video) through either the mobile web interface or the iPhone app. Then you swipe in using the card readers at the bottom of the screens and move your media around the screens, including dragging to the top bar so you can make a slideshow on the large non-touch screen. There are plans to include PDF and HTML support so you can run through presentation slides and refer to web pages when necessary. I think that’d be a pretty neat way to give a presentation. There’s a booking system which is yet to be made available online but when that’s up and running it’d be an interesting way to show potential collaborators what we can do. Over the next few meetings in BRAG we’ll be presenting on visualisation, similar to the computational talks that featured in the second half of last year. While not strictly Bayesian in nature, the talks will give examples of how to visualise different types of data and methods of analysis. I’ve put my hand up with Sama Low Choy to talk about some of the guiding principles of data visualisation that Tufte came up with. I know they’ve certainly helped when I’ve been writing papers and hopefully we can come up with a nice little talk that discusses the principles and gives some examples of good and bad graphs and discuss how we can apply the principles to make the graphs better. I’m very interested to see how others approach visualisation, particularly the common issues we have such as parameter summaries and then the specific issues such as visualising mixtures, high dimensional data, spatial information, etc.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/01/27/posterior-samples/</link>
      <pubDate>Sun, 27 Jan 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/01/27/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://tenhundredwordsofscience.tumblr.com/&#34;&gt;Ten Hundred Words of Science&lt;/a&gt; is a really neat Tumblr inspired by the &lt;a href=&#34;http://xkcd.com/1133/&#34;&gt;XKCD explanation of the Up-goer five (Saturn V)&lt;/a&gt;, for attempting to explain quite complex ideas in the ten hundred most common words of the English language (“thousand” did not make the list). &lt;a href=&#34;http://tenhundredwordsofscience.tumblr.com/post/41236467291/my-work-is-to-look-at-the-air-around-schools-to&#34;&gt;I have submitted an explanation of my own research&lt;/a&gt;. &lt;a href=&#34;http://bragqut.wordpress.com/&#34;&gt;My stats reseach group&lt;/a&gt; has decided to do a series of talks at its fortnightly meetings where presenters talk about visualisation. We’ve got a lot of people working on a variety of topics so it will be interesting to see how they present their data and data analysis. I’ve put my hand up (and my #3 supervisor’s) to do a talk about the principles of data visualisation. We’ve both read Tufte’s book and have a number of ideas about what constitutes a good graph. We’re considering a brief talk about the actual design principles and then some audience interaction where small groups are given a task such as critiquing a particular graph and suggesting changes. Good graph design and communication of ideas can always be focussed on. &lt;a href=&#34;http://www.economist.com/blogs/graphicdetail/2013/01/daily-chart-11&#34;&gt;The Economist has a terrible graph&lt;/a&gt; for what looks like the top 20 polluted cities but is actually a polluted city from the world’s 20 largest economies. In addition to being clearer about that, the graph should explicitly show the WHO standards and be on a log scale.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior Samples</title>
      <link>/./2013/01/21/posterior-samples/</link>
      <pubDate>Mon, 21 Jan 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/01/21/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://blog.revolutionanalytics.com/2013/01/elements-of-statistical-learning-2nd-ed-download.html&#34;&gt;Free download&lt;/a&gt; of Hastie, Tibshirani and Friedman’s “Elements of Statistical Learning”. Hastie and Tibshirani did a lot of the early work on Generalised Additive Models and non-parametric smoothing, albeit in a non-Bayesian framework, so this will no doubt be an invaluable resource. NASA have released &lt;a href=&#34;http://www.nasa.gov/topics/earth/features/2012-temps.html&#34;&gt;a neat visualisation&lt;/a&gt; of spatio-temporal deviation from the mean temperature going back to the 1880s. You have to be careful when generating “pretty” graphics, though, because &lt;a href=&#34;http://andrewgelman.com/2013/01/ugly-ugly-ugly/&#34;&gt;“pretty” infographics can be quite ugly and hard to decode&lt;/a&gt; when you’re not taking into account what the data actually represents. &lt;a href=&#34;http://www.biostat.jhsph.edu/~rpeng/&#34;&gt;Roger Peng&lt;/a&gt; &lt;a href=&#34;http://simplystatistics.org/2013/01/16/review-of-r-graphics-cookbook-by-winston-chang/&#34;&gt;reviews&lt;/a&gt; Winston Chang’s “R Graphics Cookbook”. The conclusion? A pretty good collection of examples about how to complete particular graphing tasks using ggplot2. It’s a simpler book than Hadley Wickham’s “ggplot2” and would be a good introduction to using ggplot2 to achieve a particular goal. &lt;a href=&#34;http://about.jstor.org/rr&#34;&gt;JSTOR’s “Register &amp;amp; Read”&lt;/a&gt; is in beta now. So if you’re not attached to a university or other institution with a JSTOR subscription, you now have the opportunity to read JSTOR articles for free (but it’s not unlimited, at least not yet). Speaking of free access to published research, &lt;a href=&#34;http://www.guardian.co.uk/science/blog/2013/jan/17/open-access-publishing-science-paywall-immoral&#34;&gt;this opinion article&lt;/a&gt; makes the point that our job as scientists is to contribute to the body of human knowledge for the benefit of society and so if a paper isn’t freely available to the public then it isn’t really “published”. Not only that, but to hide research behind a paywall is immoral. I found it very interesting even if I thought some of his arguments were a bit dismissive.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2012/12/27/posterior-samples/</link>
      <pubDate>Thu, 27 Dec 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/12/27/posterior-samples/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;span style=&#34;line-height:12px;&#34;&gt;&lt;a href=&#34;http://andrewgelman.com/2012/12/textbook-for-data-visualization/&#34;&gt;Gelman recommends&lt;/a&gt; Cleveland’s “&lt;a href=&#34;http://books.google.com.au/books/about/The_elements_of_graphing_data.html?id=Y2pqAAAAMAAJ&#34;&gt;The Elements of Graphing Data&lt;/a&gt;” over Tufte’s work for someone looking to put together a data analysis and visualisation couse. I’ll see if I can grab a copy from the library, it sounds interesting.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.nytimes.com/video/2012/12/24/science/100000001947354/wrights-law.html&#34;&gt;Jeffrey Wright uses wacky experiments to teach children about the universe, but it is his own personal story that teaches them the true meaning of life.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/Google/What-do-statisticians-do-at-Google&#34;&gt;Quora - What do statisticians do at Google?&lt;/a&gt; Some of the answer is deliberately vague, but the answer appears to be “Figure out whether the engineers have made the search algorithms better” and “Try to quantify whether changes to the way ads work have been positive”.&lt;/li&gt;
&lt;li&gt;I work in an aerosol science group which has studied tobacco smoke. Something I can’t find in our publication history is a study on marijuana smoke. NORML have &lt;a href=&#34;http://norml.org/library/health-reports/item/norml-s-marijuana-health-mythology&#34;&gt;a page&lt;/a&gt; dedicated to disputing some of the myths surrounding marijuana that come from both the pro- and anti-marijuana camps. The review was done in 1994 so I’d be interested to see how the epidemiological evidence has changed as our equipment has improved. I don’t know that the Queensland government (or QUT) would let us purchase any marijuana to do the study.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hmm. Are bullet points really the way to do this? Merry Christmas!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Presenting data and mathematical ideas</title>
      <link>/./2012/12/15/presenting-data-and-mathematical-ideas/</link>
      <pubDate>Sat, 15 Dec 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/12/15/presenting-data-and-mathematical-ideas/</guid>
      <description>&lt;p&gt;I was hanging out with some friends the other night and the topic of conversation turned to an infographic that one of the guys was working on for a friend of his, &lt;a href=&#34;http://onceround.com/2012/12/11/red-dwarf-smeg-count/&#34;&gt;the number of times the word “smeg” (or a variant) appears in each episode&lt;/a&gt; of &lt;a href=&#34;http://www.imdb.com/title/tt0094535/&#34;&gt;Red Dwarf&lt;/a&gt; (made in &lt;a href=&#34;http://processing.org/&#34;&gt;Processing&lt;/a&gt;). We got chatting about data visualisation and ended up talking about Edward Tufte and his approach to the various aspects of using data to show information. Apparently his brother have him a copy of &lt;a href=&#34;http://www.edwardtufte.com/tufte/books_vdqi&#34;&gt;Tufte’s book&lt;/a&gt; last year and he was kind enough to loan it to me. &lt;a href=&#34;http://staff.qut.edu.au/staff/lowchoy/&#34;&gt;One of my supervisors&lt;/a&gt; is a huge fan of Tufte’s approach and it’s worn off on me. Throughout my thesis I’ve moved away from giant scatter plots of the data to summary plots that don’t use more “ink” than is necessary to show the information. An example he gives in the book is the boxplot, which typically contains a lot of redundant information. The image below shows Tufte’s stripped down boxplot and the default R boxplot for the same data. In the more traditional boxplot, the maximum of the data (within 1.5 IQR) is represented by the end of the whisker as well as a hinge. The hinge isn’t necessary and neither is the box which marks the 25th and 75th percentiles as the other end of the whisker represents these. With no box, there’s no need for a horizontal stripe for the median, so it can be represented as a dot.&lt;a href=&#34;http://samcliffordinfo.files.wordpress.com/2012/12/boxplots.png&#34;&gt;&lt;img src=&#34;boxplots.png?w=300&#34; alt=&#34;boxplots&#34; /&gt;&lt;/a&gt; There are some plots in my thesis papers of which I’m quite proud and I will upload some of them here once the papers are finalised. My Tufte-mad supervisor has even commented on how my plots have become quite minimalist, something she attributes to the 2000s/10s despite Tufte’s work dating back to the 1970s. I’ve noticed that the R packages I’ve tended to use (&lt;a href=&#34;http://r-inla.org/&#34;&gt;R-INLA&lt;/a&gt;, &lt;a href=&#34;http://cran.r-project.org/web/packages/mgcv/index.html&#34;&gt;mgcv&lt;/a&gt;) have quite simple graphics. While there are some fantastic plotting packages such as &lt;a href=&#34;http://ggplot2.org/&#34;&gt;ggplot2&lt;/a&gt; that make it quite easy to produce very pretty graphics, I feel far more familiar mucking around with the base graphics system to add points, lines and polygons to a blank plot. If you take the approach that Tufte does, that the ink on the page should represent data, and that there should be no extraneous elements to your plot (such as cross-hatching a barplot or colour where it doesn’t convey information) then it’s not hard to shy away from packages that do a lot of very nice, but ultimately data-poor, plotting. But graphs on the printed page are not the only way to represent data or mathematical or statistical concepts. The &lt;a href=&#34;http://www.youtube.com/watch?v=jK7xPo1YXzY&#34;&gt;Museum of Mathematics&lt;/a&gt; in New York looks to have a lot of really cool displays of a wide range of mathematical concepts, for example. My Advanced Calculus lecturer, Dr Jack Wrigley, had a background in education and often used props in class to illustrate ideas, such as holding pieces of paper against a balloon to give us a visual representation of a tangent and normal surfaces. I don’t often have props when doing improvised theatre but academic presentation is, at the end of the day, just another type of performance. Part of the work I’ve been doing on modelling temporal trends from split panel design data involves modelling penalised random walks where the random walk is on a torus that represents a joint term for the hour of the day and the day of the week. This “hour of the week” term has 168 unique values, but we want to smooth both in the day to day and hour to hour direction, rather than just looking at the circle formed by gluing Saturday 11pm to Midnight and then Sunday 1am. Some people might be very good at visualising Markov random fields through their precision matrix but there will be many people in my PhD final seminar audience who are not postgraduate level statisticians. For the purpose of explaining one of the key ideas in my thesis, I am considering bringing an inflatable pool ring and a marker in order to draw the smoothing directions on the torus that represents the product of two circular spaces. If this doesn’t make up for the conceded pass I got in Jack Wrigley’s class I have no idea what will.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2012/12/11/posterior-samples/</link>
      <pubDate>Tue, 11 Dec 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/12/11/posterior-samples/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;span style=&#34;line-height:12px;&#34;&gt;&lt;a href=&#34;http://www.statisticsblog.com/2012/12/information-graphics/&#34;&gt;Nice infographic of Mars missions&lt;/a&gt; showing all attempts and planned attempts&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;As much as I love using .csv files to send data back and forth, especially on GitHub, apparently I should &lt;a href=&#34;http://www.win-vector.com/blog/2012/12/pleases-stop-using-excel-like-formats-to-exchange-data/&#34;&gt;stop using Excel-like files to exchange data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;There are some really lovely visualisations of quite profound and complex scientific ideas among &lt;a href=&#34;http://www.wired.com/wiredscience/2012/12/science-figures-2012/&#34;&gt;The best scientific figures of 2012&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;As someone who espouses the beauty of LaTeX and &lt;a href=&#34;http://samclifford.info/2012/08/12/credibility-of-information-given-font-choice/&#34;&gt;the importance of proper font choice&lt;/a&gt;, &lt;a href=&#34;http://typeanatomy.com/&#34;&gt;The Anatomy of Type&lt;/a&gt; is a book I’m considering buying. Maybe I should get it for my sister for Christmas.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sydneypadua.com/2dgoggles/lovelace-the-origin-2/&#34;&gt;A charming comic with an origin story for Ada Lovelace&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And, yes, I do plan on writing more about what I’m actually doing! I’m just working on thesis stuff a lot and trying to organise my final seminar. I’ve got some thoughts on presentations that I’m writing up, so stay tuned. One more &lt;a href=&#34;http://exp.lore.com/post/37688902608/60-seconds-of-awe-in-this-timelapse-of-the&#34;&gt;* Stunning time lapse photography of the eclipse.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Graphs again</title>
      <link>/./2012/11/19/graphs-again/</link>
      <pubDate>Mon, 19 Nov 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/11/19/graphs-again/</guid>
      <description>&lt;p&gt;Now that I’ve handed a draft of my final thesis paper to my supervisors/co-authors, I’ve got a little head space to work on another paper that’s been sitting on my to do list for a while. One of the challenges with this paper is coming up with a way to represent data relating to a total of over 100 students at 24 schools. Summarising at the school level ignores a lot of the within-school variation but attempting to use standard plotting approaches can lead to some very complex and visually busy graphs. Add to this that we can’t really use colour and it’s getting a bit tricky. I’ve had a few more looks at the &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/dodhia.pdf&#34;&gt;Gelman, Pasarica and Dodhia paper&lt;/a&gt; &lt;a href=&#34;http://samclifford.info/2012/10/30/turning-tables-into-graphs/&#34; title=&#34;Turning tables into graphs&#34;&gt;that I’ve previously talked about&lt;/a&gt;. While it doesn’t have an example of what I actually want to plot, it does make me think more about what kind of data I’ve got, whether they’re continuous, categorical or count, what their ranges are and what sort of variation occurs. With 24 schools it’s possible to do a 4 x 6 or 6 x 4 grid of sub-plots, and within those subplots we can generally get across what sort of variation there is at the school level. Not everyone likes such a layout, though, so I’ve been looking into grouped/stacked barplots, changing the ordering of the grouping (variable by school vs school by variable) and combining time series and barplots in the same graph (which is actually quite a good way of visualising the data we have, but can’t be done for 100 students). In the end, it’s going to come down to being creative enough to come up with a few alternatives and asking my co-authors which version they think sells the message best. I pretty much refuse to resort to pie graphs (because the scaling in area can be misleading) and feel really uncomfortable about using box-plots to summarise school-level variation. I have nothing against box plots, but for the size of the data we have at each school, summarising with a minimum, maximum and the 25th, 50th and 75th percentiles is going to be very difficult without shifting to a &lt;a href=&#34;http://samclifford.info/2012/10/25/anova-again/&#34; title=&#34;ANOVA again&#34;&gt;Bayesian ANOVA&lt;/a&gt;. Still, it’s a really interesting piece of science with some quite unique challenges in terms of the analysis and representation of that analysis (and the raw data). Edit: and it also makes me appreciate what designers (including my two housemates) have to go through, with people saying “No, I don’t like it” but not always having some constructive advice that’s actually possible to put into practice. Edit 2: &lt;a href=&#34;http://andrewgelman.com/2012/11/tradeoffs-in-information-graphics/&#34;&gt;Relevant new Gelman blog post&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2012/11/09/posterior-samples/</link>
      <pubDate>Fri, 09 Nov 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/11/09/posterior-samples/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://simplystatistics.org/post/34563838584/computing-for-data-analysis-simply-statistics-edition&#34;&gt;&lt;span style=&#34;line-height:12px;&#34;&gt;Content from very popular online R course run through Coursera to be published online soon&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.statisticsblog.com/2012/10/recommendation-of-the-week/&#34;&gt;Convinced your fancy analysis technique is the right approach? Run it on noise and see what you get&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://scienceseeker.org/&#34;&gt;Science news from science newsmakers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://statisfaction.wordpress.com/2012/11/06/just-for-the-fun-of-it/&#34;&gt;Should ecologists become Bayesians?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;If you’ve got a colour graph but want to print it black and white, make sure you check what it looks like first. &lt;a href=&#34;http://i.imgur.com/krzQu.jpg&#34;&gt;Otherwise you might struggle to make your point.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://andrewgelman.com/2012/11/poll-aggregation-and-election-forecasting/&#34;&gt;Andrew Gelman on poll aggregation and election forecasting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.amazon.com/The-Signal-Noise-Predictions-Fail-but/dp/159420411X/ref=zg_bs_books_2&#34;&gt;Nate Silver’s book is #2 on the Amazon best-seller list at the moment&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://simplystatistics.org/post/34635539704/on-weather-forecasts-nate-silver-and-the&#34;&gt;Speaking of Nate Silver, here’s a blog post on the politicisation of statistical literacy. (Bonus round: Ctrl-F “Schwimmer”. Extra bonus round: Andrew Gelman comments, saying “I wrote about this on my blog”, just like everyone else on the internet)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Turning tables into graphs</title>
      <link>/./2012/10/30/turning-tables-into-graphs/</link>
      <pubDate>Tue, 30 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/30/turning-tables-into-graphs/</guid>
      <description>&lt;p&gt;One of the things I’ve noticed from working with scientists (of various background) is that they love tables full of means and standard deviations as a way of summarising the variability in some data or regression parameters. &lt;a href=&#34;http://andrewgelman.com/2012/10/communication-is-a-central-task-of-statistics-and-ideally-a-state-of-the-art-data-analysis-can-have-state-of-the-art-displays-to-match/&#34;&gt;Andrew Gelman’s latest discussion of a paper&lt;/a&gt; makes the point that tables of numbers are awful and that a well made graphic does a good job of conveying the uncertainty. He refers in his comment to a paper he wrote, “Let’s Practice What We Preach: Turning Tables into Graphs” [1], which shows how graphs can be better at summarising variability, often in less space than a table. Another thing I really like about the paper is that it endorses the use of R/S/S+ for plotting and faults Excel for not offering enough control to the user (and it makes ugly graphs anyway). I’m a big fan of using graphs because numbers don’t really mean that much to me, especially when dealing with things like splines and random walk models for non-linear function estimation. The UPTECH papers I’m writing on the fungal data and nanotracer measurements have a lot of graphs where previously there were tables or Excel plots which weren’t as easy to interpret. I’ve been spending quite a bit of time on them so that we can present to our readers, for example, just how different the means are in our hierarchical Bayesian model. I think tables have a place and I use them in my own papers. I’m using a table in a spatial modelling paper to describe the prevailing winds and local geography at each of 13 measurement locations. There’s a map of the locations so that I don’t have to put things like “location” in the table. A list of features doesn’t translate as well to a plot as spatial locations do. I don’t think it’s appropriate to list row upon row of means, standard deviations, quantiles, etc. Long/wide tables of model fit criteria such as MSE, AIC, R&lt;sup&gt;2&lt;/sup&gt;, adjusted R&lt;sup&gt;2&lt;/sup&gt;, etc. are incredibly boring and do not scale well when you’re comparing more than, say, three models. I think I might try to send this paper around my group as an attempt to convince them to abandon tables in favour of concise graphs. With the uptake of R among some of the more senior researchers/staff looking promising, I think it’s a message that might actually get some traction. [1] Gelman, Andrew, Pasarica, C., and Dodhia, R. (2002). Let’s practice what we preach: turning tables into graphs. American Statistician 56, 121-130. [&lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/dodhia.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ANOVA again</title>
      <link>/./2012/10/25/anova-again/</link>
      <pubDate>Thu, 25 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/25/anova-again/</guid>
      <description>&lt;p&gt;I’ve been out for an after work drink with some people from ILAQH. Rather than going to bed after getting home I decided that what I &lt;em&gt;urgently&lt;/em&gt; need to do is write about the exchangeability in this hierarchical prior for the microbiology paper I’m writing with Heidi Salonen. I got a bit carried away and have reformulated the model a bit to properly represent the hierarchy while still making the code as similar in its working across all branches. Now I’ve got a bit carried away and am looking at how best to visually represent an estimate of the difference between indoor and outdoor fungal counts. It’s nice that I can generate these estimates from MCMC output rather than having to do formal testing that assumes a particular distribution. I’m looking forward to presenting these plots and results to my co-authors because it really shows the power of Bayesian hierarchical modelling as a tool for examining random effects across groups where there is little data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The pleasure of the Unknown Pleasures cover</title>
      <link>/./2012/10/18/the-pleasure-of-the-unknown-pleasures-cover/</link>
      <pubDate>Thu, 18 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/18/the-pleasure-of-the-unknown-pleasures-cover/</guid>
      <description>&lt;p&gt;Hat tip to &lt;a href=&#34;http://conidialcoleopticide.wordpress.com/&#34;&gt;Luisa&lt;/a&gt; for this one. The video below (from the &lt;a href=&#34;http://laughingsquid.com/the-story-of-the-iconic-cover-art-for-joy-divisions-unknown-pleasures/&#34;&gt;following link&lt;/a&gt;) tells the story of the front cover image of Joy Division’s 1979 album “Unknown Pleasures”. &lt;a href=&#34;http://samclifford.info/2012/10/08/unknown-measures/&#34; title=&#34;Unknown measures&#34;&gt;I’ve previously mentioned&lt;/a&gt; that this would be a great data visualisation technique for time series data and that’s more or less what it is. [vimeo &lt;a href=&#34;http://www.vimeo.com/51365288&#34; class=&#34;uri&#34;&gt;http://www.vimeo.com/51365288&lt;/a&gt; w=500&amp;amp;h=281] [Data Visualization Reinterpreted by VISUALIZED](&lt;a href=&#34;http://vimeo.com/51365288&#34; class=&#34;uri&#34;&gt;http://vimeo.com/51365288&lt;/a&gt;) from &lt;a href=&#34;http://vimeo.com/user13541926&#34;&gt;VISUALIZED&lt;/a&gt; on &lt;a href=&#34;http://vimeo.com&#34;&gt;Vimeo&lt;/a&gt;. From Wikipedia:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The front cover image comes from an edition of the Cambridge Encyclopedia of Astronomy, and was originally drawn with black lines on a white background. It presents successive pulses from the first pulsar discovered, PSR B1919+21 - often referred to in the context of this album by its older name, CP 1919. The image was suggested by Bernard Sumner. The cover design is credited to Joy Division, Peter Saville and Chris Mathan.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So there you go. It started off as an illustration in a physics encyclopedia and I’m suggesting we use it for visualisation 55 years later.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unknown measures</title>
      <link>/./2012/10/08/unknown-measures/</link>
      <pubDate>Mon, 08 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/08/unknown-measures/</guid>
      <description>&lt;p&gt;I think it would be incredibly dorky, and thus incredibly cool (or incredibly hipster), to present some aerosol time series data in the same vein as the cover art for Joy Division’s “Unknown Pleasures”. &lt;a href=&#34;unknown-pleasures-joy-division.jpg&#34;&gt;&lt;img src=&#34;http://samcliffordinfo.files.wordpress.com/2012/10/unknown-pleasures-joy-division.jpg&#34; title=&#34;Joy Division &amp;quot;Unknown Pleasures&amp;quot;&#34; /&gt;&lt;/a&gt;It’s actually quite an interesting way to visualise spatio-temporally correlated data, with either time or space as the grouping variable.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data visualisation</title>
      <link>/./2012/10/02/data-visualisation/</link>
      <pubDate>Tue, 02 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/02/data-visualisation/</guid>
      <description>&lt;p&gt;Last week I had a chat with one of Kerrie Mengersen’s new MSc students about the UPTECH work I’ve been doing. Aleysha Thomas will be working on scientific visualisation of statistical modelling/inference/analysis and has been talking to some of the other students in our stats group to get an idea of what sort of work we do and what sort of stuff there is to visualise. For example, my doing semi-parametric regression with splines means that the marginal densities of the parameters aren’t as interesting as the fitted smooth which is comprised of those parameters multiplied by B-spline basis vectors. A tensor product of two splines is better off visualised with a contour plot than with a list of coefficients and their credible intervals. My work involves spatio-temporal modelling but I don’t present it as a spatial map if the temporal variation is more interesting. At some point, though, I’ll be publishing graphs of continuous space spatial random effects and that will require some thought as to how the uncertainty in the estimates is represented. At the moment I’m just using levelplot() to plot the mean and standard deviation, but there are other options such as stacked surface plots and contour plots. &lt;a href=&#34;http://www.linkedin.com/in/matthewmoores&#34;&gt;Matt Moores&lt;/a&gt; does spatial statistics as well (cone beam and fan beam CT scans for radiotherapy treatment) but deals with completely different data, methods and visualisation techniques. In addition, our audiences’ only overlap is statisticians. Pitching to your audience is a very important part of presenting your work, whether it’s at a conference, in a journal article or to your PhD seminar panel. It’s no good me coming up with a beautiful way of representing my inference if it’s impossible for others to understand. Hopefully with Aleysha on board our stats group will be exposed to new ways of visualising data and inference. My stats group is certainly better than my aerosols group when it comes to graphical representation of data and results, but we can still be doing better (myself included).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Infographics</title>
      <link>/./2012/08/28/infographics/</link>
      <pubDate>Tue, 28 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/28/infographics/</guid>
      <description>&lt;p&gt;Kasia Piekut has written &lt;a href=&#34;http://mark-making.com/blog/27-communication/240-how-to-get-your-mind-around-infographic-design-and-data-visualisation&#34;&gt;an article on&lt;/a&gt; Mark Making about infographics and some of the most important things to remember. It’s accompanied by a cute infographic about infographics themselves. The potential to make high quality infographics is huge these days, as we have some very clever designers with very good software. But it’s important to remember that infographics aren’t just about pretty design but effectively communicating information in an accessible and entertaining manner. There are some pretty terrible infographics out there, where colour is used to pretty the graphs up without actually conveying information. I try to tell my coworkers to avoid the uninformative use of colour because people will look at a multicoloured graph and ask “What does this change of colour mean?” Often a table or simple plot will do in place of an infographic. As researchers we must resist the temptation to make our graphs so punchy and full of colour that we obscure the meaning of the data. Infographics are a tool for conveying information; we should be careful that we don’t end up with pictures for the sake of pictures. We should also be careful that we don’t end up with graphics that obscure the data and its implications. Edit: I don’t know that this is worthy of its own post so I’ll add it here. &lt;a href=&#34;http://themonkeycage.org/blog/2012/08/28/choices-in-graphing-parallel-time-series&#34;&gt;Andrew Gelman has blogged at The Monkey Cage&lt;/a&gt; about choosing plot styles and how different representations of the same data can be used to give the punchy dramatic message and then give that message a bit more context.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My take on the Bayesian updating video</title>
      <link>/./2012/08/27/my-take-on-the-bayesian-updating-video/</link>
      <pubDate>Mon, 27 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/27/my-take-on-the-bayesian-updating-video/</guid>
      <description>&lt;p&gt;I’m referring here to my &lt;a href=&#34;http://samclifford.info/2012/08/25/438/&#34;&gt;last post&lt;/a&gt; where I reblogged something that &lt;a href=&#34;http://bayesianbiologist.com/&#34;&gt;Bayesian Biologist&lt;/a&gt; &lt;a href=&#34;http://bayesianbiologist.com/2012/08/17/an-update-on-visualizing-bayesian-updating/&#34;&gt;had written&lt;/a&gt;. I’ve modified the code (and included it below) to tweak it to my tastes and show the different behaviour of the posterior under a uniform Beta(1,1) prior and an informative Beta(20,20) prior. Rather than flipping a fair coin I’ve assumed that the coin is unfair (p=0.25) and the Beta(20,20) prior is chosen by the naive observer who believes, with a high degree of certainty, that the coin is fair. This is, to me, an illustration of the power of uninformative priors (something Laplace seemed keen on in Binomial experiments). It’s also a good demonstration of how given enough data the posteriors will converge to the same result. A persistent criticism of Bayesian analysis is that the priors are so subjective that anyone can come up with their own prior and get a different result to another observer. As more data is collected, the influence of the prior in the posterior is diminished. We see (in the 1.08MB animation below the cut) that the Beta(1,1) prior is more sensitive to each success and failure and the posterior mean approximates p much quicker than the more “certain” Beta(20,20) prior. The take home message? Be more vague than you think is warranted just in case your prior is not diffuse enough. To generate the gif I’ve used the instructions in the video in the last lines of the code. &lt;a href=&#34;updating.gif&#34;&gt;&lt;img src=&#34;http://samcliffordinfo.files.wordpress.com/2012/08/updating.gif&#34; title=&#34;Bayesian updating&#34; /&gt;&lt;/a&gt; [sourcecode language=“r”] ## Corey Chivers, 2012 ## ## modifications by ## ## Sam Clifford, 2012 ## sim_bayes &amp;lt;- function(p=0.5,N=100,y_lim=20,a_a=2,a_b=10,b_a=8,b_b=3) { ## Simulate outcomes in advance outcomes&amp;lt;-sample(1:0,N,prob=c(p,1-p),replace=TRUE) success&amp;lt;-cumsum(outcomes) for(frame in 1:N) { png(paste(“plots/”,1000+frame,“.png”,sep=“”)) curve(dbeta(x,a_a,a_b),xlim=c(0,1),ylim=c(0,y_lim),col=‘green’,xlab=‘p’,ylab=‘Posterior Density’,lty=2) curve(dbeta(x,b_a,b_b),col=‘blue’,lty=2,add=TRUE) lines(x=c(p,p),y=c(0,y_lim),lty=2,lwd=1,col=“grey60”) i &amp;lt;- frame # i don’t like having the leftovers on the screen – Sam #for(i in 1:frame) #{ # curve(dbeta(x,a_a+success[i]+1,a_b+(i-success[i])+1),add=TRUE,col=rgb(0,100,0,(1-(frame-i)/frame) * 100,maxColorValue=255)) # curve(dbeta(x,b_a+success[i]+1,b_b+(i-success[i])+1),add=TRUE,col=rgb(0,0,100,(1-(frame-i)/frame) * 100,maxColorValue=255)) #} curve(dbeta(x,a_a+success[i]+1,a_b+(i-success[i])+1),add=TRUE,col=rgb(0,100,0,255,maxColorValue=255),lwd=2) curve(dbeta(x,b_a+success[i]+1,b_b+(i-success[i])+1),add=TRUE,col=rgb(0,0,100,255,maxColorValue=255),lwd=2) # modifications to make prior explicit in legend legend(‘topleft’,legend=c( paste(‘Observer A - Beta(’, a_a , ‘,’ , a_b , ‘)’,sep=“”),paste(‘Observer B - Beta(’, b_a , ‘,’ , b_b , ‘)’,sep=“”)),lty=1,col=c(‘green’,‘blue’)) text(0.75,17,label=paste(success[i],“successes,”,i-success[i],“failures”)) dev.off() } # Sam # system(’mencoder mf://plots/*.png -mf fps=15:type=png -ovc copy -oac copy -o plots/output.avi’) # we’ll use GIMP rather than mencoder # &lt;a href=&#34;http://www.youtube.com/watch?v=u5_3MGP2Lj4&amp;amp;feature=player_detailpage#t=265s&#34; class=&#34;uri&#34;&gt;http://www.youtube.com/watch?v=u5_3MGP2Lj4&amp;amp;feature=player_detailpage#t=265s&lt;/a&gt; } sim_bayes(a_a=1,a_b=1,b_a=20,b_b=20,p=0.25,N=250) [/sourcecode]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>/./2012/08/25/</link>
      <pubDate>Sat, 25 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/25/</guid>
      <description>&lt;p&gt;I came across this via reddit’s r/statistics community and thought I might share it as a nice way of visualising posteriors. Specifically, it’s a very good demonstration of the convergence of the posterior beliefs of two observers with separate priors but the same data (which is sequentially collected, but the order of successes/failures are irrelevant). So next time someone’s telling you that Bayesian statistics is inherently wrong because of the subjectivity of the prior belief, you can point them to something like this to demonstrate that as data is collected the posteriors become quite close. I suggest having a play with the R code to understand how the diffuseness of the priors affects the concentration of posterior belief. While the opposite beliefs of the observers in the attached video are a nice example of convergence to the same posterior, I think two priors with the same mean and different variance would be a more interesting visualisation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Charts and infographics</title>
      <link>/./2012/05/29/charts-and-infographics/</link>
      <pubDate>Tue, 29 May 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/05/29/charts-and-infographics/</guid>
      <description>&lt;p&gt;One of my supervisors, Sama Low Choy, is always up for a chat about the role of visualisation in statistics and data analysis. An acolyte of &lt;a href=&#34;http://www.edwardtufte.com/tufte/&#34;&gt;Tufte&lt;/a&gt;, Sama is quite passionate about appropriate methods of presenting data. 3D pie charts, needless to say, are public enemy number one. We were having a chat this afternoon about how &lt;a href=&#34;http://conidialcoleopticide.wordpress.com/&#34;&gt;a friend of mine&lt;/a&gt; who’s about to start a Masters in biology/statistics is a bit of a nerd when it comes to the presentation of data and copy. Talk turned to how easy it is to use LaTeX and how there’s a need for better visualisation in scientific results (something I’ve talked to some of my ILAQH colleagues about at length). Infographics are quite a popular thing at the moment, despite not always being particularly informative nor warranted, and I mentioned &lt;a href=&#34;http://chartsnthings.tumblr.com&#34;&gt;a blog about the process that the New York Times crew go through when developing infographics&lt;/a&gt; and other visualisation tools. Sama has forwarded me an email containing some of her favourite links that deal with the field of “data journalism”.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Times in US provide some inspiration: &lt;a href=&#34;http://blog.visual.ly/20-great-visualizations-of-2011&#34; class=&#34;uri&#34;&gt;http://blog.visual.ly/20-great-visualizations-of-2011&lt;/a&gt;/ Even on a topic that some science &amp;amp; engineerings students may become engaged with: &lt;a href=&#34;http://blog.visual.ly/best-beer-infographics-and-data-visualizations&#34; class=&#34;uri&#34;&gt;http://blog.visual.ly/best-beer-infographics-and-data-visualizations&lt;/a&gt; Someone else’s selection of highlights from their Infographics &lt;a href=&#34;http://www.smallmeans.com/new-york-times-infographics&#34; class=&#34;uri&#34;&gt;http://www.smallmeans.com/new-york-times-infographics&lt;/a&gt; Here is a link to a website about a new (free) handbook on data journalism: &lt;a href=&#34;http://datadrivenjournalism.net/news_and_analysis/A_peek_inside_the_Data_Journalism_Handbook#When:07:28:52Z&#34; class=&#34;uri&#34;&gt;http://datadrivenjournalism.net/news_and_analysis/A_peek_inside_the_Data_Journalism_Handbook#When:07:28:52Z&lt;/a&gt; Here’s a link to some videos (showing some software, doing some intuitive roll-up roll-down exploration &amp;amp; aggregation of data): &lt;a href=&#34;http://www.panopticon.com/videos&#34; class=&#34;uri&#34;&gt;http://www.panopticon.com/videos&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You might also enjoy &lt;a href=&#34;http://infosthetics.com/archives/2011/12/amanda_cox_talks_about_developing_infographics_at_the_new_york_times_graphics.html&#34;&gt;these videos of Amanda Cox&lt;/a&gt;, a woman behind some of the more innovative visualisation pieces at the NYT, talking about the processes of making good quality visualisations.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
