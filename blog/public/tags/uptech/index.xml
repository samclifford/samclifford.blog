<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Uptech on Sam Clifford </title>
    <link>/./tags/uptech/</link>
    <language>en-us</language>
    <author>Alexander Ivanov</author>
    <updated>2014-08-05 00:00:00 &#43;0000 UTC</updated>
    
    <item>
      <title>Running Bayesian models</title>
      <link>/./2014/08/05/running-bayesian-models/</link>
      <pubDate>Tue, 05 Aug 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/08/05/running-bayesian-models/</guid>
      <description>&lt;p&gt;I came across a post via r/Bayes about different ways to run Bayesian hierarchical linear models in R, a topic I talked about recently at a two day workshop on using R for epidemiology. &lt;a href=&#34;http://www.sumsar.net/blog/2013/06/three-ways-to-run-bayesian-models-in-r/&#34;&gt;Rasmus Bååth&lt;/a&gt;’s post details the use of JAGS with rjags, STAN with rstan and LaplacesDemon. JAGS (well, rjags) has been the staple for most of my hierarchical linear modelling needs over the last few years. It runs within R easily, is written in C++ (so is relatively fast), spits out something that the coda package can work with quite easily, and, above all, makes it very easy to specify models and priors. Using JAGS means never having to derive a Gibbs sampler or write out a Metropolis-Hastings algorithm that requires to you to really think about jumping rules. It’s Bayesian statistics for those who don’t have the time/inclination to do it “properly”. It has a few drawbacks, though, such as not being able to specify improper priors (but this could be seen as a feature rather than a bug) with distributions like dflat() and defining a Conditional Autoregressive prior requires specifying it as a multivariate Gaussian. That said, it’s far quicker than using OpenBUGS and JAGS installs fine on any platform. After reading the post’s section on STAN I decided that it was time to give it another go. Downloading the latest version of R and Rtools would surely give me a better experience than last time where it wouldn’t even detect the compiler properly. Putting everything in DOS-friendly file structures with short names meant that everything went off without a hitch and I was able to get the toy example running. Andrew Gelman, one of the developers of STAN, has a &lt;a href=&#34;http://andrewgelman.com/2014/01/21/everything-need-know-bayesian-statistics-learned-eight-schools/&#34;&gt;post on his blog&lt;/a&gt; by Phillip Price about the eight schools example, a really introduction to hierarchical linear modelling and meta-analysis. STAN is a bit more forgiving than JAGS when it comes to priors; any stochastic node that isn’t given a prior is given a flat prior by default. Whether or not &lt;a href=&#34;http://arxiv.org/abs/1403.4630&#34;&gt;Thiago Martins and Dan Simpson&lt;/a&gt; would be happy with that remains to be seen. STAN looks very promising, and it’s been included in the third edition of &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/book/&#34;&gt;Gelman’s BDA book&lt;/a&gt; (which I still need to buy). The other strategy I tried recently was coding up a Metropolis-Hastings sampler using &lt;a href=&#34;http://theoreticalecology.wordpress.com/2010/09/17/metropolis-hastings-mcmc-in-r/&#34;&gt;the guide from Florian Hartig at Theoretical Ecology&lt;/a&gt;. Choosing a jumping rule was difficult, as I had different parameters to deal with and a single jumping rule wouldn’t do. I tried &lt;a href=&#34;http://projecteuclid.org/euclid.bj/1130077595&#34;&gt;adaptive MCMC&lt;/a&gt; and ended up going down the rabbit hole of log-precisions, block-updates and ended up with very poor mixing and convergence. Finding a decent jumping rule is probably what prevents me from going back to using adaptive MCMC as I did for &lt;a href=&#34;http://eprints.qut.edu.au/72987/&#34;&gt;a book chapter on Bayesian splines&lt;/a&gt;. I eventually settled on writing out a full Gibbs scheme and coding it up in MATLAB. This is very fast (MATLAB’s better at loops than R is) and gives me good convergence. I’m not a fan of MATLAB’s plotting, though, so may end up importing the results into R so I’ve got ggplot2 handy. Big thanks to Zoé van Havre for her help with the Gibbs scheme. I’ve got a PhD student who’s going to be dealing with Bayesian modelling. He’s picking up R quite quickly and is doing his best with Bayesian statistics. It’s all in WinBUGS at the moment, though, which is going to limit the amount of progress we can make. I’d love to be able to code up a bunch of JAGS models and let them run on the supercomputer once we get our great big data set ready for a well-planned set of analyses. I’ve got less time to do the modelling myself these days and find myself wishing I had a clone to do the work. I guess that’s part of the training aspect of PhD supervision, making sure your student can do the implementation when you describe a piece of analysis that you propose. It’s still difficult for me working in a science group as the only statistician, as most of my statistics discussions are people asking for my help rather than us collaborating as equals. I enjoy working with others on interesting modelling problems, and it’d be good to work with other statisticians. While I’m now in the Mathematical Sciences School I don’t think I’ve capitalised yet on the connections I’ve got there in terms of directing my own research down the statistics route. With the UPTECH analysis being the major focus of my research at the moment, it’s tricky to allocate brain space to what I want to be doing next.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Science in context - my context</title>
      <link>/./2014/03/05/science-in-context---my-context/</link>
      <pubDate>Wed, 05 Mar 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/03/05/science-in-context---my-context/</guid>
      <description>&lt;p&gt;One of the first year units that QUT has introduced in the new Bachelor of Science program is &lt;a href=&#34;http://www.qut.edu.au/study/unit-search/unit?unitCode=SEB101&amp;amp;idunit=44497&#34;&gt;SEB101 - Science in Context&lt;/a&gt;. The subject aims to impress upon students the idea that science happens as part of a larger community and that how and why research is conducted relies on interactions with that community. I received an email last week from a former SEB113 student of mine, Kathryn Turner, asking if she could interview me for the SEB101 Portfolio about the work I do as research scientist. Kathryn and I organised to sit down and have a chat for this afternoon to discuss what I do, what relevance it has to the community and how the community sees the work we do. We spent most of our fifteen minutes talking about the UPTECH project and how my work, statistical analysis for the various papers, is part of a large, interdisciplinary project that allows me to work with many different sources of data and do different analyses. I mentioned that I initially studied mathematical modelling, focussing on computational fluid dynamics, and that I got involved in this research project because my primary supervisor (Professor Lidia Morawska) lectured an elective that I took in my undergrad (Global Energy Balance and Climate Change). I went to have a chat with her after I’d finished Honours about what sort of PhD projects she might have available (writing about this now, it feels like a lifetime ago; it was only 2008) and she was in the process of planning UPTECH and recruiting people. I was offered the chance to apply cool mathematical techniques to an interesting environmental health problem based that had links to transport planning. Sign me up! We also talked about the ethics side of the project, involving doing health diagnostic measurements with students, taking a health history and demographics survey home, etc. and how QUT makes sure we’re very careful with this sort of thing. I’m glad I didn’t have to do the ethics application for the project. Kathryn asked what the schools thought about having scientists come in and work with the kids. From what I understand, the schools were quite accepting and the kids were excited about the prospect of being involved with the personal sampling aspect; we also handed out badges that say “I’m doing SCIENCE” to the kids who were part of the study. On a bit of a tangent, and we didn’t discuss this, I think it’s good to have scientists seen as being regular people who have decided to pursue science and that the science isn’t just lab work. FermiLab did &lt;a href=&#34;http://ed.fnal.gov/projects/scientists/&#34;&gt;a really interesting project&lt;/a&gt; a few years ago about kids’ perceptions of scientists. They talked to some seventh graders and got them to describe and draw what they thought a scientist was before and after meeting a group of physicists who worked at the lab. The UPTECH members who went to the schools to do the measurements represent a very multicultural group, including (but not limited to) people of Iranian, Chinese, Egyptian, Malaysian, and Northern and Eastern European descent, and included both men and women. I hope that one of the outcomes of having such a diverse group involved with the field work for the project was that the students saw that scientists aren’t all old, white men with frizzy, greying hair, a lab coat and glasses. &lt;span style=&#34;line-height:1.714285714;font-size:1rem;&#34;&gt;After we’d wrapped up the interview, Kathryn said it was interesting to learn a bit more about the research career of a lecturer and seemed quite interested in the various projects that I get to work on. For my part, I found it a really interesting interview because I don’t often get asked about the ethical and community implications of my work. While I do spend my days sitting in front of a computer running statistical analyses, I am actually a research scientist who relies on the support of the public both through my funding and through social acceptance that looking at the health impact of air quality is valuable.&lt;/span&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>EMAC2013 semi-wrap</title>
      <link>/./2013/12/04/emac2013-semi-wrap/</link>
      <pubDate>Wed, 04 Dec 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/12/04/emac2013-semi-wrap/</guid>
      <description>&lt;p&gt;Today’s the final day of EMAC2013, starting with Joe Monaghan’s talk on numerical methods for the dynamics of fluids that contain particles (in 20 minutes, so I’ll be brief). I attended yesterday’s “Education” session and saw some interesting things about how maths education is going around the country. The University of Tasmania is engaging with TasTAFE to deliver maths courses to engineering diploma students in order to prepare them for the mathematics they’ll encounter in their bachelor’s degrees. UTS is doing some interesting analysis of their maths course results to rejig the prerequisite pathways for their maths courses. A particularly interesting case was the use of a first year linear algebra course as a predictor of performance in a second year stochastic models subject that previously only had a first year probability course as its prerequisite. I chaired and presented in yesterday’s “Environment” session, presenting the mathematics behind the &lt;a href=&#34;http://pubs.acs.org/doi/abs/10.1021/es403721w&#34;&gt;personal sampling&lt;/a&gt; that we’ve been working on with the UPTECH project. I got quite a number of good questions and was overall quite happy with the talk I gave. The other talks in the session were about: using approximations to a sum of Pareto distributions, developed by actuaries, to determine whether extreme values in biomass luminescence were real or artifacts from the new sensors; and incorporating insolation into global climate models. Josef Barnes (Griffith) won the student prize (for, I assume, his talk on cardiac geometries), with honorable mentions for Kristen Harley and Lisa Mayo (QUT) and Laith Hermez. Bill Blyth, for whom the prize is named, pointed out the quality of the student talks at EMAC2013 is getting higher year after year. This can only be good news for the applied mathematics sector in Australia (and New Zealand) as these students will likely go on to academic positions and generate high quality research. David Lovell gave a great talk yesterday about multi-, inter-, trans- and ante-disciplinary research. I’m reading &lt;a href=&#34;http://www.ploscompbiol.org/article/info:doi/10.1371/journal.pcbi.0010006&#34;&gt;the article&lt;/a&gt; he referred to yesterday about the way disciplines will have to deal with each other and knowledge sharing over the coming years. And I’m off.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Becoming a grown up (at least a grown-up academic)</title>
      <link>/./2013/08/30/becoming-a-grown-up-at-least-a-grown-up-academic/</link>
      <pubDate>Fri, 30 Aug 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/08/30/becoming-a-grown-up-at-least-a-grown-up-academic/</guid>
      <description>&lt;p&gt;There are only four months left in my current postdoctoral appointment and I’m discussing plans for next year with my supervisor. There’s still a lot of unfinished UPTECH work that needs to happen, including helping a handful of PhD students with the stats in their papers for their thesis, dealing with the clinical data and putting together some research plans for what to do next. The plan at the moment is to look for some funding both internally and externally to provide a research appointment. I’m also interested in continuing lecturing next year, whether in SEB113 or another mathematics/statistics unit. Most of ILAQH is away as of today or tomorrow, as they travel to Prague for the &lt;a href=&#34;http://eac2013.cz/&#34;&gt;2013 European Aerosol Conference&lt;/a&gt;. The work that I’ve been doing with some colleagues from ILAQH and Italy, on personal sampling, will be featured on a poster. The paper has been submitted to ES&amp;amp;T but hasn’t been accepted yet, so unfortunately I can’t put a preprint up to show off the cool statistics that I had to learn to do the modelling in the paper. As a result of everyone being away, I’ll be one of two academic staff members left here. It’s going to be quiet, with most of the staff and a few PhD students gone. Barring the Finnish paper that I’m still revising, this personal sampling paper has been the paper which has required the most creative and original programming as there have been many different steps along the way. I am particularly proud of this paper and the work that went into it. When I was first brought on board there didn’t appear to be much clarity regarding what we wanted to investigate; we had a lot of personal sampling data but didn’t quite know what to do with it. I think the paper we’ve developed does service to the amount of work that was put into collecting the data and is aligned with what the UPTECH project was set up to do. I’m grateful to all co-authors on the paper (and everyone who was out there in the schools) for the work that they put into bringing this to fruition. I’m still finishing the final corrections for my thesis, due in a few weeks time. After that’s handed in I’ll be taking another step in becoming a grown-up academic: supervising a PhD student. I’ll be the replacement associate supervisor for a student whose original associate supervisor has moved from QUT to another university. QUT requires an internal primary and associate supervisor and I’m the one most familiar with the modelling that this student is doing as part of their thesis. We’ve already set a meeting schedule for the time when his primary supervisor is overseas and have discussed what sort of things I’ll expect to see. It’s a strange responsibility to have for someone who’s only just finishing up their thesis. I wonder how long it will be until I’m the primary supervisor for a student. Two years? Five? Ten? Worrying about funding, writing grant applications, supervising students, lecturing (writing assessment!). It’s a strange place to find oneself.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New papers on the way</title>
      <link>/./2013/08/17/new-papers-on-the-way/</link>
      <pubDate>Sat, 17 Aug 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/08/17/new-papers-on-the-way/</guid>
      <description>&lt;p&gt;In addition to the Endotoxin paper which was accepted after revisions earlier this week, we are very close to submitting papers on the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;trends in and ratios of indoor and outdoor PNC in the UPTECH schools&lt;/li&gt;
&lt;li&gt;24 hour personal sampling and dose metrics for children in the UPTECH schools&lt;/li&gt;
&lt;li&gt;modern Bayesian spatial statistical techniques&lt;/li&gt;
&lt;li&gt;particle losses by size in diffusion dryers and thermodenuders&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In addition to these, a few papers are nearing completion but are not yet ready for submission. These include&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fungus concentrations in the UPTECH schools&lt;/li&gt;
&lt;li&gt;flame retardants in dust in the UPTECH schools&lt;/li&gt;
&lt;li&gt;particle emission and deposition rates for indoor sources in the UPTECH schools&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, yes, my plate has been rather full recently with all the various research activities in which I’ve been enlisted. These are all fascinating examples of the interaction of statistics and science and have all required different approaches to quantify what’s going on. Some of these have been fairly obvious modifications to things I’ve already done and some have required me to look quite deeply into new approaches and figure out both what the model is and how we go about implementing it. I am particularly happy with coming to terms with the combination of a Poisson regression model for total counts and a multinomial for proportions within that count, particularly when some of the classes in the multinomial may have zero counts. That model was a challenge but and I think the paper that it gets used in is much stronger than similar papers which have just taken a very naive approach to analysing the data. One of the biggest challenges with this particular paper has been communicating with the scientists I’m working with. These people are definitely not Bayesian statisticians and don’t come from a medical science background, which tends to be more accepting of complex models that replace ANOVA. I’ve had to write a few paragraphs for the flame retardants in dust paper that describe the model we’re using. Hopefully that helps make the analysis more accessible to the co-authors but also those reading the paper who haven’t got postgraduate qualifications in statistics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Conference posters and an accepted paper</title>
      <link>/./2013/08/09/conference-posters-and-an-accepted-paper/</link>
      <pubDate>Fri, 09 Aug 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/08/09/conference-posters-and-an-accepted-paper/</guid>
      <description>&lt;p&gt;Thomas Lumley &lt;a href=&#34;http://notstatschat.tumblr.com/post/57747270796/speed-sessions-at-jsm-2013&#34;&gt;has some thoughts&lt;/a&gt; on poster sessions at JSM 2013. Healthy Buildings 2012 had something I hadn’t seen before - poster presenters were given two minutes at the end of the technical session most relevant to their poster to describe the work they are presenting in the poster session immediately after the talk slot. This gave poster presenters a small taste of presenting at a conference without them needing to prepare a full talk. QUT’s Nano and Molecular Sciences discipline had a poster session during its one day symposium a few months ago and the posters were run off &lt;a href=&#34;http://www.thecube.qut.edu.au/&#34;&gt;The Cube&lt;/a&gt;, which allowed people to zoom and rotate a static image of their poster (PDF preferred). Our group will have a few posters at the &lt;a href=&#34;http://eac2013.cz/&#34;&gt;European Aerosol Conference&lt;/a&gt; in a few weeks. Mandana Mazaheri and I have been discussing the issues of transporting posters back and forth internationally, including whether or not to print on cloth and the unwieldy nature of poster tubes. I am a big fan of mailing your poster home once it’s presented but a cloth poster can be folded up and put in your luggage and you can just give it a quick iron before presenting it. I’ve also seen way too many posters that are too busy and have gradient backgrounds. Hopefully by teaching SEB113 students about the principles of good visualisation of data QUT can produce graduates who know not to make ugly posters. &lt;a href=&#34;http://pubs.acs.org/doi/abs/10.1021/es4023706&#34;&gt;Our endotoxin paper got accepted in Environmental Science &amp;amp; Technology&lt;/a&gt; after a frantic couple of days of finalising amendments and responses to reviewer comments. This paper gave me a much better understanding of Bayesian hierarchical linear models and I’m very happy with how the paper turned out. The next step is to resubmit our fungus paper, which includes similar modelling but also uses a Multinomial model with Dirichlet prior to look at the proportions of different fungal genera across the UPTECH schools. There’s yet another paper looking at chemicals in floor dust which we’re also finalising that uses a similar methodology to the fungus paper but has its own subtleties due to some chemicals not being present across all schools.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On leave next week</title>
      <link>/./2013/07/18/on-leave-next-week/</link>
      <pubDate>Thu, 18 Jul 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/07/18/on-leave-next-week/</guid>
      <description>&lt;p&gt;I’m on leave next week so am attempting to spend today and tomorrow getting ready some things finished before I disappear. This means finishing my contribution to two papers by one of the UPTECH PhD students, finding a new home for our personal sampling paper (Environmental Health Perspectives didn’t want it), getting SEB113 material ready for our 67 students next semester, contacting collaborators interstate about data, getting some Bayesian Network elicitation typed up and helping various PhD students with their data anlysis. It has been quite full on despite my supervisor being overseas.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ex Post Docto</title>
      <link>/./2013/07/08/ex-post-docto/</link>
      <pubDate>Mon, 08 Jul 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/07/08/ex-post-docto/</guid>
      <description>&lt;p&gt;I am now at the half-way point in my year-long postdoctoral fellowship. Since the start of the year the number of papers submitted with my name on them has approximately doubled, I’ve got my name on some grant applications (some successful, some not) and am co-writing a proposal for a PhD student position at ILAQH that I will likely end up co-supervising. It’s been quite the experience so far and it’s really only just getting started. I’ve been applying for lecturing positions at QUT and will continue to look further afield to see what’s out there that inspires me. Today the staff and post-docs in my group had a meeting to discuss the handling of lab business and how we maintain our space. For the longest time I’ve felt like a bit of an outsider, particularly with regards to lab stuff. I couldn’t tell you how to maintain a CPC, what the difference between a P-trak and Q-trak is or how to compare SMPS to NSAM data. I was not a member of the measurement team for UPTECH and my involvement in the research is mainly through data analysis and statistical consultation. Being given responsibilities within the lab is still a bit strange to me but I’m very happy to be helping out, as I am part of a team and I rely on those around me for my work. Statistics doesn’t happen in a vacuum (unless you’re a probabilist). A friend of a friend is finishing up their chemistry PhD and looking for work for next semester and beyond. They’re applying for a more technical job and we spent some time this evening with our mutual friend (who has recently started a postdoc) discussing how to rearrange the CV in order to best highlight their experience. I showed &lt;a href=&#34;http://samclifford.info/?attachment_id=291&#34;&gt;my own CV&lt;/a&gt; to explain what I wanted to highlight, as all three of us had different opinions on style, format, the flow of the text and whether to include a photograph or not. Obviously I’m pitching myself at academic, rather than technical, positions and I said that I believe professional experience in a lab is far more important to show off than academic awards from undergrad. An interesting moment in the conversation was the disbelief from the friend of a friend that I would make my CV so public. Why wouldn’t I want to show the world who I am, what I’m working on and what I’m interested in? It appears that developing multiple versions of a CV is necessary in order to have something to send to different bodies. University faculties are looking for a very different set of attributes than the Australian Research Council or other funding groups. I haven’t yet managed to whittle my CV down to two pages but I suspect it would include removing much of the tutoring and undergraduate experience I’ve had, my radio and TV interviews and conference organisation background, focussing instead on my top publications, professional experience and track record with grants. I will continue to need to tweak my CV as I continue to apply for jobs and this means having a look around for good resources from those who have gone before me. Some examples of advice I’ve come across are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://theresearchwhisperer.wordpress.com/2013/05/14/postdoc-chances/&#34;&gt;Boost your postdoc chances (at The Research Whisperer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://thesiswhisperer.com/2011/05/26/what-if-your-cv-is-not-enough-part-one/&#34;&gt;What if your CV is not enough? (at The Thesis Whisperer)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://trockeneisbombe.wordpress.com/2013/07/04/the-transit-from-phd-student-to-post-doc/&#34;&gt;The transit from PhD student to post-doc (at Trockeneisbombe)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of those blogs are worth following anyway. The next six months will be a challenge, as I attempt to juggle the remaining time in this postdoc with other commitments and the need to find ongoing employment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Stop, collaborate and listen</title>
      <link>/./2013/06/27/stop-collaborate-and-listen/</link>
      <pubDate>Thu, 27 Jun 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/06/27/stop-collaborate-and-listen/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://simplystatistics.org/2013/06/25/doing-statistical-research/&#34;&gt;Roger Peng posted at Simply Statistics&lt;/a&gt; about what it is to &lt;a href=&#34;http://stattrak.amstat.org/2013/06/01/how-to-do-statistical-research/&#34;&gt;do statistical research&lt;/a&gt; and how research is essentially solving problems that can’t be solved with the current methods. The message I took from Peng’s post is that often you can 90% solve a problem with current methods and that a lot of the time this is “good enough” and you can come back to the problem later with some new approaches that go beyond the current methods. As part of the UPTECH project I’ve been doing a lot of work with Bayesian hierarchical linear models. While our data has been collected from a panel design (25 schools, two weeks at each) it’s not always appropriate to use a full-blown spatial model. For example, the microbiological work I’ve been doing with my Finnish collaborator is mostly solvable by using exchangeable means priors to estimate classroom level and school level effects. Recently I’ve also had to start looking at clustering techniques, meta-analysis, spatial modelling of high-resolution data, estimating personal exposure, large surveys, and many other applied science problems that require a novel statistical approach. This sort of collaboration/consulting work, according to Terry Speed (whose post Peng is discussing), is a chance to meet lots of people and work on some interesting problems. For me, it has involved learning about existing techniques and trying to figure out how my collaborators and I can apply them to our data to do the best inference we can. With the UPTECH work, there’s always going to be a large list of authors due to the size of the project and the number of people involved in collecting data. Authorship will always be an issue with our papers, both in terms of inclusion and ordering, and we’ve got a decent process in place which makes people aware of papers as they’re finishing up (but not yet ready for submission). My personal belief is that one should always be able to point to a published paper and say “I did that”. Collaboration in applied physics and chemistry seems to be a very different beast to collaboration in statistics and mathematics. Many of the postgraduate students I know in Mathematics have tended to write methods papers with their supervisor(s) and that’s it. There’s the occasional collaboration to apply the method to a problem, but unless you’re working on cross-disciplinary modelling work or a large project involving numerical simulation there doesn’t appear to be much scope for multi-author work. Look back at some of the foundational statistical papers and you’ll see they’ve been written by a single author (some (non-parametric) Bayesian foundations spring to mind: &lt;a href=&#34;http://www.numdam.org/item?id=AIHP_1937__7_1_1_0&#34;&gt;de Finetti, 1937&lt;/a&gt;; &lt;a href=&#34;http://projecteuclid.org/DPubS?service=UI&amp;amp;version=1.0&amp;amp;verb=Display&amp;amp;handle=euclid.pjm/1102992601&#34;&gt;Kingman, 1967&lt;/a&gt;; and &lt;a href=&#34;http://projecteuclid.org/DPubS?service=UI&amp;amp;version=1.0&amp;amp;verb=Display&amp;amp;handle=euclid.aos/1176342360&#34;&gt;Ferguson, 1973&lt;/a&gt;). The question of when to collaborate, with whom, and what it will add is part and parcel of modern science but there are some fields where collaboration is rare and keeping the author list short &lt;a href=&#34;http://andrewgelman.com/2013/06/25/is-there-too-much-coauthorship-in-economics-and-science-more-generally-or-too-little/&#34;&gt;can lead to problems&lt;/a&gt;. Statistical research is necessary when there’s a problem to be solved that is 0% solvable with the current methods. Some of what I’m doing is novel, within the context of aerosol science, but I haven’t done as much stats research in my postdoc as in my PhD. This is no doubt a result of my doing as much collaboration as I am. I get to work on a lot of problems but there’s not much original statistical work in these papers; if I’m lucky I get to do some of the “10%” research. It’s hard to do statistical research in a physics group, especially as the only statistician here. I think if we had a second statistician in the group there’d be a lot more statistics being done both in terms of collaboration/consultation with the scientists and the methods we use to solve problems. The “Airports of the Future” project has quite a number of statisticians working on, among other things, Bayesian Networks, and they’re extending the BN methodology as well as applying it to a novel problem. Two of the members of this team gave a talk at BRAG this morning about visualisation of BN results. This is something I’ll no doubt need to learn about sooner or later as we plan on using BNs with another project that ILAQH is putting together. Four and a half years ago I was under the impression I was joining a physics group to do computational fluid dynamics. Since then I have been learning statistics almost constantly. It’s opened up many more opportunities for collaboration than CFD would have. The trick for me now is to try and put myself in a position where I’m working with other statisticians on statistics. We’ve got some work coming up soon with a more senior statistician at &lt;a href=&#34;http://www.ihbi.qut.edu.au/&#34;&gt;IHBI&lt;/a&gt;, which I hope will bring with it some opportunities for more statistical methodology work. Unrelated PS: The &lt;a href=&#34;http://andrewgelman.com/2013/06/26/dont-buy-bayesian-data-analysis/&#34;&gt;3rd edition of Gelman’s Bayesian Data Analysis&lt;/a&gt; is being released soon, with contributions from David Dunson and Aki Vehtari.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Trips interstate</title>
      <link>/./2013/06/06/trips-interstate/</link>
      <pubDate>Thu, 06 Jun 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/06/06/trips-interstate/</guid>
      <description>&lt;p&gt;I’m writing this morning while sitting in the corridor at the Woolcock Institute of Medical Research, Glebe NSW. I’m down here visiting some collaborators from the UPTECH project, working on reconciling the survey data from the 600 or so surveys that were sent home with school children during the UPTECH project. It’s different work to anything I’ve done because it involves sitting at a desk with another person and working together for the entire day. We’re double checking everything, sorting out our method and then implementing it where normally I’d just be mucking around and seeing what worked. We have a very disjoint set of skills as I’ve got a background in statistical computation and my colleague is an epidemiologist in a medical science group. This has its pros and cons, of course, because we can’t work in SAS/Access (what she’s used to) nor in R/MATLAB (what I’m used to). So a lot of it’s being done in Excel and custom add-ins for the time being. I have a feeling that today will be the day we start rifling through the boxes of paper surveys and comparing them to the double entered electronic versions. I’m staying with my sister-in-law in Botany while I’m in Sydney this week, which requires about an hour commute each way (if I get the right bus). Long commutes is apparently just what people do in Sydney. My sister-in-law works in Liverpool and drives 1-1.5 hours each way rather than spending two hours on public transport. It’s been a while since I’ve been in Sydney and I forget just how spread out the urban area is. I’m used to staying in Pymble and getting trains everywhere or crashing at friends’ places in the Inner West and being able to walk. It’s two buses from Botany to Glebe and the bus home can take a very long time to get out of the CBD and inner suburbs. Still, it’s nice to be able to walk around Glebe Point at lunch time. On Friday we’ll probably be visited by a few academics that I met last Friday a the &lt;a href=&#34;http://car-cre.org.au/&#34;&gt;CAR&lt;/a&gt; Investigators’ meeting in Melbourne. The meeting was the first time I’d met the group that are funding my 0.75FTE postdoctoral fellowship. It was great to meet the other post-docs (Christine Cowie, Martine Dennekamp, Yuming Guo) and see what they’re all working on. It’s quite a diverse group of people and projects in CAR and everyone was very excited about the prospect of even more collaboration withing the centre. This is the first time I’ve had any real contact with the centre; there are monthly seminars that are hosted using Adobe Connect but I’ve always been tutoring SEB113 when they’ve been on, so I haven’t had a chance to make it to any of them. I’ve caught up with Steve, a friend from undergrad maths at QUT who now lives down here and is doing computational statistics for an HIV research group. We had a drink and dinner last night (Tipple Bar and Bistro and Yulli’s vegetarian restaurant). We seem to have developed quite similar views on the role of stats in science and Bayesian statistics. We should keep in touch more, though, because it totally slipped my mind that he got married. The colleague I’m visiting here took me out to dinner in Newtown last night with her partner, where we stuffed ourselves full of Thai food and then decided to get some pastizzi but to go for a walk before attempting to eat them. I managed to eat two of them once I finally got home, and there’s a cherry cheese one waiting in my bag for morning tea once we earn ourselves a break (we’re using the Pomodoro technique to great effect). I’m not drinking as much coffee while I’m down here, which is partly due to my brother and sister-in-law not drinking coffee and the Woolcock Institute not being located within a university.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Statistics and microbiology</title>
      <link>/./2013/05/21/statistics-and-microbiology/</link>
      <pubDate>Tue, 21 May 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/05/21/statistics-and-microbiology/</guid>
      <description>&lt;p&gt;I’ve picked up a hobby over the last few months that is paying delicious dividends: homebrewing. It’s something I’d been wanting to try since about this time last year and I finally dropped the money (a cooking store voucher) on a cider homebrewing kit in February. My first batch was an apple cider that came with the kit and it’s been improving with age since the first bottle was opened in late February/early March. The second batch was a pear cider that a friend asked me to make for her; it was divided into two batches after primary fermentation so that I could try something different with the “excess”. The resulting pear and berry cider will make its debut quite soon, as it’s been patiently settling and aging over the last three weeks or so. While I haven’t been keeping time series of the specific gravity, temperature and colour of the cider as it brews, there is certainly grounds to do so. Brewing and statistics have a history which goes back at least as far as William Sealy Gosset, who developed the t-distribution (and test) under the name “Student” while working at the Guinness brewery in 1908. Brewing involves balancing complex ecosystems of a whole lot of different things (depending on what you’re making) and is essentially a giant biochemical experiment. To get properly into brewing requires an understanding of botany, chemistry, microbiology, physics and statistics as you attempt to turn your basic ingredients into something which is tasty, non-toxic and perhaps even effervescent. I would like to start brewing beer at home soon, which will no doubt lead to me reading a lot more about hops, malt, wort, grains and yeasts and taking more fastidious notes. So my exposure to microbiology has been twofold over the last year; working with a Finnish colleague on papers dealing with fungus and endotoxin counts in the UPTECH project and brewing my own alcoholic cider at home. The main fungus paper has been submitted and we’re checking the modelling on the endotoxin paper so that it can be submitted before this colleague leaves in the next few days. I can’t think of a more fitting thing to bring to her farewell party than a drinkable microbiology experiment. Bonus link: &lt;a href=&#34;http://www.reddit.com/r/Homebrewing/comments/1eghjq/op_delivers_wild_harvested_some_microbes_and_made/&#34;&gt;Homebrewing redditor who works in a microbiology lab discovers a new strain of fungus which produces the best beer he’s ever homebrewed&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Meta-analysis? Meta-regression?</title>
      <link>/./2013/05/14/meta-analysis-meta-regression/</link>
      <pubDate>Tue, 14 May 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/05/14/meta-analysis-meta-regression/</guid>
      <description>&lt;p&gt;Meta-analysis with a covariate feels really weird. I’m wanting to compare the relationship between the distributions of the mean concentration of endotoxin in the air and in dust samples across 50 locations. I wasn’t sure I did it the right way but the posterior estimates are consistent with my naïve approach of regressing the means of the air and dust samples. It’s important to account for the variability when doing this sort of &lt;em&gt;post hoc&lt;/em&gt; analysis because a point estimate of the mean doesn’t reflect anywhere near the full set of knowledge you have about your parameters of interest. On an unrelated note, another UPTECH paper has been &lt;a href=&#34;http://pubs.acs.org/doi/abs/10.1021/es400041r&#34;&gt;published&lt;/a&gt;. This one’s looking at spatial variation of particle number concentration in the school environment. Congratulations to Farhad Salimi, the first author of this paper, on the publication of his first paper. Farhad’s one of the PhD students on the UPTECH project and is due to finish his thesis later this year. I’ve worked with him on two of his papers (this one and another which has been submitted) and he’s really thrown himself into learning how to use R. This has not only made it easier for me to collaborate with him but it’s also made his analysis possible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I know the impact factor&#39;s not the be all and end all, but...</title>
      <link>/./2013/05/09/i-know-the-impact-factors-not-the-be-all-and-end-all-but.../</link>
      <pubDate>Thu, 09 May 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/05/09/i-know-the-impact-factors-not-the-be-all-and-end-all-but.../</guid>
      <description>&lt;p&gt;In Australia, at least, the impact factor of the journals you publish in plays a large role in your advance in academia. Universities are always under pressure to publish their research in more prestigious journals, conflating the impact factor of the journal and the impact of the research published in it. There are many ways journals can game their impact factor, many ways researchers can game the indices that describe the impact of their work, etc. That said, it’s always good to aim to produce research that will be accepted in a high quality journal. I’ve been excited about the PLoS journals since their launch and I believe QUT is a subscribing member, which means our publication fees are covered. It’s one of the best Open Access journal groups around and doesn’t appear to be a cash grab like some other publishers who are attempting to use Open Access as a business model to increase profits rather than because they believe in the free dissemination of research. UPTECH collected fungi and endotoxin data at the 25 schools, and we’re about to submit the fungi paper (which means work must continue on the endotoxin paper). I was considering whether we should submit to &lt;a href=&#34;http://www.plosone.org/&#34;&gt;PLoS One&lt;/a&gt; (IF 2011: 4.092) and then had a look at what other journals they have which may be an appropriate home. I really think once we get the clinical data from &lt;a href=&#34;http://www.woolcock.org.au/&#34;&gt;our Southern collaborators&lt;/a&gt; we should aim to do the best statistical modelling we can. I’m heartened by the fact that the head of the clinical group we’re working with has a strong background in stats and a desire to learn more Bayesian statistics. I don’t know if we can pull it off, but the prospect of having something investigating the role of fungi and endotoxin on child health published in &lt;a href=&#34;http://www.plospathogens.org/&#34;&gt;PLoS Pathogens&lt;/a&gt; (IF 2011: 9.172) is exhilarating.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New INLA stuff makes me happy</title>
      <link>/./2013/04/16/new-inla-stuff-makes-me-happy/</link>
      <pubDate>Tue, 16 Apr 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/04/16/new-inla-stuff-makes-me-happy/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;www.r-inla.org&#34;&gt;R-INLA&lt;/a&gt; is a really neat use of GMRFs for computing posteriors for quite complicated Bayesian Latent Gaussian Models. I used it for spatio-temporal modelling in my PhD and had to feel my way through a lot based on an old demo which was purely spatial. As I got further and further into my PhD I saw extensions for R-INLA being written thanks to a few visits from, and email correspondence with, &lt;a href=&#34;http://www.math.ntnu.no/~daniesi/&#34;&gt;Dr Daniel Simpson&lt;/a&gt;, and the help list on the R-INLA site where Dan, Håvard Rue and Finn Lindgren are very quick with a reply. A few days ago I got an email from Rue telling me he’d been made aware of &lt;a href=&#34;http://arxiv.org/abs/1206.3833&#34;&gt;one of my thesis papers&lt;/a&gt; and if I wouldn’t mind having a look at running it with the new testing distribution of R-INLA. It’s the first time I’ve looked at the code again since submitting the paper for publication and it seems that an awful lot of work has been put into internal optimisation. The code for running my model requires less manual tuning now and I’m excited about using it in follow-up papers where I’ll be looking at more of the UPTECH data. There’s also a &lt;a href=&#34;http://www.r-inla.org/examples/tutorials/spde-tutorial&#34;&gt;new tutorial for spatial modelling with INLA&lt;/a&gt;, written by &lt;a href=&#34;http://www.leg.ufpr.br/~elias/&#34;&gt;Elias T. Krainski&lt;/a&gt;, which covers a number of topics such as a simple spatial regression, a spatial model with misalignment and non-stationary spatial models (which I’ve seen talked about a few times but there’s very little documentation about them). I think R-INLA, particularly the spatial modelling, has really come a long way over the last few years and it’s encouraging to see it being taken up at QUT where students would probably have used WinBUGS in the past. While there are some limitations in terms of the flexibility of the classes of models that can be fit in BUGS versus R-INLA I’d much rather do any spatial, spatio-temporal or non-parametric smoothing in R-INLA.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Something I&#39;ve learned for BUGS/JAGS</title>
      <link>/./2013/03/19/something-ive-learned-for-bugs/jags/</link>
      <pubDate>Tue, 19 Mar 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/03/19/something-ive-learned-for-bugs/jags/</guid>
      <description>&lt;p&gt;Just quickly, I’m using JAGS with rjags to run some models for this fungal concentration paper I’m writing with our Finnish visitor (who leaves in a few months!). There are three levels of hierarchy in the experiment&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;span style=&#34;line-height:12px;&#34;&gt;school (i = 1 to 25)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;measurement site within school (j = 1 to 3)&lt;/li&gt;
&lt;li&gt;sample number at measurement site (k = 1 to K&lt;sub&gt;j&lt;/sub&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;which mean that I was constructing my data frame as a three dimensional array, y[i,j,k] where there were uneven numbers of samples at each site within each school. Furthermore, modelling y[i,j,k] ~ dnorm(mu[i,j,k],tau.y) was giving me problems because I couldn’t tell JAGS to monitor a three dimensional parameter. I figured out that it’d just be easier to treat the levels of measurement site and sample number as covariates that I could use as index counters in JAGS. I’ve got much simpler code now and JAGS is monitoring mu[i] (i = 1 to 261). Edit: It’s been a busy month. I hope to finally publish that blog post about SEB113 soon.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New things in Science and Engineering at QUT</title>
      <link>/./2013/02/18/new-things-in-science-and-engineering-at-qut/</link>
      <pubDate>Mon, 18 Feb 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/02/18/new-things-in-science-and-engineering-at-qut/</guid>
      <description>&lt;p&gt;Today was the first day of O week at QUT, a time when the relative calm of the summer break is disturbed by an influx of 17 year olds and university-run activities that always seem to generate a lot of noise. Is it possible to be a grumpy old man a week shy of 29? I received an email from my supervisor this morning asking if I could take over from one of the other PhD students in our group who had fallen ill last week and not recovered in time for a presentation this morning. The presentation, scheduled for 9am, was to be the first of the inaugural Nanotechnology and Molecular Science HDR (Higher Degree Research, i.e. Doctoral and Masters students) symposium. I’ve been moaning quietly, since starting my PhD in the School of Physical and Chemical Sciences, that the physics discipline had nothing like the School of Mathematics’ &lt;a href=&#34;http://samclifford.info/2012/09/07/qut-school-of-mathematics-postgrad-day-day-1/&#34; title=&#34;QUT School of Mathematics Postgrad Day - Day 1&#34;&gt;Postgrad Day&lt;/a&gt;. I really like Postgrad Day as it’s a good way to see what the other postgrad students are working on, what the research foci are within the school, and for students to improve their public speaking skills by delivering their research to a room of their peers and the other researchers in the school in an environment which is much more supportive than any conference is likely to be. The NMS HDR symposium brought together a number of students and staff from optics, aerosol science, nanomaterials, biotechnology, forensics and other fields within the discipline and allows them to see, perhaps for the first time, the research that others around them are doing. Even though my lab, ILAQH, is part of the Institute for Health and Biomedical Innovation, the distance between us and the remainder of IHBI is probably greater than just the physical distance between the two campuses. We do not seem to be particularly engaged with the culture of the remainder of IHBI and it’s very rare that our group will make the trek across to Kelvin Grove to see a presentation that is a short elevator ride away from the bulk of the IHBI membership. I have really only been to IHBI a few times. The two most recent appearances have been for the IHBI Olympics (a week of activities where research domains compete against each other in fun activities such as Iron Chef and photo scavenger hunt) in 2011 where I performed as part of the Health and Human Wellbeing domain’s talent quest entry, a four person improvisation troupe called “Ha ha… what?”, and to present the work that the PhD students of the UPTECH project had been working on (where we killed half an hour of time before the presentations by playing impro warm-up games). Continuing in this spirit of improvising in front of scientists, I spoke to the NMS HDR symposium at 45 minutes’ notice and in an eight minute talk managed to touch on the key points of the UPTECH project, explaining a small fraction of the science and discussing the richness of the dataset, the questions it will allow us to answer, and the diverse range of people we have involved in the project. I was told by one of the research staff in our group afterwards that it was refreshing to see a talk with no slides and that they were impressed at the quality of a talk that contained such a small amount of preparation and wondered whether I could give a presentation without speaking. Professor Dennis Arnold, the organiser of the symposium, is now based on the same floor as me; he is one of a handful of people on our floor who are not members of ILAQH. I asked him if he thought the day was a success and he was very positive. I sincerely hope that the NMS HDR symposium continues next year and well into the future, as a way to foster interest across the traditional divide of physics vs chemistry. I had to duck out of the symposium early to attend a meeting about one of the new units in the revamped Bachelor of Science degree. Dr Sama Low Choy, one of my supervisors, has asked me to run one of the collaborative workshops in the new &lt;a href=&#34;http://www.qut.edu.au/study/unit-search/unit?unitCode=SEB113&amp;amp;idunit=44499&#34;&gt;quantitative methods unit&lt;/a&gt; (she says it’s because of my impro skills). Today was one of the planning days where we got to grips with the structure of the unit, the way the workshops are to be run and how what we are doing is significantly different to anything we’ve done before. I’ll write more about it later, such as after my first tutorial, but it’s very exciting to see QUT break with tradition and make this unit happen. Through case studies with data sets relevant to their discipline, students will learn about quantitative methods in mathematics and statistics. We are ditching &lt;em&gt;t&lt;/em&gt; tests, removing the need for statistical tables, adding structure to the group work to ensure people don’t get to ride on the effort of others and teaching R and MATLAB in a first year unit that only supposes Maths B. I’m really excited that we’re teaching first year students how to use software that is free (well, at least R is) and far more powerful than Microsoft Excel. One of the problems with MAB101, the old unit, was that the computation was done in Minitab, a piece of software that I’ve never known any researcher to use. One of the workshop leaders said that they want to go back and do undergrad again knowing that this unit now exists; I don’t blame them. This will definitely be an exciting year for me, academically. A new course with new units, new facilities in the Science and Engineering Centre, new collaboration opportunities and the chance to pick somewhere new to move to at the end of the year.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I seem to be taking on a lot of work right now</title>
      <link>/./2012/11/12/i-seem-to-be-taking-on-a-lot-of-work-right-now/</link>
      <pubDate>Mon, 12 Nov 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/11/12/i-seem-to-be-taking-on-a-lot-of-work-right-now/</guid>
      <description>&lt;p&gt;For someone who’s meant to be finishing his PhD I sure do have a lot of other peoples’ papers on my plate. Today and Friday I had a chat with another PhD student from the UPTECH project about looking for spatial variation within the UPTECH schools. We’ve got some divergent ideas about how to go about it but we sat down this afternoon and spent some time going over regression modelling versus exploratory/summary statistics and how we can move from using Spearman’s rank correlation coefficient to doing non-parametric function estimation. I wrote some code and commented it as we went, so it should be fairly straightforward to write the accompanying methodology subsection for the paper. I’m going to spend the week focussing on my final thesis paper (a spatio-temporal model for data from a split panel design). I got some comments back from my supervisors last week and there’s a lot to be done checking certain sources of variation. I spent a fair bit of time today looking over a former students’ papers, checking old email threads, discussing a few things with the co-authors of his papers who are still around and have even been tracking down which particular instruments were used to perform the measurements. It’ll be important to check that my spatial analysis of the within-school variation matches up with the other UPTECH student’s analysis. If we come to opposite conclusions then at least one of us is wrong. I’m now tossing up whether I should check my results from the supercomputer or wait until tomorrow.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bayes on the Beach</title>
      <link>/./2012/11/08/bayes-on-the-beach/</link>
      <pubDate>Thu, 08 Nov 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/11/08/bayes-on-the-beach/</guid>
      <description>&lt;p&gt;I’ve spent the last three days at the Bayes on the Beach conference/workshop in &lt;a href=&#34;https://maps.google.com.au/maps?q=caloundra&amp;amp;hl=en&amp;amp;sll=-19.457034,145.879162&amp;amp;sspn=35.100111,39.506836&amp;amp;hnear=Caloundra+Queensland&amp;amp;t=m&amp;amp;z=14&amp;amp;iwloc=A&#34;&gt;Caloundra&lt;/a&gt;. The meeting is an annual event where Bayesian statisticians (usually Australians who know Kerrie Mengersen) get together for a very casual set of talks, workshops and other activities in a beachside town.&lt;/p&gt;
&lt;div id=&#34;design&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Design&lt;/h3&gt;
&lt;p&gt;We arrived in Caloundra on Tuesday morning and got down to business with a keynote talk from &lt;a href=&#34;http://www.southampton.ac.uk/maths/about/staff/davew.page&#34;&gt;Dave Woods&lt;/a&gt; (University of Southampton). Professor Woods’ talk opened a day in which the over-arching theme was experimental design and made the point that any design is at least implicitly Bayesian. I really agree with this point because any design is based on the prior experience of the experimenter or is pieced together from a review of what’s been done previously. I don’t know of any situation in which an experimental study was carried out totally at random without choosing appropriate covariate values. I don’t have much of a head for design but I think after seeing the talks on Tuesday (particularly Liz Ryan’s, which others in her session praised as giving a good review of utility) I’m a bit more aware of what it all means. What really helped was &lt;a href=&#34;http://pharmacy.otago.ac.nz/our-people/academic-staff/stephen-duffull&#34;&gt;Stephen Duffull&lt;/a&gt; (University of Otago) in his Thursday talk where he spelled out D-optimality (wanting to maximise the effect) and P-optimality (wanting to get the best estimate of parameters). D- and P-optimality work in opposite directions quite frequently (killing all your patients doesn’t tell you much about the parameters in your model, for example) but it’s possible to trade them off with a DP-optimal design.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;workshops&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Workshops&lt;/h3&gt;
&lt;p&gt;One of my favourite aspects of the Bayes on the Beach meetings is the workshops. At my first Bayes on the Beach (2009) we were shown how to do a Bayesian meta-analysis to combine the results of a bunch of disparate studies that dealt with the same topic. Ever since then, I’ve been looking forward to learning some more statistics or getting to grips with interesting data. &lt;a href=&#34;http://datasearch2.uts.edu.au/science/staff/maths/details.cfm?StaffID=11641&#34;&gt;Matt Wand&lt;/a&gt; (University of Technology Sydney), &lt;a href=&#34;http://data.aims.gov.au/staffcv/jsf/external/view.xhtml?partyId=900000428&#34;&gt;Julian Caley&lt;/a&gt; (Australian Institute of Marine Science) and &lt;a href=&#34;http://staff.qut.edu.au/staff/lowchoy/&#34;&gt;Sama Low Choy&lt;/a&gt; (Queensland University of Technology, my associate supervisor) each pitched a problem that people could have a look at, not necessarily solving but, working towards a solution. Wand presented some really interesting spatio-temporal data of extreme rainfall in NSW which I was very keen to sign up to but Kerrie suggested that it might be a bit more of a challenge to do something other than spatio-temporal modelling of environmental data. Sama presented some work that she’s been doing on combining elicited opinions into a subjective prior that represents the aggregate knowledge of experts. I ended up in Caley’s group, where we worked on some data that &lt;a href=&#34;http://scholar.google.com/citations?user=T-nbIuUAAAAJ&amp;amp;hl=en&#34;&gt;Julie Vercelloni&lt;/a&gt; is dealing with as part of her PhD.&lt;/p&gt;
&lt;div id=&#34;reef-workshop&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Reef workshop&lt;/h4&gt;
&lt;p&gt;Caley, Vercelloni and Mengersen (among others) are working on coral coverage in the Great Barrier Reef in six sectors that run up the length of the reef (2600km). Within each sector there are reef shelves and on each shelf there are multiple reefs with multiple measurement patches. The question we attempted to answer was “How different are the long term trends in coral coverage at these reefs?” Caley has data going back to about 1994, reported annually, which when pooled looked very boring but when plotted (very well by Vercelloni) grouped by reef shelf within sector indicated that there might be quite a lot of interesting variation which may not be so straight forward to model. Our group split up into a few subgroups with different approaches and I ended up working with James McKeone and a few others on a model inspired by &lt;a href=&#34;http://samclifford.info/2012/10/19/anova/&#34; title=&#34;ANOVA&#34;&gt;Cari Kaufmann’s functional ANOVA with GP priors&lt;/a&gt;. Over the next day or so McKeone took what we’d discussed and written down as a model and came up with quite a general Gibbs sampling scheme that is flexible enough to admit any linear predictor. I’m fairly certain James and I both had P-splines in mind but I did talk later to Matt Wand about O’Sullivan splines and I think it might be conceptually easier to use Wand’s low rank thin plate smoothers, particularly as Vercelloni’s quite new to Bayesian statistics and has a background in ecology rather than computational statistics. It was interesting to see how the other workshops went on the Thursday afternoon recap. Sama’s group had split into three groups, each tackling the issue of elicitation with a different topic and a different angle. I must say that my favourite was the group who did an elicitation of predictions of the outcome of the US Presidential Election. &lt;a href=&#34;http://conidialcoleopticide.wordpress.com/&#34;&gt;Luisa Hall&lt;/a&gt; even managed to elicit my opinion for her survey without me even realising it (we talk a lot about politics)! The other groups asked about how risky a life-saving operation would have to be for them to not take it and average completion time for PhD students (which Sama gave a talk about on Thursday).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;real-time-updates-for-mean-field-variational-bayes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Real time updates for Mean Field Variational Bayes&lt;/h3&gt;
&lt;p&gt;Matt Wand also gave a talk and tutorial about using Mean Field Variational Bayes (a name he attributes to Mike Jordan) to do live, real-time updates of posterior estimates with streamed data such as stock trading. Rather than going into the content of the talk, I suggest you read &lt;a href=&#34;http://www.uow.edu.au/~mwand/ovbpap.pdf&#34;&gt;the paper&lt;/a&gt; he’s written with Tamara Broderick (University of California, Berkeley) and his PhD student Jan Luts (University of Technology Sydney) and check out &lt;a href=&#34;http://realtime-semiparametric-regression.net/&#34;&gt;their website&lt;/a&gt; with neat examples, e.g. &lt;a href=&#34;http://realtime-semiparametric-regression.net/SydneyRealEstate/&#34;&gt;the Sydney rental market&lt;/a&gt; (which I think would be fascinating with the train lines superimposed).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;games-and-posters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Games and Posters&lt;/h3&gt;
&lt;p&gt;Tuesday and Wednesday evenings had Luisa and I running some games (&lt;a href=&#34;http://en.wikipedia.org/wiki/Fictionary&#34;&gt;Dictionary&lt;/a&gt; and &lt;a href=&#34;http://boardgamegeek.com/boardgame/38159/ultimate-werewolf-ultimate-edition&#34;&gt;Werewolf&lt;/a&gt;) before the poster sessions. It’s interesting running games like this with Bayesians because Dictionary is basically a problem of credibility of unknown experts and Werewolf is all about updating an initially uninformative prior with information based on peoples’ behaviour as they accuse others while trying to avoid being lynched. The poster sessions themselves were quite good, with a wide variety of applications and methodologies being presented. Everyone seemed quite keen to talk about their posters and they were generally of a high quality. On Thursday afternoon I gave my talk about spatio-temporal modelling of the UPTECH data as a case study for INLA. I got a few questions about the versatility of INLA and my choice of random walk and spline models instead of other bases as well as comments about the spatial modelling I’m doing. Definitely some things to think about for the next papers I write.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-success&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A success&lt;/h3&gt;
&lt;p&gt;The organisers of Bayes on the Beach (Nicole White, Matt Moores, Jannah Baker and Dow Jaemjamrat) all did a really good job and I think everyone had a good time but was also inspired. I had a few minor issues (timekeeping is a perpetual bugbear of mine and I’m yet to go to a conference that runs totally on schedule) but think that the meeting did a really good job of bringing together a disparate group of researchers and introducing them to each other and providing ideas for future work and employment opportunities (Kim-Anh Do did a really good job of selling the &lt;a href=&#34;http://www.mdanderson.org/&#34;&gt;MD Anderson Cancer Center&lt;/a&gt;). I think the challenge for future Bayes on the Beach meetings will be managing the growth in the number of attendees. I look forward to next year’s meeting; I might even have some time to go to the beach!&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Turning tables into graphs</title>
      <link>/./2012/10/30/turning-tables-into-graphs/</link>
      <pubDate>Tue, 30 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/30/turning-tables-into-graphs/</guid>
      <description>&lt;p&gt;One of the things I’ve noticed from working with scientists (of various background) is that they love tables full of means and standard deviations as a way of summarising the variability in some data or regression parameters. &lt;a href=&#34;http://andrewgelman.com/2012/10/communication-is-a-central-task-of-statistics-and-ideally-a-state-of-the-art-data-analysis-can-have-state-of-the-art-displays-to-match/&#34;&gt;Andrew Gelman’s latest discussion of a paper&lt;/a&gt; makes the point that tables of numbers are awful and that a well made graphic does a good job of conveying the uncertainty. He refers in his comment to a paper he wrote, “Let’s Practice What We Preach: Turning Tables into Graphs” [1], which shows how graphs can be better at summarising variability, often in less space than a table. Another thing I really like about the paper is that it endorses the use of R/S/S+ for plotting and faults Excel for not offering enough control to the user (and it makes ugly graphs anyway). I’m a big fan of using graphs because numbers don’t really mean that much to me, especially when dealing with things like splines and random walk models for non-linear function estimation. The UPTECH papers I’m writing on the fungal data and nanotracer measurements have a lot of graphs where previously there were tables or Excel plots which weren’t as easy to interpret. I’ve been spending quite a bit of time on them so that we can present to our readers, for example, just how different the means are in our hierarchical Bayesian model. I think tables have a place and I use them in my own papers. I’m using a table in a spatial modelling paper to describe the prevailing winds and local geography at each of 13 measurement locations. There’s a map of the locations so that I don’t have to put things like “location” in the table. A list of features doesn’t translate as well to a plot as spatial locations do. I don’t think it’s appropriate to list row upon row of means, standard deviations, quantiles, etc. Long/wide tables of model fit criteria such as MSE, AIC, R&lt;sup&gt;2&lt;/sup&gt;, adjusted R&lt;sup&gt;2&lt;/sup&gt;, etc. are incredibly boring and do not scale well when you’re comparing more than, say, three models. I think I might try to send this paper around my group as an attempt to convince them to abandon tables in favour of concise graphs. With the uptake of R among some of the more senior researchers/staff looking promising, I think it’s a message that might actually get some traction. [1] Gelman, Andrew, Pasarica, C., and Dodhia, R. (2002). Let’s practice what we preach: turning tables into graphs. American Statistician 56, 121-130. [&lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/dodhia.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ANOVA</title>
      <link>/./2012/10/19/anova/</link>
      <pubDate>Fri, 19 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/19/anova/</guid>
      <description>&lt;p&gt;ANOVA is one of those things that all the scientists in my group do when writing a paper where there’s more than one group, which is totally natural and a good first step for data analysis. Whether it’s looking at the mean concentration of some aerosol at the UPTECH schools, the level of diesel engine emissions by fuel type or some other experimental setup, ANOVA will typically make it into a paper (even if only as a &lt;em&gt;t&lt;/em&gt; test). ANOVA (or a &lt;em&gt;t&lt;/em&gt; test) may not always be an appropriate test to use, e.g. if the data is not normal, has a few large outliers or exhibits some sort of reliance on a covariate. In such cases it may be better to use a regression model with a non-Gaussian likelihood. This week I’ve spent a bit of time getting to grips with the Mann-Whitney U test as a way of testing medians, another summary which is used for aerosol concentrations. It’s not featured in Excel, so the person I was helping had to dust off their SPSS skills and we eventually made our way through and figured out how to run the test. But descriptive statistics of quantiles or measures of central tendency aren’t nearly as exciting as something I’ve come across, functional ANOVA. I met Cari Kaufman at ISBA earlier this year and we had a bit of a chat about spatio-temporal models of climate data with Gaussian processes and Gaussian Markov Random Fields. When I got back to Brisbane I decided to have a look at what she’s written and whether I should think about applying to work with her at Berkeley. Kaufman has &lt;a href=&#34;http://ba.stat.cmu.edu/journal/2010/vol05/issue01/kaufman.pdf&#34;&gt;a 2010 paper&lt;/a&gt; [1], which appears to have its genesis &lt;a href=&#34;http://andrewgelman.com/2007/10/anova/&#34;&gt;at least as far back as 2007&lt;/a&gt;, where functional ANOVA is discussed as a way of testing whether some observed effect (which may be a nonlinear function) is the same across groups. The examples given include temperature records in Canada and spatio-temporal modelling of regional climate in the UK. I would like to go over the functional ANOVA paper with the QUT NP Bayes reading group, as it’s a very interesting use of the Gaussian process prior. I’d also like to use it in my own work, as the question “Is the daily trend the same at each school?” is of interest to me. [1] Cari G. Kaufman and Stephan R. Sain, “Bayesian Functional ANOVA Modeling Using Gaussian Process Prior Distributions”, &lt;em&gt;Bayesian Analysis&lt;/em&gt; 5, 2010, pages 123-150. [&lt;a href=&#34;http://ba.stat.cmu.edu/journal/2010/vol05/issue01/kaufman.pdf&#34;&gt;PDF&lt;/a&gt;]&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Looking at microbes with BUGS</title>
      <link>/./2012/10/15/looking-at-microbes-with-bugs/</link>
      <pubDate>Mon, 15 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/15/looking-at-microbes-with-bugs/</guid>
      <description>&lt;p&gt;I’m working on a paper with &lt;a href=&#34;http://www.uku.fi/hallinto/viestinta/alumni/alumnijuttu3.shtml&#34;&gt;Heidi&lt;/a&gt; &lt;a href=&#34;http://www.linkedin.com/pub/heidi-salonen/20/1b5/677&#34;&gt;Salonen&lt;/a&gt;, a Finnish microbiologist who’s been with us for quite some time and is working on the microbiological (e.g. fungi, bacteria) aspects of the UPTECH project. Due to the timeframes of our presence at each school and the amount of time it takes to measure microbiological activity, we only have a handful of measurements at each school. This represents a perfect opportunity to do some very simple Bayesian hierarchical modelling in order to estimate a distribution of possible microbe concentrations at each school. It’s not a particularly taxing task (it’s more or less the kind of thing that you might find in Gelman’s textbook) but it’s still a nice example of how you can use Bayesian modelling to estimate the mean of a bunch of schools by assuming that the mean and standard deviation at each school are themselves drawn from a distribution of means and standard deviations. I’ve done the modelling, sure, but the next step is to explain it to Heidi and the other co-authors in such a way that they feel comfortable putting something in the paper that’s a little beyond taking the mean of the data and standard deviation of the data as summaries for the microbial concentrations at each school. So it was nice to dust off the old &lt;a href=&#34;http://www.openbugs.info/w/&#34;&gt;OpenBUGS&lt;/a&gt; and write out a simple model with prediction within each school based on the repeated sampling available to us. We hope to use this simple model as the basis of a model which includes covariates and perhaps a bit more random effects modelling. So I don’t have to keep manually copying and pasting data from Excel files I’ll be looking at getting back into using &lt;a href=&#34;http://cran.r-project.org/web/packages/rjags/index.html&#34;&gt;rjags&lt;/a&gt;, &lt;a href=&#34;http://cran.r-project.org/web/packages/R2jags/index.html&#34;&gt;r2jags&lt;/a&gt;, &lt;a href=&#34;http://cran.r-project.org/web/packages/BRugs/index.html&#34;&gt;BRugs&lt;/a&gt; and &lt;a href=&#34;http://cran.r-project.org/web/packages/R2WinBUGS/index.html&#34;&gt;R2WinBUGS&lt;/a&gt;. One of my colleagues in BRAG thinks I should just write my own sampler in MATLAB for this as it’ll be faster, but with so few observations (6-15 at each of 25 schools) speed’s not a huge issue here.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New paper from Trondheim&#39;s INLA group (arXiv)</title>
      <link>/./2012/10/03/new-paper-from-trondheims-inla-group-arxiv/</link>
      <pubDate>Wed, 03 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/03/new-paper-from-trondheims-inla-group-arxiv/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://arxiv.org/abs/1210.0333&#34;&gt;Martins, Simpson, Lindgren and Rue&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The INLA approach for approximate Bayesian inference for latent Gaussian models has been shown to give fast and accurate estimates of posterior marginals and also to be a valuable tool in practice via the R-package R-INLA. In this paper we formalize new developments in the R-INLA package and show how these features greatly extend the scope of models that can be analyzed by this interface. We also discuss the current default method in R-INLA to approximate posterior marginals of the hyperparameters using only a modest number of evaluations of the joint posterior distribution of the hyperparameters, without any need for numerical integration.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I’m using R-INLA for two UPTECH papers at the moment and I’m really interested in the replication functionality in 3.2 and the Kronecker functionality in 3.6, which seems to be a more “official” version of the work I’ve been doing rolling my own precision matrices for use with the generic0 model class. R-INLA is definitely a worthwhile piece of software to learn to use and the stochastic PDE model for spatial inference is one of the coolest things I’ve seen in terms of spatial modelling. I wonder if the Kronecker stuff in 3.6 will let me define a separable product of a stochastic PDE model and a model for the time series component.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data visualisation</title>
      <link>/./2012/10/02/data-visualisation/</link>
      <pubDate>Tue, 02 Oct 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/10/02/data-visualisation/</guid>
      <description>&lt;p&gt;Last week I had a chat with one of Kerrie Mengersen’s new MSc students about the UPTECH work I’ve been doing. Aleysha Thomas will be working on scientific visualisation of statistical modelling/inference/analysis and has been talking to some of the other students in our stats group to get an idea of what sort of work we do and what sort of stuff there is to visualise. For example, my doing semi-parametric regression with splines means that the marginal densities of the parameters aren’t as interesting as the fitted smooth which is comprised of those parameters multiplied by B-spline basis vectors. A tensor product of two splines is better off visualised with a contour plot than with a list of coefficients and their credible intervals. My work involves spatio-temporal modelling but I don’t present it as a spatial map if the temporal variation is more interesting. At some point, though, I’ll be publishing graphs of continuous space spatial random effects and that will require some thought as to how the uncertainty in the estimates is represented. At the moment I’m just using levelplot() to plot the mean and standard deviation, but there are other options such as stacked surface plots and contour plots. &lt;a href=&#34;http://www.linkedin.com/in/matthewmoores&#34;&gt;Matt Moores&lt;/a&gt; does spatial statistics as well (cone beam and fan beam CT scans for radiotherapy treatment) but deals with completely different data, methods and visualisation techniques. In addition, our audiences’ only overlap is statisticians. Pitching to your audience is a very important part of presenting your work, whether it’s at a conference, in a journal article or to your PhD seminar panel. It’s no good me coming up with a beautiful way of representing my inference if it’s impossible for others to understand. Hopefully with Aleysha on board our stats group will be exposed to new ways of visualising data and inference. My stats group is certainly better than my aerosols group when it comes to graphical representation of data and results, but we can still be doing better (myself included).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Third time&#39;s a charm</title>
      <link>/./2012/09/25/third-times-a-charm/</link>
      <pubDate>Tue, 25 Sep 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/09/25/third-times-a-charm/</guid>
      <description>&lt;p&gt;After getting rejected by an applied statistics journal and a more methodological statistics journal we’ve decided to send the Finnish paper to an environmental statistics journal. I think it’s a more natural home for this paper as it straddles the boundary of model development and the analysis of observational environmental data. A new version of the preprint will appear &lt;a href=&#34;http://arxiv.org/abs/1207.0558&#34;&gt;on arXiv&lt;/a&gt; in about 12 hours. I’m also still redrafting the first UPTECH paper of my thesis. With the Finnish paper resubmitted it’ll be the focus of my work over the next few days. I think the modelling is now much improved (although I might try an alternative specification) after taking reviewer comments into account from its earlier rejection. Once I’ve got this last modelling question sorted out and the analysis is written up (not much has to change in the methodology section) I can restart work on my final thesis paper. There are two similar papers coming up in my immediate post-thesis future where I’m going to have the chance to learn more about the use of Gaussian processes. While INLA does some nice GMRF approximations for Gaussian fields [1] there are some challenges that we’ll face with this data. I might also need to read up on the use of dynamic linear models for modelling the evolution of a parameter with time. [1] Lindgren, F.; Rue, H. &amp;amp; Lindström, J. (2011) An explicit link between Gaussian fields and Gaussian Markov random fields: the stochastic partial differential equation approach, _Journal of the Royal Statistical Society: Series B (Statistical Methodology)__ 73_, 423-498. &lt;a href=&#34;http://www.math.ntnu.no/inla/r-inla.org/papers/spde-jrssb-revised.pdf&#34;&gt;R-INLA&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>UPTECH paper review</title>
      <link>/./2012/09/19/uptech-paper-review/</link>
      <pubDate>Wed, 19 Sep 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/09/19/uptech-paper-review/</guid>
      <description>&lt;p&gt;I’m currently reworking the &lt;a href=&#34;http://arxiv.org/abs/1206.3833&#34;&gt;second paper&lt;/a&gt; of my thesis (or at least the paper that was planned as the second paper) to address the reviewers’ comments. Probably the biggest problem with the split panel design we’ve ended up with is that there are no measurements from the long term monitoring stations at the same time as the first ten schools’ measurements are being taken. So, what’s due to annual variation [1] and what’s due to spatial variation, e.g. [2]? This has meant going back to our models and looking at more appropriate ways to model the spatial and temporal trends to allow us to decouple the spatial and temporal variation. I’ve still got to finalise things with my supervisors, but I think if we focus less on model comparison and talk more about the computational issues and put forward a single model (which will be used as the basis for the third paper of my PhD) then we’ll have a good paper for a journal which focuses more on the scientific application than the statistical theory. After all, the paper is not a novel contribution to the field of semi-parametric regression but it’s a very novel application of semi-parametric regression to multi-site observational data recorded from a split panel design. All in all I think the paper is much more at home in the aerosol science literature than the applied statistics literature and the comments we got upon the previous rejection will make it a better paper. I’m certainly much more optimistic about this paper than I was immediately after its rejection. I showed some of the results of the new modelling to some colleagues today and while the interpretation of the graphs wasn’t immediately obvious (I showed them pictures without explanatory text) they seemed interested in what it said about the UPTECH study. [1] Mejía, Jaime F., Wraith, Darren E., Mengersen, Kerrie L., &amp;amp; Morawska, Lidia (2007) Trends in size classified particle number concentration in subtropical Brisbane, Australia, based on a 5 year study. Atmospheric Environment, 41(5), pp. 1064-1079. &lt;a href=&#34;http://eprints.qut.edu.au/5778/&#34;&gt;QUT ePrints&lt;/a&gt;. [2] Mejía, Jaime F., Morawska, Lidia, &amp;amp; Mengersen, Kerrie L. (2008) Spatial variation in particle number size distributions in a large metropolitan area. Atmospheric Chemistry and Physics, 8(5), pp. 1127-1138. &lt;a href=&#34;http://eprints.qut.edu.au/15395/&#34;&gt;QUT ePrints&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My first field work</title>
      <link>/./2012/09/17/my-first-field-work/</link>
      <pubDate>Mon, 17 Sep 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/09/17/my-first-field-work/</guid>
      <description>&lt;p&gt;It’s been three and a half years since I started my PhD program and the UPTECH measurement campaign finished a matter of weeks ago. So I’m a little late to the game but last week was my first field trip campaign. Rohan Jayaratne had been trying to organise this trip over the last two weeks, waiting for a time where the wind would be blowing in the right direction, checking the wind forecasts every day for a while. On Tuesday we finally headed out to do the measurements with another PhD student, Megat Azman Megat Mokhtar. We’d had talks about what sort of questions we’d be attempting to answer and how we could ensure we collected data that would allow us to answer them. What started out as a fifteen minute chat about equipment turned into a long discussion about semi-parametric regression and how interactions of non-linear effects can be fit. What was going to originally be just a publication of some observational results is probably going to end up with some generalised additive models attempting to model the interactions we expect to see. Rohan, Megat and I packed up the car at about 8:30 and drove out to the Gateway Motorway to do some roadside measurements. We took some &lt;a href=&#34;http://www.aerasense.com/&#34;&gt;Nanotracers&lt;/a&gt; and a CPC and spent the day taking continous measurements. The Nanotracers are very new and we’ve been using them with &lt;a href=&#34;http://www.ilaqh.qut.edu.au/Misc/UPTECH%20Study%20Design%2029%20July%202011.pdf&#34;&gt;UPTECH&lt;/a&gt; to measure child exposure to ultrafine particles. It was interesting to see the setup of the equipment and gave me a greater appreciation for just how much work everyone put in to the UPTECH study. [caption id=“attachment_478” align=“aligncenter” width=“225”][&lt;img src=&#34;p9120053.jpg?w=225&#34; title=&#34;Sam wearing nanotracers&#34; /&gt;](&lt;a href=&#34;http://samcliffordinfo.files.wordpress.com/2012/09/p9120053.jpg&#34; class=&#34;uri&#34;&gt;http://samcliffordinfo.files.wordpress.com/2012/09/p9120053.jpg&lt;/a&gt;) The Philips Aerasense Nanotracer: fastest personal sampler in the West[/caption] Megat brought two walkie-talkies with him for us to use to communicate when one of us was away from where we’d set up. To relieve the (my?) boredom in some parts, I treated Megat and Rohan to a rendition of Toto’s “Africa” and Four Non Blondes’ “What’s Up?” (often called “What’s going on?”). The weather was very pleasant, the wind more or less exactly what we wanted and we managed to get about six hours of measurements before heading home. We’re now at the stage of having the data cleaned (checking for errors in the measurements) and doing some exploratory data analysis. In the coming weeks, provided I’ve got time for it, we’ll be looking at our modelling. I hope to put a preprint up when we’ve submitted it. It’s going to be a very interesting piece of modelling and Rohan sees it as an update to a paper our group has previously written but with better analysis and a more novel data collection technique. I’m excited.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Databases</title>
      <link>/./2012/08/31/databases/</link>
      <pubDate>Fri, 31 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/31/databases/</guid>
      <description>&lt;p&gt;I spent some time this morning with Tenzin, one of our PhD students, and Xuan Ling, a team member of ours who leaves us today, discussing the use of Access for Tenzin’s project. The last time I really paid much attention to databases was in 2000/2001 when my senior IPT class was learning about them. I learned SQL with MicroSQL (which I can’t find a reference to on Google) and while we did use Access to build a simple database it was only through the form and query point and click interface. So this morning’s meeting was me scribbling out database design a la Visio Modeller (before Microsoft bought it) to try and work out what sort of tables would be needed and then trying to figure out how on earth to build said tables. Tenzin’s way ahead of me here with the database from his pilot questionnaire and he’s got some very cool subdatasheet stuff going on. If I knew how Access works it would have been a much more productive meeting this morning but it was still good to try to figure it out together. I’ve had more success with getting R to talk to our big UPTECH database through ODBC. It’s the first time I’ve done anything like it and I’m managing, with some success, to get stuff into R. There are a few bizarre design choices in the database so it’s not as straightforward as it could be, but I can copy the text from the Access queries and get what I need. I’d much rather grab a chunk of data and process it in R than open Access, run some queries to get the data I want, save it as an Excel file, convert it to CSV and then load it into R.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Starting more papers</title>
      <link>/./2012/07/17/starting-more-papers/</link>
      <pubDate>Tue, 17 Jul 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/07/17/starting-more-papers/</guid>
      <description>&lt;p&gt;One of the benefits of being a statistically curious researcher is that you get to read about all sorts of cool stuff. The UPTECH project is generating a huge amount of time series data, some of which have change points, non-linear behaviour, trends, and all sorts of other quirks. I’ve spent most of my time learning about the use of splines but over the last year have been exposed to Gaussian processes (and I guess I would say splines are a special case) and Gaussian Markov Random Fields. I’ve been having the occasional chat with the other researchers about how to analyse the time series data they’re working with and have stumbled across some really neat methods. Apart from the work I’ve been doing on spline models with my Finnish collaborators, interesting ideas for analysing time series data include Treed Linear Models, Treed Gaussian Processes [1,2] and Dirichlet Process Mixtures of GLMs [3]. The tree nature of the first two models I mentioned is apparent in its partitioning of the covariate space into regions in which the behaviour is locally linear. Change points are placed where the behaviour changes and each partition has its own linear mean and its own variance estimate. This is a fairly simple model to fit but it’s a bit limited by its only using linear functions. The treed GP relaxes this and spends its time fitting a more GP within each partition, with the focus on the covariance relationship. The third, DP mixtures of GLMs gives much smoother estimates of the mean and credible interval and has some really nice properties courtesy of the DP (which looks to be superior to tree based clustering). I find the tree structure of these models quite interesting and the treed linear model appears to be, conceptually, a mix of a multiple changepoint model and a piecewise linear regression spline with wombling knots. I’m not 100% sure how to apply these but an initial chat makes me think they will be very applicable and I’m looking forward to some exploratory data analysis. [1] [Gramacy, R. B. (2007). tgp: An r package for bayesian nonstationary, semiparametric nonlinear regression and design by treed gaussian process models. Journal of Statistical Software 19(9), 1-46.](&lt;a href=&#34;http://www.jstatsoft.org/v19/i09/&#34; class=&#34;uri&#34;&gt;http://www.jstatsoft.org/v19/i09/&lt;/a&gt;) [2] [Gramacy, R. B. and H. K. H. Lee (2008). Bayesian treed gaussian process models with an application to computer modeling. Journal of the American Statistical Association 103(483), 1119-1130.](&lt;a href=&#34;http://amstat.tandfonline.com/doi/abs/10.1198/016214508000000689&#34; class=&#34;uri&#34;&gt;http://amstat.tandfonline.com/doi/abs/10.1198/016214508000000689&lt;/a&gt;) (&lt;a href=&#34;http://arxiv.org/abs/0710.4536&#34;&gt;arXiv preprint&lt;/a&gt;) [3] [Hannah, L. A., D. M. Blei, and W. B. Powell (2011). Dirichlet process mixtures of generalized linear models. Journal of Machine Learning Research 12, 1923-1953.](&lt;a href=&#34;http://www.cs.princeton.edu/~blei/papers/HannahBleiPowell2011.pdf&#34; class=&#34;uri&#34;&gt;http://www.cs.princeton.edu/~blei/papers/HannahBleiPowell2011.pdf&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Plenary speech</title>
      <link>/./2012/07/12/plenary-speech/</link>
      <pubDate>Thu, 12 Jul 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/07/12/plenary-speech/</guid>
      <description>&lt;p&gt;This morning I gave a speech as part of the plenary session “Standing on the shoulders of giants”. I was joined on stage by Mengyan Gong from Tsinghua University and Joana Madureira from the University of Porto and the three of us were to talk about our position as students within the field of air quality and how we see ourselves contributing. After the three of us gave our ten minute talks, Professor &lt;a href=&#34;http://www.linkedin.com/profile/view?id=21633181&#34;&gt;Charles Weschler&lt;/a&gt; gave a talk about what we currently know about biochemistry and microbiology &lt;em&gt;vis a vis&lt;/em&gt; the role of chemicals and microbes in indoor air and health. I think it was a great session and I’d like to thank Lidia Morawska for coming up with the idea and &lt;a href=&#34;http://blog.bus.qut.edu.au/sefdean/&#34;&gt;Martin Betts&lt;/a&gt; and &lt;a href=&#34;http://www.ce.berkeley.edu/people/faculty/Nazaroff?destination=people%2Ffaculty%2FNazaroff&#34;&gt;William Nazaroff&lt;/a&gt; for chairing the session.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;hb-plenary.jpg&#34; alt=&#34;Thursday morning speakers Professor Charles Weschler, Ms Joana Madureira, Mr Sam Clifford and Ms Gong Mengyan. Photo courtesy Professor William Nazaroff.&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Thursday morning speakers Professor Charles Weschler, Ms Joana Madureira, Mr Sam Clifford and Ms Gong Mengyan. Photo courtesy Professor William Nazaroff.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;I spoke about the need for better statistics in science and how it was up to supervisors to encourage their students to look at novel approaches for data analysis and for students to be curious, creative and willing to learn in order to ensure that the field does not grow stagnant. I have &lt;a href=&#34;http://samcliffordinfo.files.wordpress.com/2012/07/hbplen.pdf&#34;&gt;uploaded the slides&lt;/a&gt; (which are quite spare) and a transcript of what I planned to say is available below (perhaps I should try to get this published in Indoor Air as a letter). I did vary from the script in a few parts and I will post the video online when it’s available. I will try to include links in the transcript to references so people can find out about these techniques that I get so excited about.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;“Quantitative questions, quality answers”&lt;/strong&gt; A talk for the “Standing on the shoulders of giants” session&lt;/p&gt;
&lt;p&gt;If I, as a student, am to further the field of indoor air and built environmental health it will be by standing on the shoulders of giants. The scientists, engineers and others who have gone before me in this field have developed a rich body of ideas and questions that have gone unanswered as a result of there being other work that they must do. But as one moves up the academic ladder, writing grant applications and supervising postgraduate students the chance to investigate some of these questions in depth arises. A team of PhD students with a diverse skill set can be assembled to assist the other academics in the team and to help drive the research output of the group. This has happened with my group’s UPTECH project, which is the topic of a session later today.&lt;/p&gt;
&lt;p&gt;According to Graham Farquhar of the Australian National University, Canberra, one of Australia’s most cited academics, the key to producing high quality science is to start with a really good hypothesis driven question that no one has answered and answer it. That seems fairly straight forward? In the case of UPTECH, the unanswered question is “What is the effect of exposure to airborne nano and ultrafine particles emitted from motor vehicles on the health of children in schools?”. Data collected in this project include two weeks of indoor and out aerosol and meteorology measurements at each of 25 primary schools. Indoor microbiology measurements are taken in one or two classrooms at each school and health diagnostic tests are performed on the students in these classes, accompanied by a take home survey which includes questions about family health history, demographics and housing characteristics.&lt;/p&gt;
&lt;p&gt;This project generates a huge amount of data that has the potential to reveal some very interesting relationships. But to do so requires statistics beyond ANOVA and linear regression. The same can really be said of any modern scientific project. Don’t get me wrong, ANOVA is a great tool for exploratory data analysis [1] and testing whether a term in a regression model is zero or not. But to stop the analysis at descriptive statistics and testing for equal means across groups is to cheat yourself out of the opportunity to examine why these differences arise and really get to know what your data is telling you. ANOVA can be replaced with a Generalised Linear Model with factor terms. Any measured covariates can then be included in this GLM rather than just calculating the correlation between the covariate and the response. If the effect is suspected to be non-linear there are a range of regression models which are commonly used in the statistical and computer sciences but have not found their way into the natural sciences and I will talk about these soon.&lt;/p&gt;
&lt;p&gt;The development of new statistical techniques and the ubiquity of computers in the workplace means that there is really no excuse for using statistical techniques that were developed for agricultural field trials are limited in their ability to explain variation in a data set. Expecting senior academics and industry practitioners to maintain statistical education throughout their careers is a bit of a tall ask in some cases. There’s so much work to be done keeping up with the science that the statistics often falls by the wayside. In my mind, the role of the supervisor is to present a problem and then direct the creativity and curiosity of the student. The role of the student is to answer the research question in a paper which weaves together the experience of the supervisor with high quality research and statistical modelling appropriate to the data and hypothesis.&lt;/p&gt;
&lt;p&gt;And there’s much more to data analysis than doing ANOVA. If you suspect that there might be homogenous groups within a set of observations, why not try a clustering algorithm like k-means [2] or a finite mixture model? [3] Don’t know how many groups there are? Try an infinite mixture model [4]. Think that certain covariates might have a different effect within those groups? A Dirichlet Process Mixture of GLMs is an option [5]. The Indian Buffet Process will help you identify common patterns across a bunch of correlated covariates and reduce the dimension of your data [6]. If you suspect the effect of humidity on particle number concentration is non-linear but aren’t sure about what it’s going to look like you could try a spline model [7,8]. For a smooth spatial relationship across a network of monitors you can use a Gaussian predictive process with a Matern class covariance function [9] or go all out and use a Gaussian process with non-parametric covariance [10]. Want to combine the effect sizes from some previous studies of the same thing to estimate an overall effect? Use Bayesian meta-analysis rather than a weighted average [11].&lt;/p&gt;
&lt;p&gt;These are all common approaches in the statistical community and I have seen them applied to scientific problems, many related to air quality or health. These techniques are much newer than ANOVA and their development in statistics and computer science means that professional scientists may not ever be exposed to them. So it’s up to students to be aware of new techniques which are applicable to their research. But is it too much to expect that all students are well versed in such a range of statistical techniques? Probably. Especially when you consider that a lot of these things aren’t taught in undergraduate science degrees. Science graduates are the obvious choice when recruiting science PhD students or industry practitioners. But science and engineering is strengthened by solid statistics. And the statistics are solid when a group’s capacity for statistics is solid, whether by employing one directly, choosing candidates with a strong statistical education, building links with a statistics research group at a university or providing for the ongoing statistical training of early career researchers and/or students. Our science must not just demonstrate that something is happening but attempt to understand why that effect occurs. We must quantify it and how and why it varies. Highly influential work, such as the work presented by our keynote speakers, arises when appropriate statistics raises high quality experimental science to where it belongs. The reader has before them a clear picture of what is happening and why. I see my role in my group, and through it, my role in our broad field, as fostering statistical creativity and curiosity. I am there to help provide tools which the people around me can use to solve these unanswered problems. Encouraging people to step outside the “ANOVA and linear regression in Excel” frame of mind has motivated them to ask questions about how best to fit some data which shows a non-linear effect, how to write code to process output from our instruments that will calculate summary statistics and generate plots, how to look at trends in time series data, and so on. In return, I’ve been given the opportunity to work on some really interesting air quality problems with some people who really know their science. So I pick up some more knowledge about aerosols and health, they get exposed to new ways of analysing data, and we get to present our interesting results to the world with robust and novel analysis.&lt;/p&gt;
&lt;p&gt;[1] Andrew Gelman. &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/AOS259.pdf&#34;&gt;Analysis of variance - why it is more important than ever&lt;/a&gt;. Annals of Statistics, 33:1-53, 2005.&lt;/p&gt;
&lt;p&gt;[2] Lloyd., S. P. &lt;a href=&#34;http://www.cs.nyu.edu/~roweis/csc2515-2006/readings/lloyd57.pdf&#34;&gt;Least squares quantization in PCM&lt;/a&gt;. IEEE Transactions on Information Theory 28 (2): 129-137, 1982.&lt;/p&gt;
&lt;p&gt;[3] Darren Wraith, Clair Alston, Kerrie Mengersen, Tareq Hussein. &lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1002/env.1020/abstract&#34;&gt;Bayesian mixture model estimation of aerosol particle size distributions&lt;/a&gt;. Environmetrics 22 (1)&lt;/p&gt;
&lt;p&gt;[4] Brian Kulis, Michael I. Jordan. &lt;a href=&#34;http://arxiv.org/abs/1111.0352&#34;&gt;Revisiting k-means: New Algorithms via Bayesian Nonparametrics&lt;/a&gt;. ICML 2012.&lt;/p&gt;
&lt;p&gt;[5] Lauren A. Hannah, David M. Blei, Warren B. Powell. &lt;a href=&#34;http://www.cs.princeton.edu/~blei/papers/HannahBleiPowell2011.pdf&#34;&gt;Dirichlet Process Mixtures of Generalized Linear Models&lt;/a&gt;. Journal of Machine Learning Research 1: 1-33, 2011.&lt;/p&gt;
&lt;p&gt;[6] Thomas L. Griffiths, Zoubin Ghahramani. &lt;a href=&#34;http://www.gatsby.ucl.ac.uk/~zoubin/papers/ibp-nips05.pdf&#34;&gt;Inﬁnite Latent Feature Models and the Indian Buffet Process&lt;/a&gt;. Advances in Neural Information Processing Systems 18, 2005.&lt;/p&gt;
&lt;p&gt;[7] S. Clifford, S. Low Choy, T. Hussein, K. Mengersen, L. Morawska, &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1352231011004766&#34;&gt;Using the Generalised Additive Model to model the particle number count of ultrafine particles&lt;/a&gt;, Atmospheric Environment 45 (32): 5934-5945, 2011.&lt;/p&gt;
&lt;p&gt;[8] S. Clifford, B. Mølgaard, S. Low Choy, J. Corander, K. Hämeri, K. Mengersen, L. Morawska, Bayesian semi-parametric forecasting of particle number concentration: penalised splines and autoregressive errors, in prep, 2012. &lt;a href=&#34;http://arxiv.org/abs/1207.0558&#34;&gt;arXiv&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[9] Banerjee, S.; Gelfand, A. E.; Finley, A. &amp;amp; Sang, H. &lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2008.00663.x/abstract&#34;&gt;Gaussian predictive process models for large spatial data sets&lt;/a&gt;. Journal of the Royal Statistical Society B 70: 825-848, 2008.&lt;/p&gt;
&lt;p&gt;[10] Emily Fox and David Dunson. &lt;a href=&#34;http://arxiv.org/abs/1101.2017&#34;&gt;Bayesian Nonparametric Covariance Regression&lt;/a&gt;, 2011.&lt;/p&gt;
&lt;p&gt;[11] Blangiardo, M.; Hansell, A. &amp;amp; Richardson, S. &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/S1352231010008642&#34;&gt;A Bayesian model of time activity data to investigate health effect of air pollution in time series studies&lt;/a&gt;. Atmospheric Environment, 45: 379 - 386, 2011.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Bioaerosols and lab reorganisation</title>
      <link>/./2012/05/22/bioaerosols-and-lab-reorganisation/</link>
      <pubDate>Tue, 22 May 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/05/22/bioaerosols-and-lab-reorganisation/</guid>
      <description>&lt;p&gt;Yesterday I had a meeting with my supervisor and two colleagues about looking at the microbiological measurements we’ve been taking as part of UPTECH. It was an interesting meeting if only for the chance to really see how the four of us are approaching this paper from the point of view of our backgrounds. Heidi Salonen, who has been working on microbiology with us since Caroline Duchaine went back to Canada, will be the lead author on the paper. She’s got a background in OH&amp;amp;S and this was really clear when she was talking about the need to quantify safe levels of microbiology. I was sitting there asking the questions that will shape the data analysis, like what sort of relationships we anticipate. Mandana Mazaheri was focussing on making use of the rest of the UPTECH data as best we can (we have a huge Access database) and Lidia Morawska was making sure none of us got carried away and that we could agree on an approach. I’m going to use this paper as an opportunity to push R as our statistical engine rather than Excel (which is all that scientists seem to use). I’m being brought on as the statistician and really don’t want to about learning how to use Excel and write VBA to do the things that can be done trivially in R. R’s plots are a lot better than what we tend to see in Excel and Mandana and I have been learning how polygon() works so we can shade the region between two particle diameter distributions in a plot for a report she’s working on. Mandana’s actually been quite good about learning R and seems to have stuck with it more than a lot of the other PhD students (except for Farhad Salimi, who is doing some really interesting work). I’d really like to use this paper as an opportunity to have people use git but Mandana and Heidi aren’t programmers, and I think even using R is going to stretch them. A &lt;a href=&#34;windows.github.com&#34;&gt;Windows GUI for git&lt;/a&gt; was released recently and I’m finding it better for committing and pushing than TortoiseGit or the command line git client as neither of these deal with my ssh keys particularly well. I don’t know what the deal is there. Perhaps it’s better under a more modern version of Windows. I also spent some time in the lab today helping reorganise it. Me being in the lab is a rarer event than the &lt;a href=&#34;http://www.bbc.co.uk/news/18141625&#34;&gt;recent annular eclipse&lt;/a&gt;. I don’t work in the lab and so am not responsible for the mess left over from experiments and not putting things away when I’m done, but I do rely on the lab’s monitoring data so it’s only fair that I help out from time to time. Just don’t ask me to help out with any of the science.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;a href=&#34;http://knowyourmeme.com/photos/234739-i-have-no-idea-what-im-doing&#34;&gt;&lt;img src=&#34;fa5.jpg&#34; /&gt;&lt;/a&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
