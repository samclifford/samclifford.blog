<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Publishing on Sam Clifford </title>
    <link>/./tags/publishing/</link>
    <language>en-us</language>
    <author>Alexander Ivanov</author>
    <updated>2014-02-13 00:00:00 &#43;0000 UTC</updated>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2014/02/13/posterior-samples/</link>
      <pubDate>Thu, 13 Feb 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/02/13/posterior-samples/</guid>
      <description>&lt;p&gt;It’s still ARC writing time so that’s been taking up quite a bit of time recently. A coworker from Maths mentioned she’d started using &lt;a href=&#34;http://literatureandlatte.com/scrivener.php&#34;&gt;Scrivener&lt;/a&gt; to storyboard her papers. Apparently &lt;a href=&#34;http://mosx.tumblr.com/post/51299936501/our-collaborative-scrivener-workflows&#34;&gt;it can be used with tools like git&lt;/a&gt;, &lt;a href=&#34;http://creativityhacker.ca/2013/04/23/scrivener-and-the-cloud-best-practices-2013/&#34;&gt;Google Drive and Dropbox&lt;/a&gt; to work collaboratively but you’ve got to be careful of conflicted copies that won’t be discovered. Another coworker from Maths isn’t so impressed by Scrivener, noting that in terms of using it with version control software you’re better off using LaTeX anyway. At US$40 a license I’m a bit reluctant to try to make Scrivener part of my workflow, and there’s no way I can ask collaborators to fork out that kind of money. I keep being impressed by Matt Wand, Jan Luts and Tamara Broderick’s work on &lt;a href=&#34;http://realtime-semiparametric-regression.net/&#34;&gt;realtime semiparametric regression&lt;/a&gt;. I saw Wand present this work at Bayes on the Beach just over a year ago. I can’t, for the life of me, wrap my head around mean-field variational Bayes, though. Perhaps it’s that I’ve never had to deal with Calculus of Variations and got into inference beyond linear models through MCMC in WinBUGS rather than through machine learning. I’ve got a few more books on my desk about statistical theory now, including Congdon’s “Bayesian Statistical Modelling”, Koller and Friedman’s “Probabilistic Graphical Models”, Casella and Berger’s “Statistical Inference”.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/10/25/posterior-samples/</link>
      <pubDate>Fri, 25 Oct 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/10/25/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.upworthy.com/one-guy-with-a-marker-just-made-the-global-warming-debate-completely-obsolete-7&#34;&gt;Here’s an interesting but simple discussion&lt;/a&gt; of the risk analysis of action on climate change. What I like is that the author encourages the viewer to play around with the outcomes rather than using an appeal to authority that states “this is what the IPCC and other climate scientists say will happen”. it’s a very Bayesian way of asking people to consider risk, not just in the conditional statement sense but in the sense that one’s personal subjective belief is viewed as a welcome addition to the discussion. So much of the climate debate seems to be based on whether or not the IPCC is right; some people don’t like that the IPCC is an international body of elite scientists and so will ignore anything they say. Couching the exercise in terms of “Any reasonable person should be able to concede that they may be wrong about the way the physical world behaves” takes it away from “who is right and who is wrong?”. &lt;a href=&#34;http://www.usq.edu.au/scholarships/usq/australian-postgraduate-award&#34;&gt;USQ has some APA PhD scholarships available&lt;/a&gt;, including scholarships for computational mathematics and climate risk and resource management. So if you’re interested in $30,000 per year (tax free!) to work on some interesting topics check out the USQ site. Problems with the interpretation of p values are &lt;a href=&#34;http://bayesianbiologist.com/2011/08/21/p-value-fallacy-on-more-or-less/&#34;&gt;often due to people treating them as statements about their hypothesis&lt;/a&gt; given some data when they’re really statements about the data given some hypothesis. Any SEB113 students reading would do well to remember this. I’ve also &lt;a href=&#34;http://samclifford.info/2013/10/18/response-to-a-student-on-p-values/&#34; title=&#34;Response to a student on p values&#34;&gt;blogged my response&lt;/a&gt; to an SEB113 student about this. &lt;a href=&#34;http://simplystatistics.org/2013/10/15/teaching-least-squares-to-a-5th-grader-by-calibrating-a-programmable-robot/&#34;&gt;Here’s a cute little video&lt;/a&gt; about using least squares regression to figure out how many revolutions a Lego Mindstorms robot’s wheel needs to turn to make it travel 1m. It’s an interesting use of regression as a calibration technique, which is something we haven’t covered explicitly in SEB113 but I imagine it’d be pretty common in engineering classes. &lt;a href=&#34;http://thesiswhisperer.com/2013/10/23/why-is-grey-literature-not-open-access/&#34;&gt;Interesting post at the Thesis Whisperer&lt;/a&gt; asking why work that’s owned by someone (as in the intellectual property rights are assigned) but not copyrighted by a commercial publisher isn’t more freely available.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/10/10/posterior-samples/</link>
      <pubDate>Thu, 10 Oct 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/10/10/posterior-samples/</guid>
      <description>&lt;p&gt;Open Access publishing is an exciting new development but like any new industry there are those who would seek to unethically make a quick fortune by providing a sub-par service. &lt;em&gt;Science&lt;/em&gt; did some research into this by submitting a fake article with a number of glaring errors (such as non-existent institutions) in it to a number of journals around the world to see who’d accept it. &lt;a href=&#34;http://www.npr.org/blogs/health/2013/10/03/228859954/some-online-journals-will-publish-fake-science-for-a-fee?ft=1&amp;amp;f=1001&#34;&gt;The results are quite interesting&lt;/a&gt;. I know of a few instances of work published in a respectable journal being plagiarised and published in one of these scam journals and one case where the authors hastily retracted their submission once they found out the journal wasn’t anywhere near as prestigious as the editors made out. I support the goals of Open Access and web-based publication but be careful. I’ve been poking around the QUT Wiki looking for information on graduation. In the Higher Degree Research portal there’s a link to a brilliant article (three years old) on &lt;a href=&#34;http://www.timeshighereducation.co.uk/news/how-not-to-write-a-phd-thesis/410208.article&#34;&gt;how not to write a thesis&lt;/a&gt;. Probably good advice for any PhD student looking to graduate sooner rather than later. Elizabeth C. Matsui has been working with Roger Peng for several years; she has &lt;a href=&#34;http://simplystatistics.org/2013/10/08/the-care-and-feeding-of-the-biostatistician/&#34;&gt;some advice on how to cultivate a successful relationship with the biostatistician&lt;/a&gt; you’ve brought on to your medical science project. I think some of these could be adapted to be more general to cover dealing with statisticians. One of the biggest things I could add here is that you need to recognise that asking someone to “help with the statistics” means dedicating some serious time and effort to figuring out a conceptual model (which will be converted into a quantitative model) that addresses the scientific questions you wish to ask. Asking a statistician to “calculate the correlations” or even more broadly “do the statistics” is like asking a scientist to just “run an experiment” or “do the science”. These things all take time, energy and communication. Further to this, don’t just ask for p-values if you’re dealing with a statistician. P-values represent some probabilistic statement, such as “What is the probability of seeing a test statistic at least as extreme as this if the true value of the parameter was zero?”. Sure, you can do simple tests like ANOVA or Chi-Squared goodness of fit but the real value in working with a statistician is being able to develop models that represent assumptions about the data and then assessing whether those assumptions are justified and looking at the inferences that they provide. As my unit co-ordinator for SEB113 pointed out to me the other day, default hypothesis tests of H&lt;sub&gt;0&lt;/sub&gt;: β = 0 at a 5% significance level may not always be sensible and may not even answer the question you’re interested in answering. And finally here’s &lt;a href=&#34;http://www.youtube.com/watch?v=QPKKQnijnsM&#34;&gt;a video that’s almost a year old&lt;/a&gt; that shows a very interesting case of eliciting a distribution from the American public about what they perceive the distribution of wealth in their country is and what they think it is. Turns out the ideal is as far away from the perception as the perception is from the reality.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples - July wrap</title>
      <link>/./2013/07/29/posterior-samples---july-wrap/</link>
      <pubDate>Mon, 29 Jul 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/07/29/posterior-samples---july-wrap/</guid>
      <description>&lt;p&gt;I had some Posterior Samples to share before going on leave but didn’t get around to posting them. Here’s what’s been on my mind this month: Maths and science units are popular with (Kentucky) students until they realise that &lt;a href=&#34;http://blogs.wsj.com/economics/2013/07/08/math-science-popular-until-students-realize-theyre-hard/&#34;&gt;they’re hard&lt;/a&gt;. While not directly relevant to the Australian university education model it’s probably an important thing for the Science and Engineering Faculty to keep in mind. &lt;a href=&#34;http://blogs.wsj.com/economics/2013/07/08/math-science-popular-until-students-realize-theyre-hard/&#34;&gt;&lt;/a&gt; I’m looking at ggplot2 more these days, so the idea of a “grammar of graphics” is beginning to resonate with me. &lt;a href=&#34;//www.youtube.com/watch?v=xyGggdg31mc&#34;&gt;Here’s a talk&lt;/a&gt; about building one for &lt;a href=&#34;http://clojure.org/&#34;&gt;clojure&lt;/a&gt; (which I don’t use). Something for me to keep in mind when delivering SEB113 slides this semester is &lt;a href=&#34;https://www.dropbox.com/s/p0sgdgo7mxkoj4h/What%20your%20math%20slides%20dont%20need.pdf&#34;&gt;what your maths slides don’t need&lt;/a&gt;. Probably also good pointers for any PhD students graduating soon. &lt;a href=&#34;http://well.blogs.nytimes.com/2013/07/22/the-kitchen-as-a-pollution-hazard/&#34;&gt;An interesting article in the New York Times&lt;/a&gt; about air pollution from cooking. This is something that ILAQH has a research interest in and our nanotracer paper contains a bit of analysis of inhaled surface area dose from particles that originate from cooking. &lt;a href=&#34;http://www.nytimes.com/2013/07/22/business/in-climbing-income-ladder-location-matters.html&#34;&gt;Another NYT article&lt;/a&gt;, this time with a delicious visualisation of the geographical trends in income disparity and social mobility. &lt;a href=&#34;http://www.slate.com/articles/health_and_science/science/2013/07/statistics_and_psychology_multiple_comparisons_give_spurious_results.html&#34;&gt;Andrew Gelman writes at Slate&lt;/a&gt; about some of the problems with scientific publishing and the publication of spurious findings (which isn’t always willingly dishonest). A special “Big Bayes Stories” issue of “Statistical Science” will be published soon, focussing on the real world application of Bayesian statistics where other methods were inapplicable. &lt;a href=&#34;http://xianblog.wordpress.com/2013/07/29/big-bayes-stories/&#34;&gt;Christian Robert has written the preface&lt;/a&gt;; the issue is being edited by Robert, Kerrie Mengersen (one of my PhD supervisors) and Sharon McGrayne, author of “&lt;a href=&#34;http://www.amazon.com/Theory-That-Would-Not-Die/dp/1452636850&#34;&gt;The Theory That Would Not Die&lt;/a&gt;”. Also I went to &lt;a href=&#34;http://www.questacon.edu.au/&#34;&gt;Questacon&lt;/a&gt; and it was awesome.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/06/13/posterior-samples/</link>
      <pubDate>Thu, 13 Jun 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/06/13/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://themonkeycage.org/2013/05/29/how-to-make-an-academic-conference-and-more-accessible-and-more-interesting-live-streaming-and-conference-hashtags&#34;&gt;Josh Tucker at the Monkey Cage&lt;/a&gt; and &lt;a href=&#34;http://simplystatistics.org/2013/06/11/why-not-have-a-future-of-the-field-session-at-a-conference-with-only-young-speakers/&#34;&gt;Jeff Leek at Simply Statistics&lt;/a&gt; have some good ideas and goals as to how to make academic conferences more interesting. Opening up the conference with live streaming is a cheap way to engage the wider public (but risks potential attendees deciding to stay home and watch rather than engaging with the rest of the conference). A youth session is also a really good way to engage in some inter-generational communication by giving the younger researchers a stage for setting out their vision. &lt;a href=&#34;http://f1000research.com/data-policies&#34;&gt;These journals&lt;/a&gt; wouldn’t view publication of data as prior publication when assessing an article based on that data. I spent last week in Sydney with Guy Marks’ group at the &lt;a href=&#34;http://www.woolcock.org.au/&#34;&gt;Woolcock Institute of Medical Research&lt;/a&gt;. I first met Marks at Bayesian data analysis course run by Kerrie Mengersen; he &lt;a href=&#34;http://sydney.edu.au/medicine/people/academics/profiles/guym.php&#34;&gt;does work&lt;/a&gt; on tuberculosis in Vietnam. Christian Robert, a collaborator of Mengersen’s, just gave 40 students in Ho Chi Minh City a crash course in Bayesian statistics. The slides are available &lt;a href=&#34;http://xianblog.wordpress.com/2013/06/05/teaching-bayesian-statistics-in-hochimin-city/&#34;&gt;here&lt;/a&gt;. Speaking of Bayesian stats, the term “derp” is apparently a &lt;a href=&#34;http://au.businessinsider.com/sorry-haters-derp-isnt-going-away-2013-6&#34;&gt;Bayesian way of describing the way someone believes something so strongly&lt;/a&gt; (their prior) that they can not be swayed by data. I’m going to be doing a lot more work teaching people how to use R in the near future. &lt;a href=&#34;http://www.computerworld.com/s/article/9239625/Beginner_s_guide_to_R_Introduction&#34;&gt;This looks like a handy resource for beginners&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>I know the impact factor&#39;s not the be all and end all, but...</title>
      <link>/./2013/05/09/i-know-the-impact-factors-not-the-be-all-and-end-all-but.../</link>
      <pubDate>Thu, 09 May 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/05/09/i-know-the-impact-factors-not-the-be-all-and-end-all-but.../</guid>
      <description>&lt;p&gt;In Australia, at least, the impact factor of the journals you publish in plays a large role in your advance in academia. Universities are always under pressure to publish their research in more prestigious journals, conflating the impact factor of the journal and the impact of the research published in it. There are many ways journals can game their impact factor, many ways researchers can game the indices that describe the impact of their work, etc. That said, it’s always good to aim to produce research that will be accepted in a high quality journal. I’ve been excited about the PLoS journals since their launch and I believe QUT is a subscribing member, which means our publication fees are covered. It’s one of the best Open Access journal groups around and doesn’t appear to be a cash grab like some other publishers who are attempting to use Open Access as a business model to increase profits rather than because they believe in the free dissemination of research. UPTECH collected fungi and endotoxin data at the 25 schools, and we’re about to submit the fungi paper (which means work must continue on the endotoxin paper). I was considering whether we should submit to &lt;a href=&#34;http://www.plosone.org/&#34;&gt;PLoS One&lt;/a&gt; (IF 2011: 4.092) and then had a look at what other journals they have which may be an appropriate home. I really think once we get the clinical data from &lt;a href=&#34;http://www.woolcock.org.au/&#34;&gt;our Southern collaborators&lt;/a&gt; we should aim to do the best statistical modelling we can. I’m heartened by the fact that the head of the clinical group we’re working with has a strong background in stats and a desire to learn more Bayesian statistics. I don’t know if we can pull it off, but the prospect of having something investigating the role of fungi and endotoxin on child health published in &lt;a href=&#34;http://www.plospathogens.org/&#34;&gt;PLoS Pathogens&lt;/a&gt; (IF 2011: 9.172) is exhilarating.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior Samples</title>
      <link>/./2013/01/21/posterior-samples/</link>
      <pubDate>Mon, 21 Jan 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/01/21/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://blog.revolutionanalytics.com/2013/01/elements-of-statistical-learning-2nd-ed-download.html&#34;&gt;Free download&lt;/a&gt; of Hastie, Tibshirani and Friedman’s “Elements of Statistical Learning”. Hastie and Tibshirani did a lot of the early work on Generalised Additive Models and non-parametric smoothing, albeit in a non-Bayesian framework, so this will no doubt be an invaluable resource. NASA have released &lt;a href=&#34;http://www.nasa.gov/topics/earth/features/2012-temps.html&#34;&gt;a neat visualisation&lt;/a&gt; of spatio-temporal deviation from the mean temperature going back to the 1880s. You have to be careful when generating “pretty” graphics, though, because &lt;a href=&#34;http://andrewgelman.com/2013/01/ugly-ugly-ugly/&#34;&gt;“pretty” infographics can be quite ugly and hard to decode&lt;/a&gt; when you’re not taking into account what the data actually represents. &lt;a href=&#34;http://www.biostat.jhsph.edu/~rpeng/&#34;&gt;Roger Peng&lt;/a&gt; &lt;a href=&#34;http://simplystatistics.org/2013/01/16/review-of-r-graphics-cookbook-by-winston-chang/&#34;&gt;reviews&lt;/a&gt; Winston Chang’s “R Graphics Cookbook”. The conclusion? A pretty good collection of examples about how to complete particular graphing tasks using ggplot2. It’s a simpler book than Hadley Wickham’s “ggplot2” and would be a good introduction to using ggplot2 to achieve a particular goal. &lt;a href=&#34;http://about.jstor.org/rr&#34;&gt;JSTOR’s “Register &amp;amp; Read”&lt;/a&gt; is in beta now. So if you’re not attached to a university or other institution with a JSTOR subscription, you now have the opportunity to read JSTOR articles for free (but it’s not unlimited, at least not yet). Speaking of free access to published research, &lt;a href=&#34;http://www.guardian.co.uk/science/blog/2013/jan/17/open-access-publishing-science-paywall-immoral&#34;&gt;this opinion article&lt;/a&gt; makes the point that our job as scientists is to contribute to the body of human knowledge for the benefit of society and so if a paper isn’t freely available to the public then it isn’t really “published”. Not only that, but to hide research behind a paywall is immoral. I found it very interesting even if I thought some of his arguments were a bit dismissive.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/01/10/posterior-samples/</link>
      <pubDate>Thu, 10 Jan 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/01/10/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://andrewgelman.com/2013/01/a-important-new-survey-of-bayesian-predictive-methods-for-model-assessment-selection-and-comparison/&#34;&gt;A very comprehensive paper by Vehtari and Ojanen discusses various aspects of model assessment and comparison&lt;/a&gt;. I was mentioning to a friend the other day that I don’t think model assessment is taught very well in first year statistics classes. I recognise that you can’t teach everything in a first year class, but I think we should be going beyond R&lt;sup&gt;2&lt;/sup&gt; as a summary of model performance. Even the AIC would be a good start, as it incorporates a trade-off between goodness of fit and model complexity. I am yet to fully read the paper but it’s something I should definitely get my head around. &lt;a href=&#34;http://dynamicecology.wordpress.com/2013/01/03/advice-how-to-review-a-manuscript-for-a-journal/&#34;&gt;Dynamic Ecology has some advice for how to review a journal article&lt;/a&gt;. This will become increasingly relevant for me as a junior researcher. No doubt I’ll be asked whether I could review some submitted articles for a journal in which I am publishing my papers. Having not done it before, the first one will no doubt be the toughest. Perhaps I should ask the more junior reviewer of my thesis panel for any recent experience they’ve had. &lt;a href=&#34;http://www.insidehighered.com/news/2013/01/09/jstor-offer-limited-free-access-content-1200-journals&#34;&gt;JSTOR’s “Register &amp;amp; Read”&lt;/a&gt; program is an attempt to open up access to academic publishing by allowing individuals not affiliated with an organisation with a JSTOR subscription to read three articles every two weeks for free. This will be good for when news articles discuss a study and people are interested enough to go and find the original paper but don’t want to drop $30 to read it. It’s not as far-reaching as Open Access but it’s a good step. &lt;a href=&#34;https://twitter.com/search/%23overlyhonestmethods&#34;&gt;#OverlyHonestMethods&lt;/a&gt; is a hilarious Twitter hashtag that is encouraging scientists to confess their transgressions and is &lt;a href=&#34;http://io9.com/5974256/overlyhonestmethods-is-the-postsecret-of-the-science-world-and-it-is-amazing&#34;&gt;being called&lt;/a&gt; the &lt;a href=&#34;http://www.postsecret.com/&#34;&gt;PostSecret&lt;/a&gt; of the science world.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Generating mastery through immersion, imitation and failure</title>
      <link>/./2013/01/03/generating-mastery-through-immersion-imitation-and-failure/</link>
      <pubDate>Thu, 03 Jan 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/01/03/generating-mastery-through-immersion-imitation-and-failure/</guid>
      <description>&lt;p&gt;I came across a webcomic, Doodle Alley, which deals with sustainable creativity and there are a few pages I want to focus on: “&lt;a href=&#34;http://doodlealley.com/2012/10/01/taste-is-your-teacher/&#34;&gt;Taste is your teacher&lt;/a&gt;”, “&lt;a href=&#34;http://doodlealley.com/2012/10/10/be-friends-with-failure/&#34;&gt;Be friends with failure&lt;/a&gt;” and “&lt;a href=&#34;http://doodlealley.com/2012/11/21/practice-does-not-make-perfect/&#34;&gt;Practice does not make perfect&lt;/a&gt;”. They are couched in terms of art, but I think the same arguments apply to academic science as well, particularly writing papers. “Taste” focuses on immersion as a means of improving your work. To adapt the culinary example to statistics: to write a good paper I need to know what good statistics looks like; to know what good statistics looks like I need to read a lot of good statistics. This reminds me of the &lt;a href=&#34;http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1467-9868&#34;&gt;JRSS B&lt;/a&gt; papers I’ve had to read to understand spatial statistics [1, 2]. “Taste” mentions imitation as a way of producing great art and this is explored further in “Practice”. This doesn’t mean word for word plagiarising in the academic arena, but I’d say it does mean that copying the original creator’s style and extending it is part of the road to success. In writing my thesis I looked at previous PhD students’ theses which were held up as being great work. I looked at the way the thesis was structured, the way the ideas were set out within each chapter and the way the conclusion stepped through what the work had resulted in. I obviously couldn’t just “copy” the thesis, because their work is not my work and I need to make a significant original contribution, but the thesis as a whole can definitely serve as a starting point for my imitation of good art. “Friends” starts with the very sobering realisation that the more you immerse yourself in great art (science) the more you realise your art (science) is not great. The solution to this is to embrace failure as a friend and recognise that &lt;a href=&#34;http://www.youtube.com/watch?v=vrBWJLC22mE&#34;&gt;sucking at something is the first step towards being sorta good at something&lt;/a&gt;. The comic raises the point that if you never fail at something how can you grow? One of the first things you learn in impro is that failure is an indication that you have tried. If, as beginners, we never fail we are playing it safe and producing boring work. Only by taking those bold leaps and falling flat on our faces multiple times do we begin to feel comfortable with our failure. Platitudes about failure being a learning experience don’t tend to focus on the idea that failure is something to be embraced but that it’s something that just happens and there’s nothing we can do about it. Failure, in the comic, is evidence that you’re still like a baby in terms of picking up a particular skill. Babies are born knowing absolutely nothing and pick it up by repeating their attempts, failing a little less each time they try. This is the key to mastery. Immerse yourself in your field, get a sense of what great art/science/statistics/food is and keep on trying, taking those bold steps and failing a little less each time. Your first few academic papers will probably not be worth publishing in journals like JRSS B and JASA, but that’s no reason to not aim high, fail (get rejected), try again (revise) and get the best result for what you’ve produced (a less prestigious journal but it’s still published work). Mastery is built through a combination of immersing yourself in others’ great work, imitating that great work, taking bold steps, recognising that you will fail, embracing the idea that you will fail and that you will fail less each time you try not through repetition of the exact same act but by trying different things until you get something that’s “good enough”. Then by repeatedly failing and trying new things you will learn where the pitfalls are and you will fail less and, every so often, create something that is great. [1] Lindgren, F., H. Rue and J. Lindström, (2011) “An explicit link between Gaussian ﬁelds and Gaussian Markov random ﬁelds: The SPDE approach”, JRSS B (&lt;a href=&#34;http://www.math.ntnu.no/inla/r-inla.org/papers/spde-jrssb-revised.pdf&#34;&gt;pdf&lt;/a&gt;) [2] Banerjee, S., A. Gelfand, A. Finley and H. Sang, (2008) “Gaussian predictive process models for large spatial data sets”, JRSS B (&lt;a href=&#34;http://www.biostat.umn.edu/~sudiptob/ResearchPapers/BGFS.pdf&#34;&gt;pdf&lt;/a&gt;)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2012/11/23/posterior-samples/</link>
      <pubDate>Fri, 23 Nov 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/11/23/posterior-samples/</guid>
      <description>&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://littlestat.com/&#34;&gt;&lt;span style=&#34;line-height:12px;&#34;&gt;LittleStat is an online R tool for simple data analysis&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.readmatter.com&#34;&gt;Matter&lt;/a&gt; is a new essay-based science/tech publication that got its start on &lt;a href=&#34;http://www.kickstarter.com/projects/readmatter/matter/&#34;&gt;Kickstarter&lt;/a&gt; - this issue is about people who feel like they have an extra limb.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://0fps.wordpress.com/2012/11/19/conways-game-of-life-for-curved-surfaces-part-1/&#34;&gt;Conway’s Game of Life as a smooth PDE system&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://statisticalsocietyaustralia.wordpress.com/2012/11/20/november-question/&#34;&gt;SSAI wants to know what the biggest challenges in modern Bayesian statistics are&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.r-bloggers.com/RUG/2012/11/video-simpler-tricks-and-tools-help-debugging-git-latex-and-workflow-with-r-by-prof-rob-hyndman/&#34;&gt;SimpleR tricks and tools: Help, debugging, git, LaTeX, and workflow with R by Prof Rob Hyndman&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Unfinnished business</title>
      <link>/./2012/08/30/unfinnished-business/</link>
      <pubDate>Thu, 30 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/30/unfinnished-business/</guid>
      <description>&lt;p&gt;I’ve just heard from Kerrie Mengersen that the Finnish paper got rejected by BA for not being novel enough to publish there. So now I’m in a situation where I’ve got a paper which is too methodological for an applied stats journal (and far too methodological for an atmospheric science journal) and not a novel enough methodology for a journal as theoretical as BA. If BA don’t think it’s novel enough and it’s not the first time this data’s been published we’ll struggle to get it into something like &lt;a href=&#34;http://www.rss.org.uk/site/cms/contentviewarticle.asp?article=876&#34;&gt;JRSS B&lt;/a&gt; (IF: 3.645), &lt;a href=&#34;http://rsif.royalsocietypublishing.org/&#34;&gt;JRS: Interface&lt;/a&gt; (IF: 4.402) or &lt;a href=&#34;http://www.plosone.org&#34;&gt;PLoS One&lt;/a&gt; (IF: 4.092). Our options, then, seem to be trying an Elsevier journal like &lt;a href=&#34;http://www.journals.elsevier.com/environmental-modelling-and-software/&#34;&gt;EMS&lt;/a&gt; (IF: 3.114) or &lt;a href=&#34;http://www.journals.elsevier.com/computational-statistics-and-data-analysis/&#34;&gt;CSDA&lt;/a&gt; (IF: 1.028), which I’m not keen to do, somewhere like &lt;a href=&#34;http://www.jstatsoft.org&#34;&gt;JSS&lt;/a&gt; (IF: 2.647) or a more applied journal like &lt;a href=&#34;http://onlinelibrary.wiley.com/journal/10.1111/(ISSN)1467-9876&#34;&gt;JRSS C&lt;/a&gt; (IF: 0.828, which is quite low). I’d like to put this in a statistics journal because I want to have a career as a statistician rather than just someone who can only work in aerosols. That’s one of the reasons I’m not keen to publish this somewhere like Atmospheric Environment (where both my article and Bjarke’s, the bases of this work, were published). I’m really kicking myself now for not submitting an abstract for this as a contributed talk at ISBA. I would’ve got a BA article out of it. In happier news, I gave a presentation with two other PhD students to BRAG this morning where we talked about INLA. It went well and I think we’ve convinced a few of the others that INLA is pretty cool and worth using. Edit: and I’m getting a lot of mileage out of the Finnish/finish pun.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Infographics</title>
      <link>/./2012/08/28/infographics/</link>
      <pubDate>Tue, 28 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/28/infographics/</guid>
      <description>&lt;p&gt;Kasia Piekut has written &lt;a href=&#34;http://mark-making.com/blog/27-communication/240-how-to-get-your-mind-around-infographic-design-and-data-visualisation&#34;&gt;an article on&lt;/a&gt; Mark Making about infographics and some of the most important things to remember. It’s accompanied by a cute infographic about infographics themselves. The potential to make high quality infographics is huge these days, as we have some very clever designers with very good software. But it’s important to remember that infographics aren’t just about pretty design but effectively communicating information in an accessible and entertaining manner. There are some pretty terrible infographics out there, where colour is used to pretty the graphs up without actually conveying information. I try to tell my coworkers to avoid the uninformative use of colour because people will look at a multicoloured graph and ask “What does this change of colour mean?” Often a table or simple plot will do in place of an infographic. As researchers we must resist the temptation to make our graphs so punchy and full of colour that we obscure the meaning of the data. Infographics are a tool for conveying information; we should be careful that we don’t end up with pictures for the sake of pictures. We should also be careful that we don’t end up with graphics that obscure the data and its implications. Edit: I don’t know that this is worthy of its own post so I’ll add it here. &lt;a href=&#34;http://themonkeycage.org/blog/2012/08/28/choices-in-graphing-parallel-time-series&#34;&gt;Andrew Gelman has blogged at The Monkey Cage&lt;/a&gt; about choosing plot styles and how different representations of the same data can be used to give the punchy dramatic message and then give that message a bit more context.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Obsession with statistical significance</title>
      <link>/./2012/08/14/obsession-with-statistical-significance/</link>
      <pubDate>Tue, 14 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/14/obsession-with-statistical-significance/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://bps-research-digest.blogspot.com.au/2012/08/phew-made-it-how-uncanny-proportion-of.html&#34;&gt;Another link&lt;/a&gt; courtesy of the Monkey Cage’s “Potpourri” link collection. This time it’s about the prevalence of papers in Psychology journals that report &lt;em&gt;p&lt;/em&gt; values of just under 0.05. The quest for statistical significance at the 0.05 level is probably the greatest shame of statistics education around the world. It comes across as being taught as a hard and fast rule that 0.05 is the magic number. We hear all about 95% confidence intervals (which I detest as a way of summarising uncertainty) and &lt;em&gt;t&lt;/em&gt; tests with &lt;em&gt;p&lt;/em&gt; values under 0.05 proving that there’s an effect. Something I’ve picked up from my statistics supervisors, both of whom are Bayesians, is that “significance” is a bit arbitrary yet it’s treated as a revelation of some universal truth by those whose statistical training hasn’t been particularly thorough. A little bit of knowledge is dangerous, you might say, particularly among reviewers. While I’m not the biggest fan of hypothesis testing, there’s a right way and a wrong way to do it. The argument should be made that “this is the &lt;em&gt;p&lt;/em&gt; value of the test under the hypothesis (and the model)” rather than just assuming that an effect is significant or not based on a point estimate of a probability measure. What would I suggest in its place? Doing one’s regression in a Bayesian setting (the GLM is generally more flexible than ANOVA) and reporting the 95% credible interval. The credible interval represents the distribution of values that a parameter may take and so a 95% credible interval corresponds to a belief that the value lies in that range. This is opposed to the confidence interval approach which says that infinite replication of the experiment would yield an effect size which lies in the confidence region 95% of the time. The Bayesian posterior represents one’s belief (objective, subjective, whatever) updated by the data by a model. It’s more useful to report the range of values that one believes &lt;em&gt;a posteriori&lt;/em&gt; that the parameter of interest might take. And this is the strength of the Bayesian paradigm. It is all about quantifying uncertainty rather than coming up with point estimates and stating wholesale whether a result is significant or not. Far better to state “this is what I think and this is how uncertain I am”.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Credibility of information given font choice</title>
      <link>/./2012/08/12/credibility-of-information-given-font-choice/</link>
      <pubDate>Sun, 12 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/12/credibility-of-information-given-font-choice/</guid>
      <description>&lt;p&gt;Thanks to the &lt;a href=&#34;http://themonkeycage.org/blog/2012/08/11/potpourri-80&#34;&gt;Monkey Cage blog&lt;/a&gt; (a very good read if you’re a fan of statistics and politics as I am) I’ve come across &lt;a href=&#34;http://opinionator.blogs.nytimes.com/2012/08/08/hear-all-ye-people-hearken-o-earth/&#34;&gt;an opinion article&lt;/a&gt; on the New York Times’ page that discusses whether the font or handwriting style that is used to convey information has any impact on whether we believe that information. It’s worth a read, as is the follow up and the preceding article (an essay and a quiz). There’s a lot of really interesting stuff in there, but one that really leaps out is the ATLAS slides from the presentation about the Higgs Boson. Comic Sans is used to convey fun, light-heartedness, etc. and as far as I’m concerned it simply does not belong in academia. The article goes on to do some analysis of the previous article’s quiz and shows that Baskerville is the font with the most &lt;em&gt;gravitas&lt;/em&gt;. Rather than having me summarise the article here (it’s quite long) it’s probably better to just go and read it. If you’ve ever wondered about whether you should use a particular font (personally, Times New Roman is boring and Cambria is ugly) to convey a particular feeling in your article then this is food for thought. I use LaTeX to write papers and read a lot of papers typeset in LaTeX. As such, my eyes tend to see a lot of &lt;a href=&#34;http://en.wikipedia.org/wiki/Computer_Modern&#34;&gt;Computer Modern&lt;/a&gt;, which has a bit of a reputation as being an academic font. I wouldn’t publish a school newsletter in Computer Modern, of course, but for “serious” writing, CM is it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Resubmission of Finnish paper</title>
      <link>/./2012/08/08/resubmission-of-finnish-paper/</link>
      <pubDate>Wed, 08 Aug 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/08/08/resubmission-of-finnish-paper/</guid>
      <description>&lt;p&gt;I’ve spent a lot of my time since Healthy Buildings finished revising the semi-parametric forecasting paper. We had submitted to Annals of Applied Statistics but it was rejected. We got some very useful comments back from the reviewer, though, and I think it’s a much stronger paper now. The reviewer encouraged us to rewrite the paper with a focus on the methodology rather than the application and submit it to a more theoretical journal. I have just submitted it to &lt;a href=&#34;http://ba.stat.cmu.edu/&#34;&gt;Bayesian Analysis&lt;/a&gt; (IF: 1.650), the official journal of &lt;a href=&#34;http://bayesian.org&#34;&gt;ISBA&lt;/a&gt;, and uploaded the preprint to arXiv (where it will replace the &lt;a href=&#34;http://arxiv.org/abs/1207.0558&#34;&gt;current version&lt;/a&gt; in the next 24 hours). As an Open Access journal with a well-written LaTeX document class, Bayesian Analysis is a journal I can get behind. Some very good papers have appeared there and as Bayesian statistics continues to grow as a field (and ISBA as a society) I think we can expect to see BA really take off as a journal. So much of modern statistics is algorithms rather than proofs and making these available to people, particularly people who aren’t academics, with freely available, peer reviewed papers will help improve the statistical capabilities of modern science.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A few things that warrant an update</title>
      <link>/./2012/07/04/a-few-things-that-warrant-an-update/</link>
      <pubDate>Wed, 04 Jul 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/07/04/a-few-things-that-warrant-an-update/</guid>
      <description>&lt;p&gt;The Finnish paper is pretty much ready for submission to Annals of Applied Stats. I’ve updated my publications page to include a link to the preprint on the &lt;a href=&#34;http://arxiv.org/abs/1207.0558&#34;&gt;arXiv&lt;/a&gt;. I will update my CV soon and I’ll add my posters and slides to the publications page. The Higgs boson - what’s the deal with that? &lt;a href=&#34;http://www.northcountrypublicradio.org/news/npr/156221787/cern-discovers-a-new-particle-likely-the-higgs-boson&#34;&gt;NPR has a good article on it&lt;/a&gt;. I spent the evening watching the Higgs announcements at uni and even though I thought the CERN slides were pretty cluttered and didn’t like the layout, nothing had prepared me for the ATLAS slides. Bad colour schemes (if you can call them that) and Comic Sans MS? Yuk. You don’t make science accessible by making people think “Hey. That looks like &lt;em&gt;I&lt;/em&gt; could have designed that. Scientists aren’t so different to me after all!” Some clearly presented slides that weren’t stuffed full of text and images are, in my opinion, the key to a good scientific presentation. 1 slide per minute, no more than 5-6 lines with no more than 5-6 words per line. The slides should touch on the key points so people can, at a glance, get a good idea of what’s going on. The talk that accompanies the slides is what conveys the rest of the information in more natural language. There was a lot of great science presented tonight, but it wasn’t presented well. David Spiegelhalter &lt;a href=&#34;http://understandinguncertainty.org/higgs-it-one-sided-or-two-sided&#34;&gt;explains&lt;/a&gt; the five sigma significance of the ATLAS/CERN results. P-values and confidence intervals are two things where I think frequentist probability stops being conceptually simpler than Bayesian statistics and becomes about questions like “What is the probability of observing the data I have seen given that I have this model and these parameter estimates?” and “If I did an infinite number of trials how many times would I expect this interval for my sample mean to cover the true mean?” and “Something something agriculture”. &lt;a href=&#34;http://hb2012.org/&#34;&gt;Healthy Buildings&lt;/a&gt; is coming up next week. It’s all hands on deck at ILAQH while we put the finishing touches on the program and sort out the behind the scenes stuff. It’s going to be great. I’ll be giving two talks; the first is about how we can use the Dirichlet process for clustering in health survey data and the second is about the need for better statistics in science. ISBA 2012 was a heap of fun and there were lots of good talks. I find meeting other statisticians very inspiring. I will try to write a wrap-up when HB 2012 is over. For now, you can enjoy &lt;a href=&#34;http://xianblog.wordpress.com/2012/06/27/isba-2012-guest-post/&#34;&gt;my preliminary thoughts&lt;/a&gt; on Xian’s ’Og.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>LaTeX and git</title>
      <link>/./2012/06/13/latex-and-git/</link>
      <pubDate>Wed, 13 Jun 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/06/13/latex-and-git/</guid>
      <description>&lt;p&gt;At the request of ihrhove I’ve decided to talk a little bit about using git and LaTeX together. I currently have two private git repositories; one for the Finnish paper and the other for all of my thesis work. I’ve talked previously about the Finnish paper so I’ll give a brief overview of how I use it with my thesis but you’ll need to keep in mind that I don’t have it shared with anyone because my supervisors don’t use git and nor do they edit the documents I work on directly (two print out draft papers and write on them, the third (who has used CVS/SVN in the past) uses Foxit to annotate PDFs directly and send them back to me. To start (and possibly end, if you’re easily convinced) with, LaTeX is just code. So to me there’s no reason why you can’t use any service you’d normally use for code for LaTeX. Everything that is directly being used in a paper comes under my version control with git. Each paper in my thesis repository has its own folder. Within that folder there is a LaTeX subfolder, where I keep everything needed for the writing of the paper, and an R or MATLAB folder depending on what program I’m using to do the modelling (and all the code goes into the repository). Within the LaTeX folder I have a whole bunch of .tex files and a folder where I store the images to be included in the paper. One of my favourite commands in LaTeX is . Every section in a paper has its own LaTeX source file. I find that this helps me navigate my work when I’m writing, especially when making corrections. Each file gets worked on separately and I save frequently. If I’m finished dealing with a section or I’m heading off for a break I will save everything and commit the current changes with a note about which section I’ve been focussing on. I picked this based writing up in my Honours degree when I got sick of having screen after screen of text. If I want to omit a section in a draft I can just comment out the line. Reorganising sections and maybe even subsections, becomes an issue of swapping two or three lines of LaTeX rather than copying and pasting giant blocks of text. I’m a sucker for vector graphics so I will use PDF graphs and pdflatex wherever I can. Occasionally I succumb to using PGF/TikZ for a while but usually have to generate so many different styles of plots that I don’t bother. So anyway, PDF graphics. These are really quite small and can be stored in git no trouble at all. I know git’s more or less useless for version control and revision of binary files (but PDF and EPS files are quite different) but I find it useful to be able to overwrite my graphs and still have the older versions available through reverting to a previous commit rather than making endless folders called “oldgraphics”. The root of my thesis repository has a folder called “Bibliography” which is where a monolithic bibtex file called “allpapers.bib” is stored. Because I will cite the same references across multiple papers I find the idea of having separate bibliography databases a bit silly. I use JabRef to edit this, by the way. All my \bibliography commands point to ../../Bibliography/allpapers.bib. I’ve even got a template for papers with that line in it so that I don’t even have to think about how I do my referencing. With regards to the Finnish paper, this compartmentalisation reduces, even further, the risk of conflicts. Committing changes to one section at a time means the commit messages are often quite descriptive without having to be quite long. The mixture of a few lines of changes and a brief summary means it’s easy to see what’s happened in the changelog. I also use git to keep track of side projects that have popped up during my thesis. Coworkers will often come to me with a question about some data analysis or if I can write a script to make a certain repetitive task as automatic as possible. Each coworker gets a subfolder within a /Side Projects/ folder and within those there are folders for each little project. If I worked in a group where use of git was widespread I would consider making a separate project for each person and inviting them as a collaborator. I kind of wish that QUT had a git server (the school of IT had a subversion server but I really dislike SVN after discovering git) and that scientists were encouraged to use R/MATLAB/SAS for their statistics and modelling instead of Excel. I think it’d a great way to foster collaboration and have people be able to work on a project and make changes, share their code with their coworkers, etc. without sending code and draft papers around via email. Actually a private git server without the account level limitations that github imposes would be an invaluable tool, especially if you could just open up your repositories to the QUT community to show what you’re doing and provide colleagues with usable code for statistical analysis, image manipulation tools, etc. And if someone within the university came across your work and liked it, you would potentially have another paper to work on within the uni.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Elsevier - spatial statistics</title>
      <link>/./2012/05/11/elsevier---spatial-statistics/</link>
      <pubDate>Fri, 11 May 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/05/11/elsevier---spatial-statistics/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://xianblog.wordpress.com/2012/05/11/new-elsevier-journal/&#34;&gt;Christian Robert has just blogged&lt;/a&gt; about a new Elsevier journal - &lt;a href=&#34;http://www.journals.elsevier.com/spatial-statistics/&#34;&gt;Spatial Statistics&lt;/a&gt;. I think the idea of a dedicated spatial statistics journal is fantastic, but I don’t like that Open Access publishing in this journal will cost at least $3000, that the institutional subscription rate is around $650 per year and that authors can post the final version of the text (not the published paper, which is fair enough) on their personal or institutional website but not on the arXiv (so good luck with that if you’re at a university that doesn’t keep up with the times) (but you can post pre-prints to the arXiv). With mild regret, I won’t be submitting to either Spatial Statistics or &lt;a href=&#34;http://www.journals.elsevier.com/spatial-and-spatio-temporal-epidemiology/&#34;&gt;Spatial and Spatio-temporal Epidemiology&lt;/a&gt;, even though these two journals are right up my alley and published by a respected&lt;sup&gt;[&lt;em&gt;by whom?&lt;/em&gt;]&lt;/sup&gt; publisher&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Open access and my next paper</title>
      <link>/./2012/04/19/open-access-and-my-next-paper/</link>
      <pubDate>Thu, 19 Apr 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/04/19/open-access-and-my-next-paper/</guid>
      <description>&lt;p&gt;I got some substantial feedback from one of my supervisors earlier in the week and I’ve been chopping and changing this paper to ensure that the results section is more than just “Look at these graphs. They are graphs.” and that the introduction actually introduces the problem before leaping into how we propose to solve it. Another one of my supervisors will always pick me up on my use of informal language. I tend to write as if I’m explaining how I went about solving a problem, which is very well suited to tutorials, blogging and the &lt;a href=&#34;https://wiki.qut.edu.au/display/npbayes/home&#34;&gt;NP Bayes Wiki&lt;/a&gt; (the reading group is currently on hiatus) but less well suited to academic papers which will be sent to peer reviewed journals. I need to keep working on my formal scientific writing. Part of that probably means reading more academic papers from start to finish rather than skimming them for the information that I need. It probably also doesn’t help that most of the methodological stuff that I’m writing is drawn from the documentation and FAQs of an R package as well as personal communication with the authors of said package (said package is &lt;a href=&#34;www.r-inla.org&#34;&gt;R-INLA&lt;/a&gt;). I’ve got three papers on the go at the moment, so it’s going to be important that I can pick the low-hanging fruit of avoiding informal language so that my supervisors can concentrate on the actual work when giving me feedback. I’ve recently been spending a fair amount of time thinking about, and discussing with some colleagues, the issues of the &lt;a href=&#34;http://thecostofknowledge.com/&#34;&gt;Elsevier boycott&lt;/a&gt;, open access publishing and the use of preprint repositories like &lt;a href=&#34;http://arxiv.org/&#34;&gt;arXiv&lt;/a&gt;. QUT supports open access to some extent by running an &lt;a href=&#34;http://eprints.qut.edu.au/&#34;&gt;ePrints&lt;/a&gt; repository, where university researchers are encouraged to deposit a preprint of their work (not the version published by the journal), and &lt;a href=&#34;http://libguides.library.qut.edu.au/content.php?pid=84068&amp;amp;sid=624559&#34;&gt;subscribing to, or taking out membership with&lt;/a&gt;, a few open access journals. Some of these are quite highly regarded, particularly publications by the Public Library of Science, such as &lt;a href=&#34;http://www.plosone.org/home.action&#34;&gt;PLoS ONE&lt;/a&gt;. The bulk of our papers at ILAQH end up in Elsevier’s &lt;a href=&#34;http://www.journals.elsevier.com/atmospheric-environment/&#34;&gt;Atmospheric Environment&lt;/a&gt;, quite a respectable journal, but I feel uncomfortable propping up a business with such a coercive business model that allows them to operate at a &lt;a href=&#34;http://www.nytimes.com/2012/02/14/science/researchers-boycott-elsevier-journal-publisher.html?_r=1&#34;&gt;profit level of 36&lt;/a&gt;%. Sure, Adam Smith tells us that the baker is a baker not out of a love of bread but out of a desire to earn money with which to live, but we don’t have to accept the terms of business of one large company. I’m particularly interested in journals where the authors retain the copyright (or in the case of QUT, &lt;a href=&#34;http://www.mopp.qut.edu.au/D/D_03_01.jsp#D_03_01.05.mdoc&#34;&gt;the authors’ institution&lt;/a&gt;). I’m also a fan of journals which are innovating in the modern publishing environment, such as the &lt;a href=&#34;http://www.amstat.org&#34;&gt;American Statistical Association&lt;/a&gt;’s &lt;a href=&#34;http://www.jstatsoft.org/&#34;&gt;Journal of Statistical Software&lt;/a&gt; which is not only open access but publishes each article as its own issue of the journal, increasing the frequency of publication to a point where when an article’s reviewed it’s published straight away. I don’t like Elsevier’s business model and would be happy to look at publishing in high quality open access journals where the authors don’t have to sign away their copyright to the publishers. After all, it’s not the journals funding or doing the work. I believe granting the publishers a time-limited exclusive license to publish would be a far better model. There are other journals with a similar level of credibility and respect that don’t require authors to sign over copyright, don’t coerce libraries into taking big packages with unwanted journals bundled in and don’t freeze the person in the street out of reading the results of publicly funded research (a lot of research in Australia is funded by the &lt;a href=&#34;http://www.arc.gov.au/&#34;&gt;Australian Research Council&lt;/a&gt;, a government funding body). I don’t think Elsevier are evil, but they have a terrible business model in terms of disseminating high quality research to the public in an affordable manner. There are others out there doing a better job and researchers should support them.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
