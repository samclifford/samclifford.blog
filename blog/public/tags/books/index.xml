<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Books on Sam Clifford </title>
    <link>/./tags/books/</link>
    <language>en-us</language>
    <author>Alexander Ivanov</author>
    <updated>2014-02-17 00:00:00 &#43;0000 UTC</updated>
    
    <item>
      <title>My reading list at the moment</title>
      <link>/./2014/02/17/my-reading-list-at-the-moment/</link>
      <pubDate>Mon, 17 Feb 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/02/17/my-reading-list-at-the-moment/</guid>
      <description>&lt;p&gt;While it continues to grow longer and longer, I have a stack of books on my desk that I hope to get through in a timely manner. Always on the lookout for a good general reference for Bayesian statistics, I’ve borrowed a copy of Congdon’s “Bayesian Statistical Modelling”. This has some really nice examples in it and covers topics I’m interested in such as spatial statistics and splines. I want to try my hand at understanding Variational Bayes, as I think it’ll be useful for a Discovery Project we’re submitting. To this end, the monolithic “Probabilistic Graphical Models” is sitting there, taunting me. One of my PhD students is taking his first steps into advanced statistics, having completed a Coursera course in data analysis (his second course starts today). Jim Albert’s “Bayesian Computation in R” kind-of assumes you’ll be writing code rather than using packages but I found it a useful way to wrap my head around some concepts. And as an early birthday present I got a copy of Nate Silver’s “The Signal and the Noise”. I’m already about 30 pages in and am quite impressed with how upfront he is about his belief in subjective Bayesianism as a means of inferring and predicting. &lt;a href=&#34;xianblog.wordpress.com/2013/02/27/the-signal-and-the-noise-2/&#34;&gt;Christian Robert reviewed the book&lt;/a&gt; a year ago and has some interesting thoughts on Silver’s approach to statistics. I want to get a copy of Gelman’s BDA v3.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior Samples</title>
      <link>/./2013/01/21/posterior-samples/</link>
      <pubDate>Mon, 21 Jan 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/01/21/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://blog.revolutionanalytics.com/2013/01/elements-of-statistical-learning-2nd-ed-download.html&#34;&gt;Free download&lt;/a&gt; of Hastie, Tibshirani and Friedman’s “Elements of Statistical Learning”. Hastie and Tibshirani did a lot of the early work on Generalised Additive Models and non-parametric smoothing, albeit in a non-Bayesian framework, so this will no doubt be an invaluable resource. NASA have released &lt;a href=&#34;http://www.nasa.gov/topics/earth/features/2012-temps.html&#34;&gt;a neat visualisation&lt;/a&gt; of spatio-temporal deviation from the mean temperature going back to the 1880s. You have to be careful when generating “pretty” graphics, though, because &lt;a href=&#34;http://andrewgelman.com/2013/01/ugly-ugly-ugly/&#34;&gt;“pretty” infographics can be quite ugly and hard to decode&lt;/a&gt; when you’re not taking into account what the data actually represents. &lt;a href=&#34;http://www.biostat.jhsph.edu/~rpeng/&#34;&gt;Roger Peng&lt;/a&gt; &lt;a href=&#34;http://simplystatistics.org/2013/01/16/review-of-r-graphics-cookbook-by-winston-chang/&#34;&gt;reviews&lt;/a&gt; Winston Chang’s “R Graphics Cookbook”. The conclusion? A pretty good collection of examples about how to complete particular graphing tasks using ggplot2. It’s a simpler book than Hadley Wickham’s “ggplot2” and would be a good introduction to using ggplot2 to achieve a particular goal. &lt;a href=&#34;http://about.jstor.org/rr&#34;&gt;JSTOR’s “Register &amp;amp; Read”&lt;/a&gt; is in beta now. So if you’re not attached to a university or other institution with a JSTOR subscription, you now have the opportunity to read JSTOR articles for free (but it’s not unlimited, at least not yet). Speaking of free access to published research, &lt;a href=&#34;http://www.guardian.co.uk/science/blog/2013/jan/17/open-access-publishing-science-paywall-immoral&#34;&gt;this opinion article&lt;/a&gt; makes the point that our job as scientists is to contribute to the body of human knowledge for the benefit of society and so if a paper isn’t freely available to the public then it isn’t really “published”. Not only that, but to hide research behind a paywall is immoral. I found it very interesting even if I thought some of his arguments were a bit dismissive.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Where to start if you&#39;re going to revise statistics</title>
      <link>/./2012/07/13/where-to-start-if-youre-going-to-revise-statistics/</link>
      <pubDate>Fri, 13 Jul 2012 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2012/07/13/where-to-start-if-youre-going-to-revise-statistics/</guid>
      <description>&lt;p&gt;I’d like to think it was my plenary speech that has spurred this, but given that they didn’t see it I’m not sure that it was, but one of the academics in my lab has decided it’s time to refresh their statistical knowledge. I think this is great, because they got their PhD a long time ago and have probably been using the same statistical methods for at least the last ten years. The book they’ve decided to use is the &lt;a href=&#34;http://www.amazon.com/Schaums-Outline-Statistics-Murray-Spiegel/dp/0070602816&#34;&gt;Schaum’s Outline of Statistics&lt;/a&gt;. I’ve used books from this range before to revise linear algebra, differential equations, etc. and have even taught small courses (privately) based on the topics they cover and in the order they cover them. A flick through the book confirmed that it was full of frequentist testing and other similar statistical methods that I spent my talk saying were a good start but not the end of the analysis when writing a scientific paper. The book’s online summary says it covers the use of MINITAB. I’m glad to see that it discusses the use of software other than Excel to perform analysis but I recommend people use books in Springer’s “&lt;a href=&#34;http://www.springer.com/series/6991?detailsPage=titles&#34;&gt;Use R!&lt;/a&gt;” range because R is free (in terms of both speech and beer) and is much more flexible than MINITAB in terms of programming it and running different types of analysis. Where MINITAB is based on a point and click GUI, making it great for a first year statistics class where students may not be familiar with programming, R is driven by the command line and is more easily scripted. Learning to use R means giving yourself the opportunity to use the many &lt;a href=&#34;http://cran.r-project.org/web/packages/available_packages_by_name.html&#34;&gt;packages&lt;/a&gt; that extend its functionality. The books I’ve used in the Use R! range include &lt;a href=&#34;http://www.springer.com/statistics/computational+statistics/book/978-0-387-93836-3&#34;&gt;A Beginner’s Guide to R&lt;/a&gt; and &lt;a href=&#34;http://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-92297-3&#34;&gt;Bayesian Computation with R&lt;/a&gt;. While I’d definitely recommend these Use R! books, as they’re aimed at people wanting to use R to do better analysis, there are a few others that I’ve found incredibly useful. It’s important for me to point out that my background differs from my colleague’s so they may not find the books as relevant or accessible. &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/book/&#34;&gt;Gelman et. al - Bayesian Data Analysis&lt;/a&gt;. Around my stats group, this book is called “The Bible”. It’s probably the best textbook I’ve come across. It’s full of information, tutorials, detailed descriptions of the theory and methods and how they can be applied. This is certainly a graduate level statistics textbook, though, and it assumes calculus at what I’d say is probably a second year mathematics degree level. You may find this book difficult if you don’t feel comfortable with multiplying integrals together (which is really what Bayesian analysis is). I sent my colleague a link to &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/AOS259.pdf&#34;&gt;Gelman’s Annals of Applied Statistics article on ANOVA&lt;/a&gt;. Might as well plug &lt;a href=&#34;http://andrewgelman.com/&#34;&gt;Gelman’s blog&lt;/a&gt; while I’m talking about him. &lt;a href=&#34;http://www.amazon.com/Biostatistics-Bayesian-Introduction-Probability-Statistics/dp/0471468428&#34;&gt;Woodworth - Biostatistics: a Bayesian introduction&lt;/a&gt;. I found this very useful in giving a more applied approach to introductory Bayesian statistics. There’s a good review of the book &lt;a href=&#34;http://www.theannals.com/content/39/7/1376.2.full&#34;&gt;here&lt;/a&gt; and I agree with the reviewers about the importance of the preface in that it talks about the philosophy of statistics in science and discusses the differences between frequentist and Bayesian statistics. The book walks the reader through a lot of the topics which frequentist statistics deals with but in a Bayesian setting. I find this sort of comparison very useful (and appreciate when Mike Jordan says that a lot of machine learning techniques are just Bayesian statistics with a different name) as most people who have taken a statistics class will have seen linear modelling, ANOVA and a little about statistical design. The book also introduces the use of &lt;a href=&#34;http://www.openbugs.info/w/&#34;&gt;WinBUGS&lt;/a&gt; as a tool for Bayesian modelling. As an aside, I attended an introductory course run by my supervisor, Kerrie Mengersen, where she was teaching us how to use R to write a Gibbs sampler for a very simple problem and how to do it in WinBUGS as well. One of the other attendees, the leader of a medical science research group, had it in their head that they would use Excel to write the Gibbs sampler because it provides nice reports (summary stats, plots, etc.) through a plugin they had. Comparing the time it took WinBUGS and R to run the code against the Excel’s run time was probably what convinced me that Excel was one of the worst pieces of software that one could use for statistics. Great for spreadsheets, awful for statistics. A non-technical book which does a good job extending the philosophical discussion to the history of Bayesian statistics and its use in solving some very complex problems is &lt;a href=&#34;http://www.amazon.com/Theory-That-Would-Not-Die/dp/1452636850&#34;&gt;Sharon Bertsch McGrayne’s The Theory That Would Not Die&lt;/a&gt; (which I like to think of as the “A Brief History of Time” of Bayesian statistics). It’s very readable and really drives home the importance of Bayesian statistics and the profundity of Bayes and Laplace in developing this approach. I really don’t think there’s much use revising the basics of frequentism as I disagree with its interpretation of probability and find the idea of confidence intervals problematic. Hypothesis testing is also another problem that I have with frequentism and I think we’re going to see a lot of scientific papers in the near future converting the p values for their ANOVA into a “sigma” level as a result of CERN’s announcement of the 5 sigma certainty of their search for a new boson. Tony O’Hagan has &lt;a href=&#34;http://bayesian.org/forums/news/3648&#34;&gt;a good post&lt;/a&gt; about the “sigma” issue on the ISBA forums. Edited to add: TL;DR? Got a maths degree and some familiarity with stats? Read Gelman. Don’t have a maths degree? Read Woodworth. Want to understand what Bayesian stats is but don’t want to read a textbook? Read McGrayne. Want to know how to use R? Read a Use R! book. Once you’ve got a decent understanding of what statistics is, read papers for specific topics because there is almost never a book about what you want.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
