<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
      <title>Pedagogy on Sam Clifford </title>
    <link>/./tags/pedagogy/</link>
    <language>en-us</language>
    <author>Alexander Ivanov</author>
    <updated>2014-10-17 00:00:00 &#43;0000 UTC</updated>
    
    <item>
      <title>posterior samples</title>
      <link>/./2014/10/17/posterior-samples/</link>
      <pubDate>Fri, 17 Oct 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/10/17/posterior-samples/</guid>
      <description>&lt;p&gt;I probably should have put this post up earlier because it’s now a huge collection of stuff from the last month. Here we go! It appears that &lt;a href=&#34;http://hilaryparker.com/2012/08/16/the-setup-part-1/&#34;&gt;Hilary Parker&lt;/a&gt; and I have similar (but by no means identical) work setups for doing stats (or at least we did two years ago). It’s never too late to come up with a sensible way of organising your work and collection of references/downloaded papers. Applied statisticians should probably &lt;a href=&#34;http://simplystatistics.org/2014/09/15/applied-statisticians-people-want-to-learn-what-we-do-lets-teach-them/&#34;&gt;teach scientists what it is we do&lt;/a&gt;, rather than just the mathematics behind statistics. This is a difference I’ve noticed between SEB113 and more traditional statistics classes; we spend a lot less time discussion F distributions and a lot more time on model development and visualisation. Speaking of visualisation, here’s a really great article on visualisation and how we can use small multiples and colour, shape, etc. to highlight the interesting differences so that it’s very clear what our message is. Jeff Leek has compiled &lt;a href=&#34;http://simplystatistics.org/2014/09/09/a-non-comprehensive-list-of-awesome-female-data-people-on-twitter/&#34;&gt;a list of some of the most awesome data people&lt;/a&gt; on Twitter who happen to be female. In the ongoing crusade against abuse of p-values, &lt;a href=&#34;http://simplystatistics.org/2014/09/30/you-think-p-values-are-bad-i-say-show-me-the-data/&#34;&gt;we may want to instead focus on reproducibility&lt;/a&gt; to show that our results say what we say they do. Andrew Gelman and Eric Loken have &lt;a href=&#34;http://www.americanscientist.org/issues/feature/2014/6/the-statistical-crisis-in-science/99999&#34;&gt;an article in The American Statistician&lt;/a&gt; reminding us that p-values have a context and we need to be aware of issues like sample size, p-hacking, multiple comparisons, etc.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Paper helicopters</title>
      <link>/./2014/08/15/paper-helicopters/</link>
      <pubDate>Fri, 15 Aug 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/08/15/paper-helicopters/</guid>
      <description>&lt;p&gt;There is no textbook for SEB113 - Quantitative Methods in Science. It’s not that we haven’t bothered to prescribe one, it’s that no one seemed to be taking the same approach we decided upon two years ago when the planning for the unit started. There are books on statistics for chemistry, statistics for ecology, statistics for physics, statistics for mathematics, etc. but trying to find a general “statistics for science” book that focuses on modelling rather than testing has been difficult. That said, there are some amazing resources out there if you know where to look, not just for learning statistics but for teaching statistics. One of the most useful that we’ve come across is “&lt;a href=&#34;http://ukcatalogue.oup.com/product/9780198572244.do&#34;&gt;Teaching Statistics&lt;/a&gt;”, by Andrew Gelman and Deborah Nolan. The book itself is full of advice for things like groupwork, topic order, structure of learning activities, etc. but my favourite thing so far is the paper helicopter experiment. &lt;a href=&#34;http://www.tandfonline.com/doi/pdf/10.1080/08982119208918925&#34;&gt;George Box&lt;/a&gt; introduced engineering students to statistical design with the paper helicopter. The experiment itself is quite simple and motivates the idea of using statistics to optimise some design by varying the dimensions of the helicopter. As an activity, it’s a fun way to collect some data that can be used in analysis. By dividing the class up into groups and getting each group to do one or two different designs it’s possible to collect quite a large amount of data, with replication used to identify any group-level effects that may be explaining the variation within the data. There’s a great &lt;a href=&#34;http://www.tandfonline.com/doi/abs/10.1198/000313005X70777#.U-1UePmSx8E&#34;&gt;paper by David Annis&lt;/a&gt; which simplifies the experiment by only varying the length and width of the helicopter’s “blade”, and explains that fitting polynomials and their interactions may yield a regression surface which explains the variation but ignores the physics of the helicopter. In a class teaching statistics to scientists, any chance to tie the statistics to some scientific context must be leapt upon. One of the biggest challenges in teaching statistics is making it relevant to students so that it doesn’t come across as a dry technique for crunching numbers but as a way of probing deeper into a scientific question. I was discussing the experiment with a colleague yesterday who mentioned that when she was learning mathematics at university as part of her science degree it was at the hands of mathematicians who were teaching the unit as if it were for other mathematicians. It was only at the end of the course that a lecturer said “Oh, and by the way, these methods can be used to analyse scientific data”. This is the message that needs to come at the start of the class. Statistics (and more generally, mathematics) gives the scientist a set of tools to ask questions of their data. Being able to ask the right question is therefore very valuable. Ignoring the science means you’re throwing out all the hard work that went into the experimental design and data collection. This is one reason we focus so much on modelling instead of testing. Stopping your analysis at ANOVA doesn’t do justice to your data. Annis’ paper shows the derivation of a mathematical model of the motion of the helicopter from force balance equations, terminal velocities and rotational inertia. This mathematical model is then converted to a non-linear regression model. In SEB113 we cover non-linear regression after linear regression and then show where the regression models come from with a week of mathematical modelling. Even though students enrolled in the unit may not have Senior Maths B (assumed knowledge, rather than a formal pre-requisite) many enjoy peeking behind the curtain to see where the models come from. More than that, they are learning that application-specific non-linear models include what is known about the particular application. We explain first order compartment models (pharmacokinetics), asymptotic growth (ecology), the biexponential model (biology) and logistic growth (ecology) models and show the mathematical models that lead to their existence. We’ve also shown the Lotka-Volterra equations (ecology) in the past as an example of emulating a system, which students seem to enjoy (some are even comforted by the idea that there’s no exact solution). This year we’ll be adding the paper helicopter model to the mix, performing the experiment in week 5’s workshops and analysing the data in the Problem Solving Tasks. I’ll try to get some feedback on whether the students enjoy the experiment and can understand and complete the outcomes; I think it’s neat, but does it appeal to them? I really like that in the past we’ve had students who feel ownership of their data by collecting it in SEB114 - Experimental Science and analysing it in SEB113. SEB114 doesn’t run in second semester, though, so we have had to figure out ways of collecting data for analysis and I think the helicopter’s the best one we’ve come up with yet. We’ve modified the design found in Annis’ paper and I’ve used Adobe InDesign to come up with a printable A4 design where students don’t have to do any measuring, just cutting, folding and paper clipping. We have 12 designs available to us, which gives us a lot of flexibility when it comes to parallelising the experiment.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2014/07/02/posterior-samples/</link>
      <pubDate>Wed, 02 Jul 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/07/02/posterior-samples/</guid>
      <description>&lt;p&gt;ARC Discovery Projects have been returned to their authors, and we are putting our responses together for the rejoinders. Interesting to see that we got a comment suggesting that we use the less restrictive CC-by instead of CC-by-nc-sa as we’d suggested. We weren’t successful in our Linkage Project applications, which is disappointing as they were interesting projects (well, we thought so). Continuing to bring research funding in is an ongoing struggle for all research groups and I feel it’s only going to get harder as the new federal government’s research priorities appear to be more aligned to medical science that delivers treatments than to our group’s traditional strengths. SEB113 is pretty much completely over for the semester, with marks having been entered for almost every student. Overall I think the students did fairly well. We had some issues with the timetable this semester. Ideally, we’d like the Lecture, then all of the computer labs, then all of the workshops, so that we can introduce a statistical idea, show the code and then apply the idea and code in a group setting. Next semester, we have the lecture followed immediately by the workshops with the computer labs dotted throughout the remainder of the week. This has provided us with an opportunity to try some semi-flipped classroom ideas, where students are able/expected to do the computer lab at home at their own pace rather than watch a tutor explain it one line at a time at the front of a computer lab. I’m teaching part of a &lt;a href=&#34;http://www.eventbrite.com.au/e/r-statistical-language-for-air-pollution-epidemiology-tickets-12043581677&#34;&gt;two day course&lt;/a&gt; on the use of R in air pollution epidemiology. My part will introduce Bayesian statistics with a brief overview, a discussion about prior distributions as a means of encoding &lt;em&gt;a priori&lt;/em&gt; beliefs about model parameters, and discuss the use of Bayesian hierarchical modelling (as opposed to more traditional ANOVA techniques) as a way of making the most of the data that’s been collected. The other two presenters are &lt;a href=&#34;http://researchers.uq.edu.au/researcher/2181&#34;&gt;Dr Peter Baker&lt;/a&gt; and &lt;a href=&#34;http://researchers.uq.edu.au/researcher/2530&#34;&gt;Dr Yuming Guo&lt;/a&gt;. The course is being run by the CAR-CRE, who partially fund my postdoctoral fellowship. I had meant to post this back when they were doing the rounds, but there’s &lt;a href=&#34;http://www.tylervigen.com/&#34;&gt;a bunch of plots&lt;/a&gt; that attempt to show that correlation isn’t causation and that spurious correlations exist in large data sets. &lt;a href=&#34;https://tom-christie.github.io/articles/correlation/&#34;&gt;Tom Christie has responded&lt;/a&gt; to this by going over the fact that correlation in time series isn’t as simple as in the case of independent, identically distributed data. One should be careful that one’s criticism of bad statistics is itself founded on good statistics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2014/05/22/posterior-samples/</link>
      <pubDate>Thu, 22 May 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/05/22/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://www.compoundchem.com/2014/04/02/a-rough-guide-to-spotting-bad-science/&#34;&gt;A rough guide to spotting bad science&lt;/a&gt;. &lt;a href=&#34;http://simplystatistics.org/2014/05/07/why-big-data-is-in-trouble-they-forgot-about-applied-statistics/&#34;&gt;Why big data is in trouble: they forgot about applied statistics&lt;/a&gt;. Big data analytics are all well and good but you have to keep in mind that there are statistical properties that govern which inferences are valid. While I’m comfortable giving a lecture I really struggled to get through them in undergrad. &lt;a href=&#34;http://news.sciencemag.org/education/2014/05/lectures-arent-just-boring-theyre-ineffective-too-study-finds&#34;&gt;It turns out they may not be the most effective way to get information to students.&lt;/a&gt; My supervisors, Professor Lidia Morawska, is giving a public talk (free to register) at QUT soon, &lt;a href=&#34;https://www.qut.edu.au/institute-for-future-environments/about/news-events/news?news-id=71015&#34;&gt;“Air Quality Reports On Our Mobiles - Do We Care?”&lt;/a&gt; June 6 2014&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The ongoing crusade against Excel-based analysis</title>
      <link>/./2014/05/14/the-ongoing-crusade-against-excel-based-analysis/</link>
      <pubDate>Wed, 14 May 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/05/14/the-ongoing-crusade-against-excel-based-analysis/</guid>
      <description>&lt;p&gt;&lt;span style=&#34;line-height:1.714285714;font-size:1rem;&#34;&gt;One of the things I catch myself saying quite often in SEB113 is “This is new. It’s hard. But remember, you weren’t born knowing how to walk. You learned it”, as my way of saying that it’s okay to not understand this straight away, it takes time, practice and determination. I often say this in response to students complaining about learning R to do their data analysis. It’s actually got to the point where t&lt;/span&gt;&lt;span style=&#34;line-height:1.714285714;font-size:1rem;&#34;&gt;he unit co-ordinator suggested I get a t-shirt printed with “You weren’t born knowing how to walk” on the front and “So learn R” on the back.&lt;/span&gt; One of the reasons I’m so keen to push new students into learning R is that while Excel can do some of the simpler calculations required in the first year of a science degree it is often completely inadequate for doing data analysis as a professional scientist, or even in an advanced level university course. I actually saw a senior researcher in a 3 day Bayesian statistics course try to avoid using R to code a Gibbs sampler by getting it up and running in Excel. They managed it, but it took minutes to run what the rest of us could compute in a second (and it was for a trivially simple problem). There are &lt;a href=&#34;http://www.asq904.org/StatisticalFlawsInExcel.pdf&#34;&gt;problems with Excel&lt;/a&gt;, such as its inability to deal with the standard deviation of a group of very large numbers due to its bizarre formulation. Apparently the secret to sane use of Excel is to &lt;a href=&#34;http://www.r-bloggers.com/excel-fanaticism-and-r/&#34;&gt;only use it for data storage&lt;/a&gt;. This guiding principle has meant that I no longer manipulate my data in Excel. Even with time stamp information I’ll fire up the &lt;a href=&#34;http://cran.r-project.org/web/packages/lubridate/index.html&#34;&gt;lubridate&lt;/a&gt; package to convert from one format to another. I’m slowly exploring the &lt;a href=&#34;http://blog.datascienceretreat.com/&#34;&gt;Hadleyverse&lt;/a&gt; and that sort of approach is filtering through into SEB113 where we’re teaching the use of ggplot2 and reshape2 within RStudio. These are all powerful tools that simplify data analysis and avoid the hackish feel that much Excel-based analysis has, where pivot tables are a thing and graphs are made by clicking and dragging a selection tool down the data (which can lead to &lt;a href=&#34;http://en.wikipedia.org/wiki/Growth_in_a_Time_of_Debt&#34;&gt;some nasty errors&lt;/a&gt;). The fact that these powerful tools that make data analysis simple are free is another reason to choose R over Excel. I’m not on the “Open Source Software and provision of all code is mandatory” bandwagon as others seem to be when it comes to analysis being replicable. I agree it’s a worthwhile goal but it’s not a priority for me. That said, though, I definitely support encouraging the use of free software (in both senses) in education on the grounds of equity of access. I had a chat with some students in SEB113 yesterday about why we’re teaching everything in R given that the SEB114 staff use a combination of Excel, MATLAB (and maybe even other packages I don’t know about). If we were to teach analysis the way that the SEB114 lecturers do it themselves, we’d have to teach multiple packages to multiple disciplines. Even discounting the fact that everything we teach is implemented in R, that R is free (unlike Excel and MATLAB), cross-platform (Excel on Linux? Try OpenOffice/OfficeLibre) and extensible (MATLAB has toolboxes, Excel has add-ins, R has a nice package manager) was a big plus for students who said that being able to work on assignments at home was valuable and so paying for software would make study difficult. Convincing students to use R can be difficult, especially if they have no programming background, but ultimately they seem to accept that R is powerful, can do more than Excel and that writing reusable code makes future analysis easier. Convincing SEB114 academics that teaching their students to use R is a good idea is probably a harder sell, given that they’ve got years of experience with other tools. It’s still only semester 3 of the new Bachelor of Science course so we’ll have to see how this plays out over the years to come.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Timetabling and the potential for alternative delivery in SEB113</title>
      <link>/./2014/04/07/timetabling-and-the-potential-for-alternative-delivery-in-seb113/</link>
      <pubDate>Mon, 07 Apr 2014 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2014/04/07/timetabling-and-the-potential-for-alternative-delivery-in-seb113/</guid>
      <description>&lt;p&gt;I’ve been pretty busy writing the analysis plan for the main paper from the UPTECH project and reorganising SEB113 workshops. We’ve had some meetings recently with QUT timetabling people which has led to discussions about how we try to get students to enrol in a sensible pair of workshops and labs for both SEB113 and SEB114. One of the biggest concerns when it comes to these paired subjects is making sure that people attend the labs and workshops in the right order and are working with the same groups across both subjects so that we can structure the teaching material. In SEB113 the preferred order of classes is Lectorial, Computer Lab, Collaborative Workshop. The lecture introduces the topic, the lab shows you how it’s implemented in R and the workshop gets you working in a group with others to solve a problem based on the topic. The problem comes about with QUT’s timetabling software providing a timetable which contains no clashes for the core first year subjects (SEBs 101, 102, 113, 114). Timetabling the lectures/lectorials for these units so that they don’t clash is a task in and of itself and I’m impressed that the timetabling people have managed to make sure these subjects don’t clash (I remember taking two units for the applied physics co-major in the old B App Sc course where the lectures clashed). The non-clashing timetable doesn’t necessarily mean students can enrol in the class order that we would prefer. It’s also unlikely that we can automatically combine a lab-workshop pair as one thing to be enrolled in and it’s impractical to try to get a staff member to enrol students manually. It’s got me thinking a lot about flipped classrooms and other ways of overcoming the timetable difficulty. The benefit of the workshop for students is that they have a group to work with on a big task and they have two tutors to ask for help when they get stuck. I feel like this would be difficult to do outside a classroom without some sort of help-desk queueing system that is only open between certain times (and then you’ve still got the time restrictions). The computer labs can be done individually at any time, though, as they’re about exposure to code rather than solving a particular problem. In this instance, we could probably cut down on the number of computer labs required by encouraging students to do the lab in their own time before their workshop, which is in the spirit of flipped classrooms. The last labs are in week 7 (this week!) which means it’s not going to be an issue much longer this semester. Semester 2 has fewer SEB113 enrolments (SEB114 isn’t offered) so it’s not going to be as big an issue then. Whether we go with changing the timetabling system or we modify computer labs to become programming consults (where to get help you must have attempted the lab) is something we can deal with a bit later. With the use of Echo360 being made mandatory in all lectures at QUT the availability of recorded lectures makes it easier for students to go through the material at their own pace. With so many students in the subject, there’s a large number of person hours which go into content delivery. I’m not sure we’re using that resource (labour) as effectively as we can, and changing the way we deliver the subject may help that.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Science as storytelling</title>
      <link>/./2013/11/06/science-as-storytelling/</link>
      <pubDate>Wed, 06 Nov 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/11/06/science-as-storytelling/</guid>
      <description>&lt;p&gt;I used to not be a very confident public speaker. I remember getting up at a community meeting in 2007 and stammering some words out to a group of residents; it was a disaster. Motivated for the desire for some money to augment my Youth Allowance payments I applied to be a tutor with the School of Mathematics (QUT) during my final years of undergrad and found that I became a bit better at talking to people. My Honours seminar was still a nervous affair but it was much less disastrous than the community meeting. After Honours I had a job teaching mathematics to a group of video game programmers, developing the curriculum to suit their needs and interests and it’s here that I became far more comfortable with speaking. I was coming up with my own material and delivering it to people who I knew were interested in it. That’s a world away from teaching university students, where many may not see the point in learning what I’m teaching. This is especially the case in service mathematics and statistics units. During my PhD studies I got interested in improvised theatre as a creative alternative to the mathematics, statistics and science that was my day. My reputation as someone not afraid to get up in front of 100 people and perform lead to my being asked by one of my PhD supervisors if I’d like to be a tutor in the brand new SEB113 course. Teaching students how to use R for their data analysis? Of course I’m interested! After the end of a very enjoyable, if somewhat disjointed, semester I was asked if I’d consider lecturing the smaller second semester re-run. I jumped at the chance. Restructuring the subject from the way it was run in first semester meant we could focus on the way the material flowed and see if we could smooth out some of the jumps in style, making the unit more consistent and easier to understand. We had to do a lot of work rejigging the slides, writing new workshops and computer laboratory worksheets to accommodate the use of ggplot rather than a combination of base, lattice and MASS graphics. The result was a subject that introduces a diverse list of topics in a much more sensible manner:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Measurement and variation&lt;/li&gt;
&lt;li&gt;Visualisation&lt;/li&gt;
&lt;li&gt;Summary statistics and confidence intervals&lt;/li&gt;
&lt;li&gt;Inference and sample size, hypothesis tests&lt;/li&gt;
&lt;li&gt;Regression lines of best fit&lt;/li&gt;
&lt;li&gt;Regression with a categorical variable&lt;/li&gt;
&lt;li&gt;Non-linear regression based on process models&lt;/li&gt;
&lt;li&gt;Multivariate summary statistics and regression&lt;/li&gt;
&lt;li&gt;Mathematical modelling of process models&lt;/li&gt;
&lt;li&gt;Linear algebra, including the guts of how linear regression works&lt;/li&gt;
&lt;li&gt;Writing scientifically, revisiting the scientific method&lt;/li&gt;
&lt;li&gt;Writing about numbers, conditional probability for understanding hypothesis tests&lt;/li&gt;
&lt;li&gt;Revisiting visualisation&lt;/li&gt;
&lt;li&gt;An introduction to advanced quantitative methods&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It became apparent around week 8-9 that what we were doing was telling a story of how to get from calculating means to understanding how to develop a model to either model a process or emulate that process. The discussions about writing scientifically became about how the quantitative reports were telling a story. The first step, the introduction, is like meeting the characters for the first time and understanding their relationships with each other. As we move through the methods and analysis we see the action of the story unfold. The conclusion is the consequences of the action and by relating the analysis back to the motivating aim we can see the arc of the story and understand more about these characters. Now that the teaching is over and the marking of the quantitative workbooks is coming to a close, I’ve got a bit more space in my head to process my thoughts about improvisation and storytelling (we do a weekly show and I’m still doing workshops on the weekend). I’ve picked up a book on my Kindle by scientist-turned-filmmaker Randy Olson, entitled “&lt;a href=&#34;http://www.amazon.com/gp/product/B00FASMHP8/ref=oh_d__o00_details_o00__i00?ie=UTF8&amp;amp;psc=1&#34;&gt;Connection: Hollywood Storytelling meets Critical Thinking&lt;/a&gt;”. Olson’s book is all about how any intellectual topic can be made interesting and accessible by treating its presentation as telling a story. He states that we, as humans, engage with stories far more than we do with dry information as we feel stories it in our hearts, guts and sexual organs rather than just in our brains. Not only is the communication of scientific results storytelling but lecturing is storytelling. I’ve thought this semester that lecturing is definitely a style of performance, but the idea that the topics in a unit should follow an arc and tell a unified story means that part of the academic’s role is telling a story in the classroom. For me, that means that elements of comedy, pantomime and suspense make their way into my lectures. Storytelling in science is a very interesting topic and I look forward to making my way through the remainder of the book over the end of year break, ready to start a new semester with a revised narrative arc and better storyboarding, maybe even a few new characters.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Response to a student on p values</title>
      <link>/./2013/10/18/response-to-a-student-on-p-values/</link>
      <pubDate>Fri, 18 Oct 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/10/18/response-to-a-student-on-p-values/</guid>
      <description>&lt;p&gt;My students are working on their 25% assessment pieces, the Quantitative Workbook. These are group assignments that require students do a quantitative analysis from start to finish on some ecology data we’ve given them. A few students are struggling with the p value concept, particularly what it means in the R summary.lm() output. I responded to the student with the following statement. It’s a bit more verbose than I might have liked but I think it’s important to try to step it through from start to finish. It took me ages to get this as an undergrad.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The hypothesis test that R does and gives you in the regression summary asks:&lt;/p&gt;
&lt;p&gt;What is the probability of seeing a test statistic (third column in the output) at least as extreme as what we have if the true value of the parameter were actually zero (this is our null hypothesis)?&lt;/p&gt;
&lt;p&gt;Our best estimates of the parameters given the data we are using with our model (first column in the output) are found by minimising the sum of squares of the errors between the observed values and the fitted values (see the Normal equations slides from the linear algebra week). Our uncertainty about those estimates is given to us with the standard error of the estimate (second column in the output) which is related to the size of the standard deviation of the residuals. More uncertainty in our fitted values reflects uncertainty in our parameter estimates. If the standard error is comparable in size to the estimate, then perhaps our uncertainty may mean we can’t reject the idea that the true value of the parameter is zero (i.e. we may not be able to detect that this variable has an effect).&lt;/p&gt;
&lt;p&gt;The test statistic (third column) is assumed to come from a t distribution whose degrees of freedom is the number of data points we started with minus the number of parameters we’ve observed. The idea of the test statistic coming from a t distribution reflects the notion that our data is a finite sample of all the data that could have been collected if the experiment were repeated an infinite number of times under the same conditions. If the test statistic is really far away from zero, then it’s very improbable that we would observe sampled data like this if the true value of this parameter were zero (i.e. the relevant variable plays no role in explaining the variation in the response variable).&lt;/p&gt;
&lt;p&gt;It’s traditional in science to use a cutoff for the p value of 0.05, corresponding to whether a 95% confidence interval covers zero. This is saying “we accept that in 1 out of every 20 identically conducted experiments we may see no observable effect, the rest of the time we see it”. If your p value, the probability of seeing a test statistic at least as extreme as this if the true value of the parameter is zero, is less than 0.05 then you’ve got evidence to reject the null hypothesis. Sometimes we want to be really confident and we choose a cutoff of 0.01, corresponding to whether a 99% CI covers zero. If the p value is less than 0.01 (where only at most 1 in 100 experiments show us a zero effect) then we have evidence to reject the null hypothesis at our 0.01 level. Sometimes we will accept a less confident cutoff of 0.1 (1 in 10 experiments). Whatever level we choose must be stated up front.&lt;/p&gt;
&lt;p&gt;So in summary the hypothesis we are testing is “The true value of the parameter is zero”, the p value is a probabilistic statement that says “If I assume the true value is zero, what’s the probability of seeing a test statistic (that represents how uncertain I am about my estimate) at least as big as this?”&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/08/02/posterior-samples/</link>
      <pubDate>Fri, 02 Aug 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/08/02/posterior-samples/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://lindsaybradford.wordpress.com/2013/07/25/the-database-design-goggles-they-do-nothing/&#34;&gt;Database design is important&lt;/a&gt;, especially if someone else has to work with your database. It’s not really something we teach in undergraduate science, perhaps the American model of requiring a certain number of credits from certain fields would help remedy this. Ever wanted a glimpse of &lt;a href=&#34;http://xianblog.wordpress.com/2013/07/22/bayes-notebook/&#34;&gt;Bayes’ notebook&lt;/a&gt;? Laura McInerney’s comments on the benefits of &lt;a href=&#34;http://thesiswhisperer.com/2013/07/31/in-praise-of-the-small-conference/&#34;&gt;small conferences&lt;/a&gt; are similar to my experience with &lt;a href=&#34;http://bayesian.org/node/1657&#34;&gt;8 BNP&lt;/a&gt; in Veracruz, Mexico. As long as you’re within the niche field this sort of conference is a great experience. I felt a little like an outsider at 8 BNP because while I was interested in non-parametrics and was working on smoothing, a lot of people were working on things that I had no experience with which are actually the central elements of the field. I got to learn about a lot of neat things, hear some great talks and meet lots of amazing people, but I don’t think I was steeped in NP Bayes enough to really get the most out of the conference. My research went a bit away from NP Bayes these last few years so I didn’t get to put anything together for 9 BNP in Amsterdam. Perhaps ISBA 2014 in Cancún, Mexico will provide a bit more of a chance to get back to that work. We’re teaching R in SEB113. Perhaps any students reading this might be interested in these &lt;a href=&#34;http://www.computerworld.com/s/article/9239799/60_R_resources_to_improve_your_data_skills&#34;&gt;60 R resources&lt;/a&gt;. I use multiple monitors at work but really enjoyed the virtual monitors setup in Gnome when I ran Ubuntu. &lt;a href=&#34;http://lifehacker.com/5616859/is-the-multiple+monitor-productivity-boost-a-myth&#34;&gt;It turns out&lt;/a&gt; that having a large canvas of pixels, rather than multiple monitors, is the key to workplace productivity. My work setup has two widescreen monitors side by side in portrait orientation. This doesn’t work particularly well with programs that assume you’re using a single landscape monitor (such as RStudio) or give you a single window with multiple documents inside that each have focus one at a time (Microsoft Office, why can’t I have a spreadsheet on each monitor?) but it means I don’t have to keep switching back and forth between TeXStudio and RStudio when I’m writing up my analysis. &lt;a href=&#34;http://chronicle.com/article/Introduction-to-Ancient/140475/&#34;&gt;Flipped classes&lt;/a&gt; are an interesting model for education. I remember taking an Honours level mathematical modelling course a few years ago where the three hours of lecture time allocated us were used to discuss concepts and do modelling. We would read a chapter from the textbook in the lead-up to the class and then have a talk about what it meant and then work out a model based on a case study. I don’t know how well a truly flipped class would translate to a group bigger than about 30 students, but Sue Savage (QUT) tells me that the new lecture theatres in P block are designed to facilitate small group discussions within lectures. Daina Taimiņa explains &lt;a href=&#34;https://www.youtube.com/watch?v=w1TBZhd-sN0&#34;&gt;hyperbolic geometry&lt;/a&gt; with crochet. Every once in a while something similar pops up and I can’t help but get excited. &lt;a href=&#34;http://longnow.org/essays/richard-feynman-connection-machine/&#34;&gt;Daniel Hills recalls his memories&lt;/a&gt; of working with Richard Feynman on developing a massive parallel computer in the 1980s.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples - SEB113 edition</title>
      <link>/./2013/07/10/posterior-samples---seb113-edition/</link>
      <pubDate>Wed, 10 Jul 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/07/10/posterior-samples---seb113-edition/</guid>
      <description>&lt;p&gt;I’m going to be frank, a lot of this relates to SEB113 - Quantitative Methods for Science, a subject I tutored last semester. One of the students from SEB113 last semester, Daniel Franks, is &lt;a href=&#34;https://twitter.com/dpfscience&#34;&gt;live-tweeting his Bachelor of Science degree&lt;/a&gt;. Daniel was in my workshop group last semester and I recognise some of the events he talks about in his timeline. It’s interesting to see his perspective not just on SEB113 but on the other three units that form the first semester of QUT’s new Bachelor of Science course. SEB113 is getting a small makeover for Semester 2. One of the things we’re considering is the use of ggplot2 instead of a combination of the base graphics package, heatmaps from dendrograms with colorbars from yet another package, etc. Lattice doesn’t have the nicest interface and it’s nigh on impossible to add elements afterwards (I hate you, levelplot). It’s possible to do &lt;a href=&#34;http://gettinggeneticsdone.blogspot.com.au/2010/01/ggplot2-tutorial-scatterplots-in-series.html&#34;&gt;small multiples in ggplot2&lt;/a&gt; fairly easily. We ought to be sticking to the same steps in data analysis as we did last semester, and Daniel’s tweets refer to an experience in class last semester where we discussed drawing the analysis method out of exploratory plots of the data, rather than trying to pick the “best” model &lt;em&gt;a priori&lt;/em&gt; and making the data fit the model. &lt;a href=&#34;http://simplystatistics.org/2013/06/27/what-is-the-best-way-to-analyze-data/&#34;&gt;Roger Peng’s got a good five step&lt;/a&gt; technique for analysing data:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Exploratory analysis&lt;/li&gt;
&lt;li&gt;Model fitting&lt;/li&gt;
&lt;li&gt;Model building&lt;/li&gt;
&lt;li&gt;Sensitivity analysis&lt;/li&gt;
&lt;li&gt;Reporting&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Via &lt;a href=&#34;http://www.quantumforest.com/2013/07/flotsam-13-early-july-links/&#34;&gt;Luis Apiolaza at Quantum Forest&lt;/a&gt; I’ve stumbled across &lt;a href=&#34;http://www.statschat.org.nz/&#34;&gt;Thomas Lumley&lt;/a&gt;’s Tumblr, where he’s doing some personal blogging about statistics. An &lt;a href=&#34;http://notstatschat.tumblr.com/post/54011641155/where-is-bayesian-introductory-statistics-better&#34;&gt;interesting post&lt;/a&gt; of his is on the role of Bayesian stats in introductory classes. I would love to turn SEB113 into a Bayesian statistics based class but for the time being I will have to settle for it dealing with modelling over tests (which is still a big win, pedagogically). Teaching Bayesian statistics generally relies on a good grounding in calculus, otherwise writing down full conditionals is going to be quite difficult. When people tell me that statistics is so different to mathematics I like to point out that it’s just a combination of calculus, linear algebra and some discrete mathematics. &lt;a href=&#34;http://magazine.amstat.org/blog/2013/07/01/calculus-and-statistics/&#34;&gt;Daniel Kaplan writes at &lt;strong&gt;AMSTAT&lt;/strong&gt;News&lt;/a&gt; about ditching mathematical formalism to make statistics more accessible. The American undergraduate model is very different to what we have in Australia, but I take his point about a first year calculus class not being as relevant to graduates as a first year statistics course that teaches statistical thinking over statistical calculation. I really like the focus in SEB113 on modelling using R rather than statistical tests by hand with pages of tables (as MAB101 was when I did my Bachelor of Science). If people finish SEB113 knowing how to read their data in to R and perform a Generalised Linear Model I think we’ll have done our job. If they want to go on to further statistics from there, the statistics units in the School of Mathematical Sciences work from a calculus perspective and while they require a calculus pre-requisite (MAB121 or MAB122 for those QUT students reading) you could do a lot worse than taking MAB210 and MAB314. I hope a follow-up data analysis course will be offered to Bachelor of Science students that builds on SEB113 and covers some more advanced topics and introduces enough mathematics to make those topics worthwhile. We’ll have to see how it all unfolds as this first cohort make their way through.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Posterior samples</title>
      <link>/./2013/05/13/posterior-samples/</link>
      <pubDate>Mon, 13 May 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/05/13/posterior-samples/</guid>
      <description>&lt;p&gt;Something important to remember as a maths educator is that &lt;a href=&#34;http://www.slate.com/articles/health_and_science/science/2013/04/math_teacher_explains_math_anxiety_and_defensiveness_it_hurts_to_feel_stupid.single.html&#34;&gt;maths can make people feel stupid and people don’t like feeling stupid&lt;/a&gt;. &lt;a href=&#34;http://kottke.org/13/05/riding-an-icebreaker&#34;&gt;Ever wondered what it’s like to spend two months on an ice-breaker?&lt;/a&gt; The &lt;a href=&#34;http://harvarddatascience.com/2013/05/05/harvard-stat-221-statistical-computing-and-visualization-all-lectures-online/&#34;&gt;lecture slides from Harvard’s Stat 221 course&lt;/a&gt; are all online now. Commander Chris Hadfield’s &lt;a href=&#34;http://www.youtube.com/watch?v=KaOC9danxNo&#34;&gt;farewell from the ISS&lt;/a&gt; is, fittingly, a cover of David Bowie’s “Space Oddity”.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>New things in Science and Engineering at QUT</title>
      <link>/./2013/02/18/new-things-in-science-and-engineering-at-qut/</link>
      <pubDate>Mon, 18 Feb 2013 00:00:00 UTC</pubDate>
      <author>Alexander Ivanov</author>
      <guid>/./2013/02/18/new-things-in-science-and-engineering-at-qut/</guid>
      <description>&lt;p&gt;Today was the first day of O week at QUT, a time when the relative calm of the summer break is disturbed by an influx of 17 year olds and university-run activities that always seem to generate a lot of noise. Is it possible to be a grumpy old man a week shy of 29? I received an email from my supervisor this morning asking if I could take over from one of the other PhD students in our group who had fallen ill last week and not recovered in time for a presentation this morning. The presentation, scheduled for 9am, was to be the first of the inaugural Nanotechnology and Molecular Science HDR (Higher Degree Research, i.e. Doctoral and Masters students) symposium. I’ve been moaning quietly, since starting my PhD in the School of Physical and Chemical Sciences, that the physics discipline had nothing like the School of Mathematics’ &lt;a href=&#34;http://samclifford.info/2012/09/07/qut-school-of-mathematics-postgrad-day-day-1/&#34; title=&#34;QUT School of Mathematics Postgrad Day - Day 1&#34;&gt;Postgrad Day&lt;/a&gt;. I really like Postgrad Day as it’s a good way to see what the other postgrad students are working on, what the research foci are within the school, and for students to improve their public speaking skills by delivering their research to a room of their peers and the other researchers in the school in an environment which is much more supportive than any conference is likely to be. The NMS HDR symposium brought together a number of students and staff from optics, aerosol science, nanomaterials, biotechnology, forensics and other fields within the discipline and allows them to see, perhaps for the first time, the research that others around them are doing. Even though my lab, ILAQH, is part of the Institute for Health and Biomedical Innovation, the distance between us and the remainder of IHBI is probably greater than just the physical distance between the two campuses. We do not seem to be particularly engaged with the culture of the remainder of IHBI and it’s very rare that our group will make the trek across to Kelvin Grove to see a presentation that is a short elevator ride away from the bulk of the IHBI membership. I have really only been to IHBI a few times. The two most recent appearances have been for the IHBI Olympics (a week of activities where research domains compete against each other in fun activities such as Iron Chef and photo scavenger hunt) in 2011 where I performed as part of the Health and Human Wellbeing domain’s talent quest entry, a four person improvisation troupe called “Ha ha… what?”, and to present the work that the PhD students of the UPTECH project had been working on (where we killed half an hour of time before the presentations by playing impro warm-up games). Continuing in this spirit of improvising in front of scientists, I spoke to the NMS HDR symposium at 45 minutes’ notice and in an eight minute talk managed to touch on the key points of the UPTECH project, explaining a small fraction of the science and discussing the richness of the dataset, the questions it will allow us to answer, and the diverse range of people we have involved in the project. I was told by one of the research staff in our group afterwards that it was refreshing to see a talk with no slides and that they were impressed at the quality of a talk that contained such a small amount of preparation and wondered whether I could give a presentation without speaking. Professor Dennis Arnold, the organiser of the symposium, is now based on the same floor as me; he is one of a handful of people on our floor who are not members of ILAQH. I asked him if he thought the day was a success and he was very positive. I sincerely hope that the NMS HDR symposium continues next year and well into the future, as a way to foster interest across the traditional divide of physics vs chemistry. I had to duck out of the symposium early to attend a meeting about one of the new units in the revamped Bachelor of Science degree. Dr Sama Low Choy, one of my supervisors, has asked me to run one of the collaborative workshops in the new &lt;a href=&#34;http://www.qut.edu.au/study/unit-search/unit?unitCode=SEB113&amp;amp;idunit=44499&#34;&gt;quantitative methods unit&lt;/a&gt; (she says it’s because of my impro skills). Today was one of the planning days where we got to grips with the structure of the unit, the way the workshops are to be run and how what we are doing is significantly different to anything we’ve done before. I’ll write more about it later, such as after my first tutorial, but it’s very exciting to see QUT break with tradition and make this unit happen. Through case studies with data sets relevant to their discipline, students will learn about quantitative methods in mathematics and statistics. We are ditching &lt;em&gt;t&lt;/em&gt; tests, removing the need for statistical tables, adding structure to the group work to ensure people don’t get to ride on the effort of others and teaching R and MATLAB in a first year unit that only supposes Maths B. I’m really excited that we’re teaching first year students how to use software that is free (well, at least R is) and far more powerful than Microsoft Excel. One of the problems with MAB101, the old unit, was that the computation was done in Minitab, a piece of software that I’ve never known any researcher to use. One of the workshop leaders said that they want to go back and do undergrad again knowing that this unit now exists; I don’t blame them. This will definitely be an exciting year for me, academically. A new course with new units, new facilities in the Science and Engineering Centre, new collaboration opportunities and the chance to pick somewhere new to move to at the end of the year.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
